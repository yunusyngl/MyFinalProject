# -*- coding: utf-8 -*-
"""HB - 221009 - Piton ile Veri Analitigi Egitimi adlı not defterinin kopyası

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OE4iWS3tpYzwt4NNDjuvlbp9_3saImkm

## Halk Bankası Veri Analitiği Eğitimi
### Piton Programlama ve Veri Bilimi Kütüphaneleri

# Python (Piton) Programlama
[Piton başlangıç kitabı](https://jakevdp.github.io/WhirlwindTourOfPython/)
"""

a = 2
b = 3
toplam = a + b
print(toplam) # print yerlesik fonksiyon

print("Hello world")

# üç tırnaklar arasındaki kısım comment/yorumlardır
'''
yorumların belirtildiği yer
Syntax => Yazım
Semantic => Anlamsal
'''

prin(toplam) # Syntax hatasi

print(toplamlar) # Syntax hatasi

print(9.5)

print(9,5) # aralarina girilen virgul bu degerlerin farkli 2 piton nesnesi oldugunu belirtmeye yariyor, yani ondalik sayi belirtmek icin virgul kullanamiyoruz

"""
Yorumlar => #, üçer adet tek/çift tırnak kullanarak
Yerleşik/built-in fonksiyonlar => print(), open(), len(), range()
string/dize => 'string', "string" => karakter dizileri, character array

Veri Yapıları / Data Structures
=> listeler / lists => ['a', 'the', ...]
=> sözlükler / dictionary => {'a':5, 'the':100, ...} => anahtar:değer ikilileri

Döngüler
for i in range(10):
    # döngünün her bir elemanı için çalıştırılacak algoritma
    print(i)        # print(i) ifadesi öncesindeki boşluk indentation yani hizalama için bırakılmıştır

while i < 10:
    print(i)

Koşullu İfadeler
if
elif
else

if musterinin_yasi > 30:
    print("Kredi verilebilir.")
else:
    print("Krediniz onaylanmamıştır.")

def fonksiyon_adi(parametreler):
    print("Hello world")
    return True
"""

# COMMENTS / YORUMLAR
# bir bolumdeki ogrencilerin ortalama GNO hesabi
GNOlar = [3.0, 2.7, 3.3] # liste/list - dizi/array
# ortalamayi bulurken
# 1. öncelikle GNOlarının toplamı bulunur  => sum(GNOlar)
toplamGNO = sum(GNOlar)
# 2. sonrasında kaç öğrenci olduğu bulunur => len(GNOlar)
kac_ogrenci = len(GNOlar)
# 3. bulunan bu iki değer birbirine bölünerek ortalama değer bulunur ve bir değişkende saklanır
ortalama_gno = toplamGNO / kac_ogrenci
# bulunan değeri ekranda gösterelim
print(ortalama_gno)

# tek satirda ortalama hesabi
ortalama_gno_tek = sum(GNOlar) / len(GNOlar)
# ortalama_gno_tek = 9.0 / len(GNOlar)
# ortalama_gno_tek = 9.0 / 3
# ortalama_gno_tek = 3.0
print(ortalama_gno_tek)

# GIRINTI/INDENTATION - indentation / girinti / hizalama (scope'u belirler)
# musterinin yasi 30'dan buyukse kredi verilebilir
musterinin_yasi = 35
# KURAL TABANLI MODEL - kurallar/kosullara bagli bir mantikla calisan model
if musterinin_yasi > 30:
    # if kosulunun (musterinin_yasi > 30) dogru oldugu duruma ait olan kod blogu
    print("Kredi verilebilir")
    print("Çünkü müşterinin yaşı 30'dan büyüktür.")
else:
    print("Başvuru tekrardan incelenecektir.")
print("Kredi belirleme süreci tamamlanmıştır.")

# Sabitler / Constants
print(122) # tamsayi sabiti
print(66.45) # ondalik sabit
print("Hello world's people") # string/dize sabiti
#print('Hello world's people') # string sabiti hatası - tek tırnaklar sorun olusturabilirmektedir
print('Hello world\'s people') # \ escape kaçma karakteri
print(True)  # bool sabiti # True/False
print(None)

# pitondaki yerleşik tipler
print(type(122)) # tamsayi sabiti
print(type(66.45)) # ondalik sabit
print(type("Hello world's people")) # string/dize sabiti
print(type(True))  # bool sabiti # True/False
print(type(None))

type(None)

# Pitonda hersey bir nesnedir
# Nesnelerin metaverisi/attribute/özellikleri ve fonksiyonları/metotları olur
# Nesne => insan
#          -- metaveri=> insanin yasi, cinsiyeti, ...
#          -- metotlari=> adimat, konus, ...
# bunlara da . (dot) operatoru ile ulasilir.
# mehmet bir insan nesnesi olsun;
#     => mehmet.yas         (NOT: yas, insan nesnesinin bir ozelligi oldugu ve fonksiyon olmadigi icin () ile cagrilmiyor)
#     => mehmet.adimat(10)  (NOT: adimat, insan nesnesinin bir metodu oldugu icin () ile cagriliyor)
# bu bilgilere (nesnenin hangi metaveri/özellikler ve fonksiyonlar/metotlar var) ise dir fonksiyonu ile ulasabiliriz

x = 12

# 1. degiskende tutulan (degiskenin gosterdigi) nesnenin tipi nedir?
# nesnenin tipini type yerleşik fonksiyonu ile ogreniyoruz
type(x)

# 2. Bu nesnenin metaveri/özellikleri ve metodlari nelerdir?
# dir fonksiyonu: Nesnelerin metaverisi/özellikleri ve fonksiyonları/metotları
# dir(x) # metaverileri ve metodlarin adlarini donduruyor
dir(x)

print( dir(x) )

# 3. metodlarin/özelliklerin bilgisine nasil ulasiriz?
x.to_bytes? # kullanilan IDE'ye bagli
# Signature: x.to_bytes(length, byteorder, *, signed=False)
# Docstring: Return an array of bytes representing an integer.

x.to_bytes()

x.to_bytes(2, byteorder='big')

# LISTE NESNESI ICIN
L = [1,2,3]
# 1. degiskende tutulan (degiskenin gosterdigi) nesnenin tipi nedir?
# nesnenin tipini type yerleşik fonksiyonu ile ogreniyoruz
type(L)

# 2. Bu nesnenin metaveri ve metodlari nelerdir?
# dir fonksiyonu: Nesnelerin metaverisi/özellikleri ve fonksiyonları/metotları
# dir(L) # metaverileri ve metodlarin adlarini donduruyor
print(dir(L))

# 3. metodlarin/özelliklerin bilgisine nasil ulasiriz?
# kullanilan IDE'ye bagli
L.append?
# Signature: L.append(object, /)
# Docstring: Append object to the end of the list.

help(L.append)

L.append(5)
# ekrana/konsola bir değer basmadı
# => fonksiyon herhangi bir deger dondurmedi => None dondurdu
# => cunku degisikligi yerinde yaptiktan sonra None donduruyor

print(L.append(555))

print(L)

L = L.append(44) #  yapmiyoruz !!!
# burada = operatorunun sagindaki islem yapilip None donmesi, L degiskeninin artik None nesnesini gostermesine sebebiyet verecektir
# L = None

print(L) # orjinal nesne degisti

L.append(99)

# STRING NESNELERI
banka_adi = 'Halk Bankasi'

print(banka_adi)

type(banka_adi)

print(dir(banka_adi))

# banka_adi kucuk harfli olarak adi gostersin
banka_adi.lower()

print(banka_adi) # orjinal değer/nesne değişmedi

# banka_adi kucuk harfli olarak adi gostersin yani değişken hepsi küçük harfli olan stringi göstersin
banka_adi = banka_adi.lower()
print(banka_adi)

"""#### Sayısal Operatörler"""

# Sayisal Operatorler
x = 47
y = 4
print(x + y)
print(x - y)
print(x * y)
print(x / y) # 11.75
print(x // y) # tamsayi bolum (ondalik kismi atar ve sadece tamsayi olan kismi dondurur)
print(x % y) # kalan/remainder/mod alma
print(x ** y) # ussunu almak/exponentiation ==>> x uzeri y => 47 uzeri 4

x + y
x - y 
x / y

x / y
# 11.75

int(x / y) # int(11.75)
# int fonksiyonu sonucun ondalik kismini atarak sadece tamsayi kismini donduruyor

x // y # int(x/y)

round(x/y) # round(11.75) # round yerlesik fonksiyonu sonucu en yakin tamsayiya yuvarliyor

# en yakin tamsayiya yuvarlama
print(round(11/4)) # 2.75
print(round(9/4)) # 2.25
print(round(9/2)) # 4.5
# asagi yuvarlama
print(int(11/4)) # 2.75
print(int(9/4)) # 2.25
print(11//4) # 2.75
print(9//4) # 2.25

5 % 2 # kalan

5 // 2 # bolum

'''
# Operatör öncelikleri
1. parantezler
2. üslü sayılar
3. çarpma / bölme / kalan (%) / tamsayı bölme (//)
4. toplama / çıkarma
5. aynı önceliğe sahipler arasında da soldan sağa işlemler gerçekleştirilecek
'''

x = 1 + 3 ** 2 / 4 * 6
print(x)
# x = 1 + 3 ** 2 / 4 * 6
# x = 1 + 9 / 4 * 6
# x = 1 + 2.25 * 6
# x = 1 + 13.5
# x = 14.5

x = 1 + 3**2 // (4 * 6)
print(x)
# x = 1 + 3**2 // (4 * 6)
# x = 1 + 3**2 // 24
# x = 1 + 9 // 24
# x = 1 + 0
# x = 1

# Atama / Assignment operatoru
x = 25
print(x)
x = x + 5
print(x)
# => Augmented Operators x+=5 ==>> x = x + 5 ==>> artirilmis operator
x += 5 # atama operatorunden once + islemi yapilacagindan, + operatoru, = operatorunun onune aliniyor
print(x)

# Augmented/artırılmış atama operatörü
a = 10
b = 20
a = a * b
# a->10, b->20
# a = 10 * 20
# a = 200
a *= b
# a = 200 * 20
# a = 4000
print(a, b)

k = 10
d = 3
k **= d # us alma
print(k)

"""#### Yerleşik piton nesnelerinin Tipleri

"""

type(True)

type(False)

type(None)

type(5), type(4.5), type('veri')

xnone = None
xbool = False
print(type(xnone))
print(type(xbool))

# bool olarak True ve False bulunmaktadir. Bunlarin int degerleri ise sirasiyla 1 ve 0 dir
int(True), int(False)

bool(1), bool(0), bool(1245), bool(-111), bool(12.35), bool(0.45) # 0dan farkli sayilarin bool degeri True dur

bin(1245)

bin(0)

# stringlerin bool degerleri
bool("banka"), bool('a'), bool(''), bool('False'), bool(False)

"""#### Karşılaştırma operatörleri"""

# Karşılaştırma operatörleri => boolean => True/False
a = 18
b = 25

a == b

18 == 25

a != b

if a != b: # if 18 != 25: ==>> if True:
    print("a, b'ye esit degildir")
else:
    print("a, b'ye esittir")
print("Kontroller bitmistir")

if a = b: # tek = ifadesi atama operatorudur
    print("a")
else:
    print("b")

# Mantıksal Operatörler
# and, or, not
# Boolean / Ikili islemler
a <= 20 and b > 18

a <= 20

b > 18

'''
sol  and  sag  => sonuc
True     True     True
True     False    False
False    True     False
False    False    False
'''

musteri_adi = 'ahmet'
musteri_yasi = 35
musteri_geliri = 6500
kredi_basvuru_tutari = 100000
kredi_onaylandi_mi = None # kredinin onaylanip onaylanmadigini belirten boolean degisken. (True/False) 
# KREDI VERME KURALIMIZ
# musterinin yasi 30dan buyuk ya da 30a esitse bu musteriye kredi verilir

musteri_yasi >= 30

# KREDI VERME KURALIMIZ
# musterinin yasi 30dan buyuk ya da 30a esitse 
# ve ayni zamanda
# aylik geliri de 8000 TLnin uzerindeyse bu musteriye kredi verilir.

musteri_yasi >= 30 and musteri_geliri > 8000

musteri_yasi >= 30

musteri_geliri > 8000

if musteri_yasi >= 30 and musteri_geliri > 8000:
    print("kredi onaylanmistir")
    kredi_onaylandi_mi = True
else:
    print("kredi onay alamamistir")
    kredi_onaylandi_mi = False

print(kredi_onaylandi_mi)

if kredi_onaylandi_mi:
    print("onaylanan kredi miktari ayrilsin")
else:
    print("kredi miktarinin ayrilmasina gerek bulunmamaktadir")

'''
sol   or   sag   => sonuc
True       True     True
True       False    True
False      True     True
False      False    False
'''

# KREDI VERME KURALIMIZ
# 1. Kural
# 1.1. musterinin yasi 30dan buyuk ya da 30a esitse 
# ve ayni zamanda 
# 1.2. musterinin aylik geliri de 8000 TLnin uzerindeyse bu musteriye kredi verilir.
# ve ya
# 2. Kural
# musterinin yillik geliri talep edilen kredi miktarindan buyukse kredi onaylanir 
# Bu kosullardan ikisini de saglamiyorsa kredi verilemez.

# 1. Kural
musteri_yasi >= 30 and musteri_geliri > 8000

# 2. Kural
musteri_geliri * 12 > kredi_basvuru_tutari

# 2. Kural
yillik_gelir = musteri_geliri * 12
yillik_gelir > kredi_basvuru_tutari

# Tum kurallarin kontrolu - 1. ve 2. Kural
(musteri_yasi >= 30 and musteri_geliri > 8000) or (musteri_geliri * 12 > kredi_basvuru_tutari)

if (musteri_yasi >= 30 and musteri_geliri > 8000) or (musteri_geliri * 12 > kredi_basvuru_tutari):
    print("kredi onaylanmistir")
    kredi_onaylandi_mi = True
else:
    print("kredi onay alamamistir")
    kredi_onaylandi_mi = False

"""#### identity/kimlik (is) ve membership/uyelik (in) kontrol operatorleri"""

# identity/kimlik (is) ve membership/uyelik (in) kontrol operatorleri
# is operatoru == operatorunden farklidir
# == operatoru piton nesnelerinin iceriklerinin ayni/esit olup olmadigini kontrol eder
#    ==>> degerler birbirine esit midir'i kontrol eder ==
# is operatoru piton nesnelerinin ayni nesne olup olmadigini kontrol eder
liste1 = [1, 2, 3]
liste2 = [1, 2, 3]
liste3 = [1, 1, 1]
a = liste1

liste1 == liste2

liste1 == liste3

liste1 is liste2

# identityler => id yerlesik fonksiyonu
print( id(liste1) )
print( id(liste2) )

# f-string => suslu parantezler
# f"string gelebilir {degisken ya da fonk.} stringin kendisi"
f"liste1in {liste1} idsi: {id(liste1)}, liste2in {liste2} idsi: {id(liste2)}"

# liste1 is liste2
id(liste1) == id(liste2)

f"liste1in {liste1} idsi: {id(liste1)}, a'nin {a} idsi: {id(a)}"

a == liste1

a is liste1

# MEMBERSHIP / uyelik / elemani midir? in
'onur' in ['ahmet', 'deniz']

# analitik gorevimiz icin degersiz olan kelimeler (stopwords) - dokumandan cikarilmasini istedigimiz kelimeler
anlamsiz_kelimeler = ['a', 've', 'gibi']

print(anlamsiz_kelimeler)

yeni_kelime = 'veri'

# yeni gelen kelime anlamsiz kelimelerin icinde mi?
yeni_kelime in anlamsiz_kelimeler

'veri' in ['a', 've', 'gibi']

# yeni gelen kelime anlamsiz kelimelerin icinde degilse?
yeni_kelime not in anlamsiz_kelimeler

if yeni_kelime not in anlamsiz_kelimeler:
    print("Kelime ön işleme tabi tutulacaktır")

if yeni_kelime not in anlamsiz_kelimeler:
    print(f"{yeni_kelime} kelimesi ön işleme tabi tutulacaktır")
else:
    print(f"{yeni_kelime} kelimesi anlamsiz kelimelerden birisidir.")

yeni_kelime = 'gibi'

if yeni_kelime not in anlamsiz_kelimeler:
    print(f"{yeni_kelime} kelimesi ön işleme tabi tutulacaktır")
else:
    print(f"{yeni_kelime} kelimesi anlamsiz kelimelerden birisidir.")

# musterinin adi hesapdisi musteri isimlerinden degilse ve 2. kurali sagliyorsa bu musteriye kredi verilebilir
# 2. Kural
# musterinin yillik geliri talep edilen kredi miktarindan buyukse kredi onaylanir
hesapdisi_musteriler = ['onur', 'selin', 'mustafa']

musteri_adi not in hesapdisi_musteriler

musteri_geliri * 12 > kredi_basvuru_tutari

if (musteri_adi not in hesapdisi_musteriler) and (musteri_geliri * 12 > kredi_basvuru_tutari):
    print("kredi onaylanmistir")
    kredi_onaylandi_mi = True
else:
    print("kredi onay alamamistir")
    kredi_onaylandi_mi = False

"""f-string tekrari"""

# hangi musterinin basvuru yaptigini konsola bastirmak istersek
print( "ahmet kredi basvurusu yapmistir" )

musteri_adi

# degisken adini kullanarak
print( "musteri_adi kredi basvurusu yapmistir" )

print( f"musteri_adi kredi basvurusu yapmistir" )

# neyin degisken ya da hesaplama oldugunu suslu parantezlerle belirtiyoruz
print( f"{musteri_adi} kredi basvurusu yapmistir" )

musteri_adi='aydin'

print( f"{musteri_adi} kredi basvurusu yapmistir" )

musterinin_basvurdugu_krediler = ['araba', 'ihtiyac', 'ev']

# hangi musterinin kac farkli kredi basvuru oldugunu konsola basmak istersek
print(f"aydin isimli musterimiz 3 farkli krediye basvurmustur")

print(f"{musteri_adi} isimli musterimiz {len(musterinin_basvurdugu_krediler)} farkli krediye basvurmustur")

"""##### kullanicidan/konsol uzerinden deger almak"""

# input() fonk. => arguman olarak (parantezlerin icine) kullaniciyi bilgilendirici mesaj gonderilecek
input("Isminizi giriniz: ")
# # input fonk. string nesnesi donduruyor (tek tirnaklar arasinda konsola basiliyor)

input("Bir sayi degeri giriniz: ")

# Kullanicidan bilgi almak
sayi_degeri = input("Bir sayi degeri giriniz: ")
#sayi_degeri = '138'

print(sayi_degeri)
print(type(sayi_degeri))

sayi_degeri * 3 # stringler uzerinde carpma yapti (concatenation) => stringi carpim kadar coklayarak birbirine ekliyor

sayi_degeri

# kullanicidan string olarak alinan degeri tamsayiya donusturmemiz gerekiyor
int(sayi_degeri)

float(sayi_degeri)

# ogrenci yuksek onur derecesi almis midir? (gno >= 3.5)
okul_gno = input("Lisans ortalamanizi giriniz: ")
# okul_gno = '3.6'
if okul_gno >= 3.5:
    print(f"Öğrenci {okul_gno} genel ortalaması ile yüksek onur derecesi almaya hak kazanmıştır.")

# vs. 2
# ogrenci yuksek onur derecesi almis midir? (gno >= 3.5)
okul_gno = input("Lisans ortalamanizi giriniz: ")
print(type(okul_gno))
# okul_gno = '3.6'
# kullanicidan alinan string degeri kodun ileriki kisimlarinda kullanilacak mi? 
# Evet ise okul_gno'sunun orjinal degeri degistirilmemeli
#  ===>>> okul_gno_float = float(okul_gno)
# Hayir ise degisiklik direk bu degiskende yapilabilir
okul_gno = float(okul_gno) # ayni degiskende floata donusturulmus degeri tutuyoruz. Cunku string formatindaki deger baska yerde kullanilmiyor
print(type(okul_gno))
if okul_gno >= 3.5:
    print(f"Öğrenci {okul_gno} genel ortalaması ile yüksek onur derecesi almaya hak kazanmıştır.")

# if
# ---
# if
# else
# ---
# if
# elif
# ...
# else
# onur.durahim@principai.com

"""#### Alıştırma 1."""

# Alistirma sorusunun cevabi
sure = input("Çalışılan süreyi saat olarak giriniz: ")
sure = float(sure)
saat_ucreti = input("Saat ücretini giriniz: ")
saat_ucreti = float(saat_ucreti)
odeme_miktari = sure * saat_ucreti
print(f"Alacağınız ödeme tutarı: {odeme_miktari} TL'dir")

# yanlislikla int olarak donusturme yapilirsa yanlisligi
sure = input("Çalışılan süreyi saat olarak giriniz: ")
sure = int(sure)
saat_ucreti = input("Saat ücretini giriniz: ")
saat_ucreti = int(saat_ucreti)
odeme_miktari = sure * saat_ucreti
print(f"Alacağınız ödeme tutarı: {odeme_miktari} TL'dir")

# hata 2
sure = float(input("Çalışılan süreyi saat olarak giriniz: "))
saat_ucreti = float(input("Saat ücretini giriniz: ")) # string input ile alindiktan hemen sonra floata donusturuluyor !!!
odeme_miktari = sure * saat_ucreti
print(f"Alacağınız ödeme tutarı: {odeme_miktari} TL'dir")

# ? sayi olmayan girdi girildiginde ne yapmak gerekiyor?
# Input Check / Girdi Kontrolü !!!
# ==>> sure = input("Çalışılan süreyi saat olarak giriniz: ")
# Burada girdi kontrolunun yapilmasi gerekir ve sonrasinda donusturme yapilir
# ===>> sure = float(sure)

"""### (Yerleşik/Built-in) Veri Yapıları / Data Structures

#### Listeler
"""

L0 = [] # boş liste

L0 = list()

L0

# yerlesik len fonk.
# listedeki eleman sayısı (len)
# len(object) => Return the number of items in a container (obj).
len(L0)

L0.len() # listelerin len diye bir fonk. bulunmamaktadir

# listeler herhangi bir Python nesnesini icerebilir
L = [1, 'iki', 3.14, [11,22,33]]

len(L)

print( len(L) ) # print( 4 )

# listedeki her bir elemanin tipi (type) nedir?
# collection / yigin
# for degiskenler in iterator/collection/sequence:
# (NOT: for kelimesi sonrasindaki degisken isimlerinin daha once tanimlanmasi gerekmemektedir)
for liste_elemani in L: # liste_elemani degiskeni for dongusunun scope'unda liste elemanlarina ulastigim degisken adidir
    #print(liste_elemani, type(liste_elemani))
    print(f"{liste_elemani} elemaninin tipi {type(liste_elemani)}'dir")
    # liste_elemani = L[0] ==>> liste_elemani = 1
    # liste_elemani = L[1] ==>> liste_elemani = 'iki'
    # liste_elemani = L[2] ==>> liste_elemani = 3.14
    # liste_elemani = L[3] ==>> liste_elemani = [11,22,33]
    # liste_elemani = L[4] ==>> bu indekste bir eleman yok => Dongu tamamlanmistir

for degisken adlari in iterator/koleksiyon/sira:
    dongudeki her bir adimda calistirilacak mantiksal islemler (yani algoritmayi isletiliyor)

"""##### İndeksleme/indexing ve Dilimleme/Slicing
- indeksleme ile tek bir elemana ulasilir
- dilimleme ile birden fazla elemana ulasilabilir
"""

L

len(L)

# zero-based indexing / 0-bazlı indeksleme
L[0]

L[3]

L[5]
# olasi indeksleri (0,1,2,3) aşan bir indeksteki elemana ulaşmaya çalışırsak
# indexerror (list index out of range) hatasi aliriz

# negative indexing - eksi indeksleme
# sondan baslanir ve sondaki elemanin indeksi -1 dir
L[-1]

L[-3]

L[-5]
# olasi eksi indeksleri (-4,-3,-2,-1) aşan bir indeksteki elemana ulaşmaya çalışırsak
# indexerror (list index out of range) hatasi aliriz

len(L)

# listedeki elemanlarin index araligi
-len(L) ile len(L)-1

# listedeki elemanlarin index araligi
-len(L), len(L)-1

print(f"listedeki elemanlara negatif {-len(L)}'e kadar, pozitif +{len(L)-1}'e kadar olan indeks araliginda ulasabilirsiniz")

# slicing - dilimleme
listeadi[baslangic index:bitis index] # bitiş indeksindeki eleman hariç (olarak bir liste dondurecek)
listeadi[baslangic index:bitis index:1] # bitiş indeksindeki eleman hariç (olarak bir liste dondurecek)
listeadi[baslangic index:bitis index:artış/atlama] # bitiş indeksindeki eleman hariç, her bir artış indeksi atlayarak
artış/atlama: elemanlari okurken indeksi kacar sayi arttiracagini belirtir

L

L[1:3]

L[1:2] # icinde tek eleman olan bir liste donduruyor

L[1] # elemanin kendisini yani str olarak 'iki' elemanini donduruyor

# listelerin dilimlenmesi sonucu yine bir liste oluşuyor
# dondurulen/ulasilan listeyi bir degiskende tutabiliriz
L_1ve3_arasi = L[1:3]

print(L_1ve3_arasi)

print(type(L_1ve3_arasi))

# indekslemedeki indeksi aşma problemi dilimlemede yaşanmıyor
L[1:1000] # L[1:]

L[100:1000] # hata dondurmuyor
# bos liste donduruyor !!

# negatif indeksle dilimleme
L[-10:10]

liste2nci = [10, 20, 'uc', 'dort', 3.5, 5.87]

len(liste2nci)

liste2nci[0:3]

liste2nci[:3] # -->> liste2nci[0:3]

liste2nci[2:]

len(liste2nci)

liste2nci[len(liste2nci)] # -->> liste2nci[6]

# en sondaki elemana ulasmak icin - indekleme
liste2nci[len(liste2nci)-1]

# en sondaki elemana kadar okumak istersek - HATA
# !! en son indeks haric
liste2nci[2:len(liste2nci)-1] # liste2nci[2:5] ==> 5.87 elemanina kadar / 5. indeksteki elemana kadar

# en sondaki elemana kadar okumak istersek 
# liste2nci[2:] # ==>> liste2nci[2:6] # 5.87 elemani dahil / 5. indeksteki eleman dahil
liste2nci[2:len(liste2nci)]

# increment / artış
liste2nci[1:4]

liste2nci[1:4:1]

liste2nci[1:4:2]

# bastan sona indeksi 2ser arttirarak okumak (incremental - atlayarak okuma)
liste2nci[::2]

liste2nci[0::2]

liste2nci[:len(liste2nci):2]

liste2nci[0:len(liste2nci):2]

liste2nci[:-2:2]

liste2nci # 3.5 -2. indekste oldugundan yukarida dilime dahil edilmiyor

# Özetlersek

# indeksleme
liste2nci[3]

# eksi indeksleme
liste2nci[-2]

# dilimleme
liste2nci[1:-2]

# atlayarak dilimleme
liste2nci[1:-2:2]

# Elimizde buyukten kucuge sirali olarak ogrencilerin genel not ortalamalari bulunsun
sirali_gnolar = [3.9, 3.6, 3.55, 3.5, 3.2, 3.0, 2.75, 2.5, 2.0, 1.9, 1.75, 1.5]

# en yuksek not almis 3 ogrencinin ortalama gnosu nedir?
sirali_gnolar[:3]

#ortalama
sum(sirali_gnolar[:3]) / 3

# en dusuk not almis 3 ogrencinin ortalama gnosu nedir?
sirali_gnolar[-3:]

sum(sirali_gnolar[-3:]) / 3

"""##### Listeler (lists) ve Dizelerin (strings) indekslemedeki benzerlikleri ve mutable/immutable olma farkliliklari"""

# dizeler indeksleme ve dilimlemede listelere benzer olarak calisirlar
ders_konusu = 'veri analitiği'
# karakter dizisi # karakter arrayleri

ders_konusu # -->> ['v', 'e', 'r', ...., 'i'] benzer

len(ders_konusu)

# indeksleme
ders_konusu[2]

ders_konusu[4] # bosluk karakteri

print(ders_konusu[4]) # bosluk karakteri

# dilimleme
ders_konusu[6:10]

ders_konusu[6::2]

# mutable/immutable olma farkliliklari

#############   STRING   #############
# Stringler immutable (değiştirilemez)
ders_konusu[5]

# kucuk harf a yi buyuk harf A ya donusturmek istersek
ders_konusu[5] = 'A' #immutable
# assignment => atama

type(ders_konusu)

#############   LISTS   #############
# listeler mutable (değiştirilebilir)
liste2nci[5]

liste2nci

liste2nci[5] = 11.25 # atama operatoru mutable olan listelerde yerinde degisiklik yapabiliyor

print(liste2nci)

# stringleri indeksleme yaparak yerinde degistermiyoruz.
# kelimelerin bas harflerini buyuk harf nasil yapabiliriz?

ders_konusu

# string veri tipinin metadata ve metodlari
print( dir(ders_konusu) )
# dir(str)

# capitalize fonk. bilgisine ulaşmak için
ders_konusu.capitalize?
#Signature: ders_konusu.capitalize()
#Docstring: Return a capitalized version of the string.
#           More specifically, make the first character have upper case and the rest lower case.

help(ders_konusu.capitalize)

ders_konusu.capitalize()

ders_konusu.title() # title fonk. stringin bas harfleri buyuk olan halini donduruyor

ders_konusu # yapılan değişiklikler orjinal stringin değerini etkilemedi

liste2nci

liste2nci.append(222)

liste2nci # yapılan değişiklik (stringlerden farkli olarak) orjinal listenin içeriğini değiştirdi !!

# 1. orjinal string ve yeni olusan string ayrı ayrı saklanmak istenirse
baslik_ders_konusu = ders_konusu.title()

print(f"Orjinal string: {ders_konusu}")
print(f"Yeni oluşan dize: {baslik_ders_konusu}")

# 2. orjinal stringin tutuldugu degisken yeni nesneyi gostersin istenirse (orjinal degere ihtiyac yoksa)
ders_konusu = ders_konusu.title()

print(ders_konusu) # orjinal stringin degerini kaybetmis olduk. Ihtiyac duyulmadigi icin

# genel olarak fonksiyonlari 2 farkli sekilde cagirip kullanabiliyoruz

# 1. yerlesik/built-in ya da kullanici(/user-defined) tarafindan yazilmis fonksiyonlar
len(ders_konusu) # arguman olarak gonderilen string icinde kac karakter var?

# 2. piton nesnelerinin (str nesnesinin) kendi metotlarinin kullanimi
ders_konusu.upper() # ders_konusu bir str nesnesi. Bu nesnenin upper fonksiyonunun cagirilmasi

# tum harfleri buyuk harf yapan, kullanici tarafindan yazilmis ya da yerlesik bir fonk. kullanabilir miyiz?
upper(ders_konusu)
# upper adinda bir yerlesik ya da kullanici tarafindan yazilmis fonksiyon bulunmamaktadir

## YAPILACAK: turkce upper fonksiyonunun yazilmasi?

# yerlesik ya da kullanici tarafindan tanimlanmis bir upper fonk. bulunmamaktadir
# str piton nesnesinin (ders_konusu) upper fonk. kullanilacaktir
# str modulunun upper fonk. direk kullanadabiliriz
# upper fonksiyonu string nesnelerine yonelik bir fonksiyon oldugu icin string nesnesinin bir metodu olarak tanimlanmistir
str.upper(ders_konusu)
# print gibi yerlesik fonksiyonlar ise pitonun daha genis bir nesne kumesine yonelik gelistirilmistir

"""##### liste fonksiyonları / operasyonları"""

2 + 5 # arti operatoru sayilarda toplama islemi yapar

'veri' + 'bilimi' # arti operatoru dizelerde birleştirme (concatenation) operasyonu yapar

# Concatenation (birleştirme - birbirine bağlama)
L1 = [1,2,4,5]
L2 = ['a', 'b', 'c']
L3 = L1 + L2 # concatenation (+ operatörü stringlerde de benzer şekilde çalışıyor)
print(L3)

print(L1) # L1 ve L2 degiskenlerinin gosterdikleri nesneler degismedi
print(L2)

L1 + L2

print( len(L1), len(L2), len(L3) )

print( dir(list) ) # print( dir(L1) )

# 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort'

L3

# listeler mutable/yerinde degistirilebilir
L3.append?
# Signature: L3.append(object, /)
# Docstring: Append object to the end of the list.

L3.append('f') # herhangi bir deger dondurmuyor (None donduruyor)

L3

dondurulen_deger = L3.append('d')
# dondurulen_deger = None
print(dondurulen_deger)

print(L3)

# yukaridaki iki operasyonu tek satirda yazarsak
print(L3.append('d'))
# listeler mutable => append metodu ise void bir metod, None döndürüyor
# => yani hiçbir şey dondurmedi

print(L3)
print(len(L3))

L3.append([19, 29]) # listeyi append edersek

print(L3)
print(len(L3))
# Append Fonk.
# (arguman olarak) verilen listeyi tek bir eleman olarak sona ekliyor

# (arguman olarak) verilen listenin elemanlarini tek tek sona eklemek istersek
# ==>> EXTEND metodu kullanilacak

# EXTEND METODU
L3.extend([1.55, 2.88]) # listeyi, verilen listedeki elemanları sona ekleyerek yerinde genişletti

print(L3)
print(len(L3))

# extend metodu arguman olarak iterable bekliyor
L3.extend?
# Signature: L3.extend(iterable, /)
# Docstring: Extend list by appending elements from the iterable.

L3.extend(33) # tamsayilar iterable/yenilenebilir degildir

L2

# slicing yaparak secilen verilerle extend kullanimi
# L2nin son 2 elemanini tek tek L3e eklemek istersek
L2[-2:]

L3.extend(L2[-2:])
print(L3)
print(len(L3))

# listenin (sonuna eklemek yerine) istenilen bir yerine yeni bir eleman eklenmesi
# append/extend olmaz cunku bu fonksiyonlar sona ekleme yapiyor

# 3. eleman olan 4 rakamindan once 'banka' kelimesini listeye eklemek istiyoruz
# insert fonk. !
# 4un bulundugu indeks => 2
L3.insert(2, 'banka')

print(L3)
print(len(L3))

L3.insert?
# Signature: L3.insert(index, object, /)
# Docstring: Insert object before index.

eklenecek_deger = 'veri'
eklenecek_indeks = 6

L3.insert(eklenecek_indeks, eklenecek_deger)

print(L3)
print(len(L3))

# L3u biraz daha genisletirsek
L3.extend( ['d', 2.5, 100, 'd', 'a','1.75', 'b'] )

print(L3)
print(len(L3))

# 'b' elemanindan listede kac tane var?
# ==>> count metodunu kullanacagiz

# 'b' listede var mi? True/False
# 1. in operatorunun kullanimi
'b' in L3

# 'b' listede kac defa geciyor?
L3.count('b')

# 'b' listede var mi? True/False
# 2. count fonk. kullanimi
L3.count('b') > 0

# 'b' listede nerede bulunuyor - indeksi ne => ilk indeks kac?
# index
L3.index('b')
# nesneyi listede buldugumuz ilk indeksi donduruyor
# TANIMI: listede değeri x'e eşit olan ilk öğenin sıfır tabanlı dizinini/indeksini döndürür

# 1. elemanin indeksi
L3.index('b')

# ikinci 'b' nesnesinin indeksini bulmak icin
L3.index('b', 7) # tekrardan 7 indeksini donuyor, cunku aramaya 7. indeksten basliyor

# ikinci 'b' nesnesinin indeksini bulmak icin
L3.index('b', 7+1)

# indeksleri bir degiskende tutalim
ilk_b_indeksi = L3.index('b')
# ilk_b_indeksi = L3.index('b', 0)
print(ilk_b_indeksi)
ikinci_b_indeksi = L3.index('b', ilk_b_indeksi+1)
print(ikinci_b_indeksi)
# ucuncu 'b' nesnesinin indeksini bulmak icin
ucuncu_b_indeksi = L3.index('b', ikinci_b_indeksi + 1)
print(ucuncu_b_indeksi)
# 4. 'b' nesnesinin indeksini bulmak icin
dorduncu_b_indeksi = L3.index('b', ucuncu_b_indeksi+1) # 4. bir b olmadigi icin ve boyle bir b bulamadigindan hata atiyor
print(dorduncu_b_indeksi)

# Bir listedeki bir elemanın tüm oluşumları nasıl bulunur? (HATA ALMADAN - program crush etmeden)
# Translate: How to find out all the occurrences of an element in a list
# arama motoru ile buldugumuz sonuc - 2022-10-21
# https://stackoverflow.com/questions/6294179/how-to-find-all-occurrences-of-an-element-in-a-list
# indices = [i for i, x in enumerate(my_list) if x == "whatever"]
# ==>> # enumerate yerlesik fonksiyonu ile list-comprehension metodunu kullanarak
indices = [i for i, x in enumerate(L3) if x == 'b']

print(indices)

enum_listesi = ['a', 'b', 'c']
list(enumerate(enum_listesi))

# liste fonksiyonlari ile bir nesnesinin bulundugu indekslerin bulunmasi
kactanebvar = L3.count('b')
b_nin_indeksleri = []
bulundugu_indeks = -1
for i in range(kactanebvar): # kactanebvar kadar donguyu isletiyoruz => cunku daha fazla arama yapilinca hata atiyor
    bulundugu_indeks = L3.index('b', bulundugu_indeks+1)
    b_nin_indeksleri.append(bulundugu_indeks)

print(b_nin_indeksleri)

print(L3)

# remove
L3.remove('a')
# ilk karsilasilan degeri listeden kaldirir
# None donduruyor

print(L3)

# pop 
L3.pop?
# Signature: L3.pop(index=-1, /)
# Docstring: Remove and return item at index (default last).
# argumansiz cagirildiginda default index degeri -1 oldugundan sondaki elemani silip o elemani dondurur
# append fonk. tersi gibi calisir

L3.pop()

print(L3) # pop fonk. ile sondaki b listeden cikarildi.

silinen_eleman = L3.pop(8) # 8. indeksteki elemani kaldirip, o elemani donduruyor

print(silinen_eleman)
print(L3)

"""##### Sorting / SIRALAMA"""

L3.sort()
# L3 elemanlarinin karsilastirilamaz olmasindan dolayi siralanamiyor

# karsilastirma yapilabilmesi icin nesnelerin benzer/karsilastirilabilir tipte olmalari gerekmektedir
# benzer/karsilastirilabilir => float ile int
siralanabilirliste = [10, 4, 22.5, 22, 145, 8]

# sort fonksiyonunu cagirmadan/call önce
print(siralanabilirliste)

siralanabilirliste.sort() # sort fonksiyonu da None donduruyor
# None dondurdugunu bildigimizden donen degeri bir degiskende tutmamiza gerek yok

# sort fonksiyonunu cagirdiktan/call sonra
print(siralanabilirliste)

# buyukten kucuge siralamak istersek
# sort fonksiyonunun reverse adinda bir parametresi var.
# reverse parametresine anahtar deger (keyword) argümani olarak True degerini veriyoruz.
siralanabilirliste.sort(reverse=True)

# sort fonksiyonunu reverse parametresini True ile cagirdiktan/call sonra
print(siralanabilirliste)

# YANLISLIKLA sort fonk. dondurdugu degeri orjinal degiskende tutmak istersek
siralanabilirliste = siralanabilirliste.sort(reverse=True)
# ==>> siralanabilirliste = None
# sort fonksiyonu None dondurdugunden SEMANTIC/ANLAMSAL olarak hatali kod

print(siralanabilirliste)

# yukarida yanlislikla! None'i atadigimiz icin tekrardan olusturuyoruz
siralanabilirliste = [10, 4, 22.5, 22, 145, 8]

siralanabilirliste.sort()
print(siralanabilirliste)

# sort fonksiyonunun reverse parametresini kullanmadan buyukten kucuge cevirmek istersek
# reverse fonk.
siralanabilirliste.reverse()
# reverse => siralama yapmiyor !! yani elemanlari karsilastirma operasyonu yok
print(siralanabilirliste)

print(L3)

L3.sort() # karsilastirma operasyonu var

L3.reverse() # karşılaştırma yapılmadığından hata vermiyor

print(L3)

"""##### Yerleşik Fonk."""

# range yerlesik fonksiyonu
# genellikle indeks olusturmak icin kullandigimiz fonksiyon
range?
# range(stop) -> range object
# range(start, stop[, step]) -> range object
# Başlangıçtan (dahil) bitişe (hariç) adım/step atlayarak bir tamsayı dizisi üretir

L3[3:10:2] # dilimlemeye benzer calisiyor

# range(stop) -> range object
range(4) # 0'dan baslayarak 4'e kadar olan tamsayilari dondurur # [0,1,2,3]
# range nesnesi dondurur

list(range(4)) # list() listeye donustur fonk.dur
# indeks listesi olarak kullanabiliriz !!

# for dongusunde bir listenin indeksleri olarak kullanilirsa
# for indeks in [0,1,2,3]:
for indeks in range(4):
    print(indeks)

print(siralanabilirliste)

# AMAC: listenin tum elemanlarına indekslerle ulaşmak
### range fonksiyonu
# 1. adim: listede kac eleman var
listedeki_eleman_sayisi = len(siralanabilirliste)
print(listedeki_eleman_sayisi)

# 2. range fonk. ile indekslerin olusturulmasi
range(listedeki_eleman_sayisi)
# range(len(siralanabilirliste))

list(range(listedeki_eleman_sayisi))

# AMAC: listenin tum elemanlarına indekslerle ulaşmak
# for indeks in range(len(siralanabilirliste)):
for indeks in range(listedeki_eleman_sayisi):
    print(indeks, siralanabilirliste[indeks])
    # for indeks in [0,1,2,3,4,5]
    # indeks = 0 -->> 0, siralanabilirliste[0] -->> 0, 145
    # indeks = 1 -->> 1, siralanabilirliste[1] -->> 1, 22.5
    # ...
    # indeks = 5 -->> 5, siralanabilirliste[5] -->> 5, 4
    # indeks = ?? ==> baska indeks elemani kalmadigindan dongu sonlandiriliyor

"""[Piton Programlamadaki Yerleşik/Built-in Fonksiyonlar](https://docs.python.org/3/library/functions.html)"""

# diger yerlesik fonksiyonlar
gnolar = [2.5, 1.4, 3.6]

max(gnolar)

min(gnolar)

# ortalama hesaplama
sum(gnolar) / len(gnolar)

"""##### Alıştırma
Aşağıdaki, kullanici tarafindan girilen sayıların ortalamasını bulan kodu, listeleri kullanarak yazınız
"""

girdi = input("Bir sayi giriniz: ")

girdi

type(girdi)

sayi_degeri = float(girdi)
print(sayi_degeri)

# AMAC: kullanici tarafindan girilen sayıların ortalamasını bulmak
# (Girilmesi gereken sayi miktari 5 olsun => 5 tane ile sinirlayalim)
# bu vs.: ortalama hesaplarken girilen sayilarin toplami, sayi adedine bolunur
# toplam sayi ve girilen sayi adedi bulunacaktir

# dongu icinde: kullanicidan sayi alinir, bu sayi, sayi toplamina eklenir ve sayi adedi 1 arttirilir
# while kosul: => while True: # sonsuz dongu => kosul her zaman dogru olacagindan
sayilar_toplami = 0
sayi_adedi = 0
while True:
    # 1. kullanicidan deger alinir ve sayi tipine donusturulur
    girdi = input("Bir sayi giriniz: ")
    sayi_degeri = float(girdi)
    sayilar_toplami = sayilar_toplami + sayi_degeri # sayilar_toplami += sayi_degeri
    sayi_adedi += 1 # sayi_adedi = sayi_adedi + 1
    # kullanici 5 tane sayi girebilsin
    if sayi_adedi == 5:
        # artik yeni bir sayi alinmasin, yani dongu bitirilsin (kirilsin)
        break

# bu noktada donguden cikilmistir. 
# Kullanicinin girdigi sayilarin toplami ve kac adet girdikleri ilgili degiskenlerde tutulmustur.
sayilarin_ortalamasi = sayilar_toplami / sayi_adedi
print(f"Girilen sayıların ortalama değeri: {sayilarin_ortalamasi}")

# LİSTE metodlarini kullarak 
# AMAC: kullanici tarafindan girilen sayıların ortalamasını bulmak
# (Girilmesi gereken sayi miktari 5 olsun => 5 tane ile sinirlayalim)
# bu vs.: girilen sayilar bir liste icine ekleyerek tutulur. bu listedeki sayilarin toplami, icindeki sayi adedine bolunur.
sayi_listesi = []
while True:
    # 1. kullanicidan deger alinir ve sayi tipine donusturulur
    girdi = input("Bir sayi giriniz: ")
    sayi_degeri = float(girdi)
    sayi_listesi.append(sayi_degeri)
    # kullanici 5 tane sayi girebilsin
    if len(sayi_listesi) == 5:
        # artik yeni bir sayi alinmasin, yani dongu bitirilsin (kirilsin)
        break

# bu noktada donguden cikilmistir. 
# Kullanicinin girdigi sayilar listede tutulmustur.
# yerlesik fonksiyonlari kullanarak ortalama bulunursa
sayilarin_ortalamasi = sum(sayi_listesi) / len(sayi_listesi)
print(f"Girilen sayıların ortalama değeri: {sayilarin_ortalamasi}")

print(sayi_listesi)

# yerlesik olmayan bir kutuphane fonksiyonu kullanmak istersek
# numpy kutuphanesi kullanilirsa
import numpy as np

np.sum(sayi_listesi)

np.mean(sayi_listesi)

np.var(sayi_listesi)

np.std(sayi_listesi)

# ortalamanin 2 std sapmasindan buyuk/kucuk degerler var mi?
np.mean(sayi_listesi) - 2 * np.std(sayi_listesi), np.mean(sayi_listesi) + 2 * np.std(sayi_listesi)

# ODEV
# liste metodlarini kullarak 
# ve kullanicinin diledigi kadar sayi girmesine olanak saglayan versiyon
# => kullanicidan sayi girmeyi bitirdigine dair bilgi almamiz gerekiyor
#     => kullanici girdi olarak 'bitti' girerse sayi alma dongusunden cikabiliriz

# 
while True:
    kelime = input("Lütfen bir kelime giriniz: ")
    kelimebosluksuz = kelime.strip()   #girilen kelimede başta ve sondaki boşlukları kırpar
    kelimekucuk = kelimebosluksuz.lower()
    
    L=[]
    metin= ""
    kelimedekilerharfmi = True
    for harf in kelimekucuk:
        if harf.isalpha() or harf == ' ':
            pass
        else:
             kelimedekilerharfmi = False
             break

    if kelimedekilerharfmi == False : # girilen kelimelerin sadece harflerden oluşup oluşmadığı(özel karakterlerden oluşursa tekrar girdirir)
        print("Kelimeler sadece harflerden oluşmalıdır, lütfen tekrar deneyiniz.", "\n")
    else:
        for harf in kelimekucuk:
            L.append(harf) #harfleri listeye (eleman) ekler
        L[0] = L[0].upper() #Listenin ilk elemanını (ilk harfi büyük harf yapar
        for i in range(1,len(L)):
            L[i] = L[i].lower()
        for i in range(0, len(L)):
            metin += L[i] #Son olarak bütün elemanları (harfleri) yanyana getirir
        print(metin, "\n")

"""### Koşullu İfadeler ve Döngüler (Conditional Executions and Iterations)"""

x, y = 10, 20

if x < y:
    print("kucuktur")
elif x > y:
    print("buyuktur")
else:
    print("esit")

# HATALI versiyon 1
if x < y:
    print("kucuktur")
if x > y:
    print("buyuktur")
else:
    print("esit")

# HATALI versiyon 2
if x < y:
    print("kucuktur")
    if x > y:
        print("buyuktur")
    else:
        print("esit")

# HATALI versiyon 3
x = 15
y = 10
if x < y:
    print("kucuktur")
    if x > y:
        print("buyuktur")
else:
    print("esit")

# DOGRU 2. versiyon
if x < y:
    print("kucuktur")
else:
    if x > y:
        print("buyuktur")
    else:
        print("esit")

x = 10, y = 15

x, y = 10, 15

print(x)
print(y)

# 1. if blogundaki ifadelerden sadece 1 tanesi calistirilir
# 2. kosullar sirasiyla degerlendirilir
# ------------------------
if kosullar?: # kosullar birden fazla mantiksal operator barindirabilir
    ifmantigi # if'e ait olan kosullar True ise yani dogruysa bu ifadeler calistirilacaktir
# ------------------------

if kosullar?: # kosullar birden fazla mantiksal operator barindirabilir
    ifmantigi # if'e ait olan kosullar True ise yani dogruysa bu ifadeler calistirilacaktir
else:
    elsemantigi # if'e ait olan kosullar False ise calistirilacaktir
# ------------------------

if kosullar?: # kosullar birden fazla mantiksal operator barindirabilir
    ifmantigi # if'e ait olan kosullar True ise yani dogruysa bu ifadeler calistirilacaktir
elif diger kosullar?:
    elifmantigi # if'e ait olan kosullar False ise ve diger kosullar True ise calistirilacaktir
else:
    elsemantigi # if'e ve elif'lere ait olan kosullar False ise calistirilacaktir
# ------------------------

if kosullar?: # kosullar birden fazla mantiksal operator barindirabilir
    ifmantigi # if'e ait olan kosullar True ise yani dogruysa bu ifadeler calistirilacaktir
elif diger kosullar?:
    elifmantigi # if'e ait olan kosullar False ise ve diger kosullar True ise calistirilacaktir

# ------------------------
# en genis if blogu ornegi
if kosullar?: # kosullar birden fazla mantiksal operator barindirabilir
    ifmantigi # if'e ait olan kosullar True ise yani dogruysa bu ifadeler calistirilacaktir
elif diger kosullar?:
    elifmantigi # if'e ait olan kosullar False ise ve diger kosullar True ise calistirilacaktir
elif ...:
    digerelifmantigi
elif ...:
    ...
...
else:
    elsemantigi # if'e ve elif'lere ait olan kosullar False ise calistirilacaktir

musteri_geliri = 12000
musterinin_yasi = 40

# kredi basvuru degerlendirme kurallari - 1
# 1. basvuru sahibinin yasi 30dan buyukse ve geliri 10000den buyuk ya da esitse OK
if musterinin_yasi > 30 and musteri_geliri >= 10000:
    print("Kredi Onaylanmistir")

# kredi basvuru degerlendirme kurallari - 2
# 1. basvuru sahibinin yasi 30dan buyukse ve geliri 10000den buyuk ya da esitse OK
# bu kosullar saglanmiyorsa, kredi RED olur
if musterinin_yasi > 30 and musteri_geliri >= 10000:
    print("Kredi Onaylanmistir")
else:
    print("Kredi Basvurusu OnaylanMAmistir")

# kredi basvuru degerlendirme kurallari - 3
# 1. basvuru sahibinin yasi 30dan buyukse ve geliri 10000den buyuk ya da esitse OK
# 2. musterinin geliri 20000 TLden buyukse, yasa bakmadan OK
# bu kosullar saglanmiyorsa, kredi RED olur
if musterinin_yasi > 30 and musteri_geliri >= 10000:
    print("Kredi Onaylanmistir - 1")
elif musteri_geliri > 20000:
    print("Kredi Onaylanmistir - 2")
else:
    print("Kredi Basvurusu OnaylanMAmistir")

# kredi basvuru degerlendirme kurallari - 3
# 1. basvuru sahibinin yasi 30dan buyukse ve geliri 10000den buyuk ya da esitse OK
# 2. musterinin geliri 20000 TLden buyukse, yasa bakmadan OK
# tum bu kosullar saglanmiyorsa, kredi RED olur
if (musterinin_yasi > 30 and musteri_geliri >= 10000) or (musteri_geliri > 20000):
    print("Kredi Onaylanmistir - 1 ve ya 2")
else:
    print("Kredi Basvurusu REDdedilmistir")

"""##### **Alıştırma - 2**
Kullanıcıdan süre ve saat başına alınacak ücret bilgisini aldıktan sonra çalışana ödenecek brüt ücreti saat hesaplayan bir program yazmanız beklenmektedir. Programınız 40 saat üzerinde gerçekleşen çalışma süresini fazla mesai olarak kabul etmeli ve fazla mesai ücretini normal çalışma ücretinin 1,5 katı olarak alarak çalışana ödenecek brüt ücreti hesaplamalıdır.
"""

sure = input("Saat olarak çalışılan süreyi giriniz: ")
sure = float(sure)
saatucreti = input("Saatlik ücret miktarını giriniz: ")
saatucreti = float(saatucreti)

if sure > 40:
    odeme_miktari = 40 * saatucreti + (sure - 40) * (saatucreti * 1.5)
else:
    odeme_miktari = sure * saatucreti

print(f"Alacağınız ödeme tutarı: {odeme_miktari} TL'dir")

# yukaridaki kodun daha okunur hali
sure = input("Saat olarak çalışılan süreyi giriniz: ")
sure = float(sure)
saatucreti = input("Saatlik ücret miktarını giriniz: ")
saatucreti = float(saatucreti)

if sure > 40:
    fazla_mesai_suresi = sure - 40
    mesai_ucreti = saatucreti * 1.5
    odeme_miktari = 40 * saatucreti +  fazla_mesai_suresi * mesai_ucreti
else: # sure <= 40 olma durumu
    odeme_miktari = sure * saatucreti

print(f"Alacağınız ödeme tutarı: {odeme_miktari} TL'dir")

# yukaridaki kodun parameterize edilmis hali
# sabitleri de degiskenlerde tutalim? => mesai ici sureyi degiskende (mesai_ici_sure) tutalim
# yukaridaki kodun daha okunur hali
sure = input("Saat olarak çalışılan süreyi giriniz: ")
sure = float(sure)
saatucreti = input("Saatlik ücret miktarını giriniz: ")
saatucreti = float(saatucreti)

mesai_ici_sure = 40
fazla_mesai_ucret_katsayisi = 1.5

if sure > mesai_ici_sure:
    fazla_mesai_suresi = sure - mesai_ici_sure
    mesai_ucreti = saatucreti * fazla_mesai_ucret_katsayisi
    odeme_miktari = mesai_ici_sure * saatucreti +  fazla_mesai_suresi * mesai_ucreti
else: # sure <= 40 olma durumu
    odeme_miktari = sure * saatucreti

print(f"Alacağınız ödeme tutarı: {odeme_miktari} TL'dir")

# yukaridaki kodun parameterize edilmis hali
# sabitleri de degiskenlerde tutalim? => mesai ici sureyi degiskende (mesai_ici_sure) tutalim
# yukaridaki kodun daha okunur hali
sure = input("Saat olarak çalışılan süreyi giriniz: ")
sure = float(sure)
saatucreti = input("Saatlik ücret miktarını giriniz: ")
saatucreti = float(saatucreti)

mesai_ici_sure = 45
fazla_mesai_ucret_katsayisi = 1.75

if sure > mesai_ici_sure:
    fazla_mesai_suresi = sure - mesai_ici_sure
    mesai_ucreti = saatucreti * fazla_mesai_ucret_katsayisi
    odeme_miktari = mesai_ici_sure * saatucreti +  fazla_mesai_suresi * mesai_ucreti
else: # sure <= 40 olma durumu
    odeme_miktari = sure * saatucreti

print(f"Alacağınız ödeme tutarı: {odeme_miktari} TL'dir")

sure = input("Saat olarak çalışılan süreyi giriniz: ")
sure = float(sure)
saatucreti = input("Saatlik ücret miktarını giriniz: ")
saatucreti = float(saatucreti)

mesai_ici_sure = 45
fazla_mesai_ucret_katsayisi = 1.75

if sure > mesai_ici_sure:
    fazla_mesai_suresi = sure - mesai_ici_sure
    mesai_ucreti = saatucreti * fazla_mesai_ucret_katsayisi
    odeme_miktari = mesai_ici_sure * saatucreti +  fazla_mesai_suresi * mesai_ucreti
else: # sure <= 40 olma durumu
    odeme_miktari = sure * saatucreti

print(f"Alacağınız ödeme tutarı: {odeme_miktari} TL'dir")

"""#### Döngüler (Iterations)"""

while koşullar?: # kosullar True yani Dogru oldugu surece donguye ait ifadeler calistirilir.
    dongu ifadeler/işlemler (while dongusune ait kod blogu - while'in ic hizasinda olan kodlar)

for degisken adlari (iterator degiskenleri) in collection/iterator/yinelenebilir/yigin:
    dongu ifadeleri/işlemleri (for dongusune ait kod blogu - for'un ic hizasinda olan kodlar)

break (kendine en yakin olan dongunun kirilmasini ve o donguden cikilmasini saglar)
continue (kendisinden sonra gelen ve donguye ait olan ifadeleri calistirmadan bir sonraki dongu adimina gecmeyi saglar)
pass (bos ifade - herhangi bir islem yapilmasi istenmediginde kullanilir)

# su anda fonk nasil yazilacagina karar verilmemis fakat fonksiyon bir sekilde de burada tutulmak isteniyor
def oklit_uzakligi()

def oklit_uzakligi():
    pass

# ogrencilerin genel not ortalamalari bir listede tutuluyor
gnolar = [3.6, 1.5, 2.9]

# gnolara gore mezun mu degil mi kontrolunun yapilmasi ve mezunlarin gnolarinin bir listede saklanmasi
# ogrencinin mezun olabilmesi icin gno'sunun 2.0dan buyuk ya da 2.0a esit olmasi gerekmektedir
# mezun ortalamalarinin tutulacagi liste
mezun_gnolari = []
# tek tek not ortalamalarini okuyup mezun mu kontrolunun yapilmasi
for ogr_gno in gnolar:
    print(ogr_gno)
    if ogr_gno >= 2.0:
        print("Mezun olabilmektesiniz")
        mezun_gnolari.append(ogr_gno)
    else:
        print("Mezun olmaya hak kazanamadiniz")
print("Mezun olunma kontrolu tamamlanmistir")
# dongunun ilk iterasyonunda => ogr_gno = 3.6
# 2. iterasyonda             => ogr_gno = 1.5
# 3. iterasyonda             => ogr_gno = 2.9
# gnolarda okunmamis eleman kalmadi => dongu sonlandi

print(mezun_gnolari)

# mezun olan ogrencilerin gnolarinin ortalamasi
import numpy as np
ortalama_gno = np.mean(mezun_gnolari)
print(ortalama_gno)

ogrGNOlari = [1.9, 2.2, 3.3, 3.1, 1.99, 4.0, 3.1, 1.1, 2.2, 3.3]

# listedeki ilk 5 ogrencinin not ortalamalarini bulunuz
# 1. for dongusu ve indeksler ile
toplam_gno = 0.0
# range(5) ==>> [0,1,2,3,4]
for ind in range(5):
    ogr_gno = ogrGNOlari[ind]
    toplam_gno = toplam_gno + ogr_gno
ortalama_gno = toplam_gno / 5
print(ortalama_gno)

# alternatif 2 
# => listedeki ilk 5 ogrencinin not ortalamalarini bulunuz
# 2. ogrenci notlari direk listeden tek tek okunarak
toplam_gno = 0.0
gno_adedi = 0
for gno in ogrGNOlari:
    toplam_gno += gno
    gno_adedi = gno_adedi + 1
    if gno_adedi == 5:
        break

ortalama_gno = toplam_gno / gno_adedi
print(ortalama_gno)

# dilimleme ile
# listedeki ilk 5 ogrencinin not ortalamalarini bulunuz
# tekrardan import etmemize gerek bulunmamakta => import numpy as np
ortalama_gno = np.mean(ogrGNOlari[:5])
print(ortalama_gno)

# tum sinifin GNOlarinin ortalamasini bulalim.
toplamGNO = 0 # ilk deger verme - initialization
kac_ogrenci = 0
for gno in ogrGNOlari:
    toplamGNO = toplamGNO + gno
    kac_ogrenci += 1
ortalama_gno = toplamGNO / kac_ogrenci 
# kac_ogrenci yerine len(ogrGNOlari) kullanilabilirdi ==> ortalama_gno = toplamGNO / len(ogrGNOlari)
print(f"Öğrencilerin GNO ortalaması: {ortalama_gno:.3f}") # tum ogrencilerin ortalamasi bulunmustur
print(f"{len(ogrGNOlari)} tane ogrenci icinden {kac_ogrenci} ogrencinin notu goz onune alinmistir")

# tum sinifin GNOlarinin ortalamasini bulalim.
# FAKAT siniftaki en yuksek ve en dusuk GNO degerlerini goz onune almayalim => es gecelim => continue
toplamGNO = 0 # ilk deger verme - initialization
kac_ogrenci = 0
enyuksekGNO = max(ogrGNOlari) 
endusukGNO = min(ogrGNOlari)
for gno in ogrGNOlari:
    if gno == enyuksekGNO:
        continue
    if gno == endusukGNO:
        continue
    toplamGNO = toplamGNO + gno
    kac_ogrenci += 1
ortalama_gno = toplamGNO / kac_ogrenci 
# kac_ogrenci yerine len(ogrGNOlari) kullanilabilirdi ==> ortalama_gno = toplamGNO / len(ogrGNOlari)
print(f"Öğrencilerin GNO ortalaması: {ortalama_gno:.3f}") # tum ogrencilerin ortalamasi bulunmustur
print(f"{len(ogrGNOlari)} tane ogrenci icinden {kac_ogrenci} ogrencinin notu goz onune alinmistir")

# tum sinifin GNOlarinin ortalamasini bulalim.
# FAKAT siniftaki en yuksek ve en dusuk GNO degerlerini goz onune almayalim => es gecelim => continue
toplamGNO = 0 # ilk deger verme - initialization
kac_ogrenci = 0
enyuksekGNO = max(ogrGNOlari) 
endusukGNO = min(ogrGNOlari)
for gno in ogrGNOlari:
    if gno == enyuksekGNO or gno == endusukGNO:
        continue
    toplamGNO = toplamGNO + gno
    kac_ogrenci += 1
ortalama_gno = toplamGNO / kac_ogrenci 
# kac_ogrenci yerine len(ogrGNOlari) kullanilabilirdi ==> ortalama_gno = toplamGNO / len(ogrGNOlari)
print(f"Öğrencilerin GNO ortalaması: {ortalama_gno:.3f}") # tum ogrencilerin ortalamasi bulunmustur
print(f"{len(ogrGNOlari)} tane ogrenci icinden {kac_ogrenci} ogrencinin notu goz onune alinmistir")

# enyuksekGNO => 4.0, endusukGNO => 1.1
# dongunun ilk iterasyonunda => gno = 1.9 ==>> toplamGNOya eklendi
# 2. iterasyonda             => gno = 2.2 ==>> toplamGNOya eklendi
# 3. iterasyonda             => gno = 3.3 ==>> toplamGNOya eklendi
# 4. iterasyonda             => gno = 3.1 ==>> toplamGNOya eklendi
# 5. iterasyonda             => gno = 1.99 ==>> toplamGNOya eklendi
# 6. iterasyonda             => gno = 4.0 ==>> continue isletildi ve toplamGNOya eklenMEdi
# 7. iterasyonda             => gno = 3.1 ==>> toplamGNOya eklendi
# ...
# gnolarda okunmamis eleman kalmadi => dongu sonlandi

ogrGNOlari

enyuksekGNO, endusukGNO

toplamGNO = 0 # ilk deger verme - initialization
kac_ogrenci = 0
enyuksekGNO = max(ogrGNOlari) 
endusukGNO = min(ogrGNOlari)
for gno in ogrGNOlari:
    if gno == enyuksekGNO or gno == endusukGNO:
        break
    toplamGNO = toplamGNO + gno
    kac_ogrenci += 1
ortalama_gno = toplamGNO / kac_ogrenci 
# kac_ogrenci yerine len(ogrGNOlari) kullanilabilirdi ==> ortalama_gno = toplamGNO / len(ogrGNOlari)
print(f"Öğrencilerin GNO ortalaması: {ortalama_gno:.3f}") # tum ogrencilerin ortalamasi bulunmustur
print(f"{len(ogrGNOlari)} tane ogrenci icinden {kac_ogrenci} ogrencinin notu goz onune alinmistir")

# enyuksekGNO => 4.0, endusukGNO => 1.1
# dongunun ilk iterasyonunda => gno = 1.9 ==>> toplamGNOya eklendi
# 2. iterasyonda             => gno = 2.2 ==>> toplamGNOya eklendi
# 3. iterasyonda             => gno = 3.3 ==>> toplamGNOya eklendi
# 4. iterasyonda             => gno = 3.1 ==>> toplamGNOya eklendi
# 5. iterasyonda             => gno = 1.99 ==>> toplamGNOya eklendi
# 6. iterasyonda             => gno = 4.0 ==>> break isletildi ve dongu kirildigi icin sonlandi

gno == enyuksekGNO or gno == endusukGNO

toplamGNO = 0 # ilk deger verme - initialization
kac_ogrenci = 0
enyuksekGNO = max(ogrGNOlari) 
endusukGNO = min(ogrGNOlari)
for gno in ogrGNOlari:
    if gno == enyuksekGNO or gno == endusukGNO:
        pass
    else:
        toplamGNO = toplamGNO + gno
        kac_ogrenci += 1
ortalama_gno = toplamGNO / kac_ogrenci

toplamGNO = 0 # ilk deger verme - initialization
kac_ogrenci = 0
enyuksekGNO = max(ogrGNOlari) 
endusukGNO = min(ogrGNOlari)
for gno in ogrGNOlari:
    if not(gno == enyuksekGNO or gno == endusukGNO):
        toplamGNO = toplamGNO + gno
        kac_ogrenci += 1
ortalama_gno = toplamGNO / kac_ogrenci

toplamGNO = 0 # ilk deger verme - initialization
kac_ogrenci = 0
enyuksekGNO = max(ogrGNOlari) 
endusukGNO = min(ogrGNOlari)
for gno in ogrGNOlari:
    if gno != enyuksekGNO and gno != endusukGNO:
        toplamGNO = toplamGNO + gno
        kac_ogrenci += 1
ortalama_gno = toplamGNO / kac_ogrenci
# kac_ogrenci yerine len(ogrGNOlari) kullanilabilirdi ==> ortalama_gno = toplamGNO / len(ogrGNOlari)
print(f"Öğrencilerin GNO ortalaması: {ortalama_gno:.3f}") # tum ogrencilerin ortalamasi bulunmustur
print(f"{len(ogrGNOlari)} tane ogrenci icinden {kac_ogrenci} ogrencinin notu goz onune alinmistir")

# asagidaki ifadeler birbiriyle tamamen ayni mantiksal operasyonlardir
not (gno == enyuksekGNO or gno == endusukGNO)
gno != enyuksekGNO and gno != endusukGNO

# Indekslerle verilerin okunmasi
ogrGNOlari = [1.9, 2.2, 3.3]
# ogrenci gnolarinin tumunun indeksleriyle okunmasi

print("For dongusu sonuclari: ")
for indeks in range( len(ogrGNOlari) ):
    print(ogrGNOlari[indeks])

print("For dongusu sonuclari - 2: ")
kac_ogrenci = len(ogrGNOlari)
for indeks in range(kac_ogrenci):
    print(ogrGNOlari[indeks])

print("While dongusu sonuclari: ")
indeks_w = 0 # while dongusunun indeksi (w whiledan geliyor)
# kosul => ogrGNOlari listesindeki tum elemanlara ulasana kadar
#       => 0. indeksten baslayarak, en sondaki elemanin pozitif indeksine kadar (3 tane eleman oldugu icin 2 indeksine kadar)
# en sondaki elemanin pozitif indeksine kadar? => len(ogrGNOlari)-1
# ===>>> en son elemanin indeksi, eleman sayisinin (len(ogrGNOlari)) 1 eksigidir
# kosulumuz: indeks_w, len(ogrGNOlari)-1 sayisindan kucuk ya da bu sayiya esit oldugu surece dongu devam etsin
# kosulumuz ==>> indeks_w <= len(ogrGNOlari)-1
#                indeks_w <= 2
# kosulumuz ==>> indeks_w < len(ogrGNOlari)
#                indeks_w < 3
while indeks_w <= len(ogrGNOlari)-1:
    print(ogrGNOlari[indeks_w])
    indeks_w += 1 # indeks degerini dongu icinde 1 arttiriyoruz !!

print("While dongusu sonuclari (yorumsuz kod): ")
indeks = 0
while indeks < len(ogrGNOlari):
    print(ogrGNOlari[indeks])
    indeks += 1



# RESUL BEYDEN GELEN
# adam asmaca oyunu
while True:
    import random

    turkcesozluk = ["aslında","yükümlülük"]
    ingilizcesozluk = ["indeed","obligation"]

    Lt = []
    Li = []
    C  = []
    Y  = []
    yanlis_sayisi = 0
    kelime = random.choice(ingilizcesozluk) #ingilizcesozluk'ten rastgele bir kelime seçer

    for harf in kelime:        #seçilen kelimedeki harfleri Li listesine ekler
        Li.append(harf)


    cevap = "-" * len(kelime) #seçilen kelimen harf sayısı kadar '-' koyar
    print(cevap)
    for eleman in cevap: #cevap'taki tre 'leri C listesine ekler
            C.append(eleman)
    while True:
        girilenharf = input('lütfen bir harf giriniz: ') #kullanıcıdan bir harf girmesini ister
        if girilenharf not in Li:
            Y.append(girilenharf)
            print(f"yanlış sayısı = {len(Y)}, {3-len(Y)} tane yanlış yapma hakkın kaldı")
            if len(Y) == 3:
                print("bilemedin, tekrar denemek ister misin")
                break
        yenicevap=""
        j=-1
        for k in Li: # Li elemanlarını taradı(taramak için c değişkenini kullandık, girilenharfe eşit olan indexleri verdi
            j+=1

            if k==girilenharf:

                C.insert(j, k) #girilenharf'i C listesinde(cevap için oluşturulan liste) ilgili indexlere göre yerleştirdi
                C.pop(j+1)
        for  m in C:
            yenicevap+=m
        print(yenicevap)

        if C == Li:
            print("tebrikleeeerrr")
            break
           
    devam_mi = input("devam etmek isterseniz E'ye basınız")
    if devam_mi!='E':
        print("tekrar bekleriz")
        break

"""##### **Alıştırma 3**
Kullanıcı tarafından bilgileri sağlanacak olan ve adının ilk harfi 'a' (ya da 'A') olanlar haricindeki çalışanlar için ödeme tutarını hesaplayan bir program yazınız. Programınız çalışanın adını, çalıştığı süreyi ve saat başına kazandığı ücret bilgisini aldıktan sonra çalışana yapılacak ödeme miktarını hesaplayıp kullanıcıya göstermelidir (40 saat üzeri çalışma mesai olarak değerlendirilecek olup mesai saat ücreti normal ücretin 1,5 katı olacaktır.) Programınız, kullanıcı hesaplatmaya devam etmek istediği sürece ücret hesaplamalarına devam etmelidir. Programınız kullanıcı 'devam etmek istiyor musunuz?' sorusuna 'H' ya da 'Hayır' girdiği zaman programınız hesaplamaları durduracaktır.
"""

# ODEME TUTARINI HESAPLAYAN KOD
sure = input("Saat olarak çalışılan süreyi giriniz: ")
sure = float(sure)
saatucreti = input("Saatlik ücret miktarını giriniz: ")
saatucreti = float(saatucreti)

mesai_ici_sure = 40
fazla_mesai_ucret_katsayisi = 1.5

if sure > mesai_ici_sure:
    fazla_mesai_suresi = sure - mesai_ici_sure
    mesai_ucreti = saatucreti * fazla_mesai_ucret_katsayisi
    odeme_miktari = mesai_ici_sure * saatucreti +  fazla_mesai_suresi * mesai_ucreti
else: # sure <= 40 olma durumu
    odeme_miktari = sure * saatucreti

print(f"Alacağınız ödeme tutarı: {odeme_miktari} TL'dir")

print("Ücret Hesaplama Modülüne Hoşgeldiniz")
while True:
    # 1. Kullanıcıdan bilgi alma mödülü
    calisan_ismi = input("Çalışanın adını giriniz: ")
    # girdinin kontrolu yapilacak (a,A? ) # input check
    if calisan_ismi[0] == 'a' or calisan_ismi[0] == 'A':
        print(f"Çalışanın adının ilk harfi a ya da A olduğundan {calisan_ismi} için hesaplama yapılmıyor")
        continue
    
    sure = input("Saat olarak çalışılan süreyi giriniz: ")
    # input check? - girdi kontrolu? - sure bir sayi mi kontrol edilmelidir/
    sure = float(sure)
    saatucreti = input("Saatlik ücret miktarını giriniz: ")
    saatucreti = float(saatucreti)

    # 2. Maas hesaplama modulu
    mesai_ici_sure = 40
    fazla_mesai_ucret_katsayisi = 1.5

    if sure > mesai_ici_sure:
        fazla_mesai_suresi = sure - mesai_ici_sure
        mesai_ucreti = saatucreti * fazla_mesai_ucret_katsayisi
        odeme_miktari = mesai_ici_sure * saatucreti +  fazla_mesai_suresi * mesai_ucreti
    else: # surenin mesai_ici_sure'den kisa olma durumu
        odeme_miktari = sure * saatucreti

    print(f"Alacağınız ödeme tutarı: {odeme_miktari} TL'dir")

    # 3. hesaplamalara devam edilecek mi kismi
    #    sonsuz dongu icinde kullanicidan dongunun bitip bitmedigi bilgisinin alınması
    # bitti bilgisi alindi ise donguden cikan kodu yazalim
    bitti_mi_bilgisi = input("Hesaplamaya devam etmek istiyor musunuz? E ya da H giriniz: ")
    # 'H' ya da 'Hayır' girdiği zaman programınız hesaplamaları durduracaktır.
    if bitti_mi_bilgisi == 'H' or bitti_mi_bilgisi == 'Hayır':
        print("Hesaplama işlemleri sonlandırılmıştır.")
        break

print( dir(str) )

ornek_dize = 'Banka'

print(ornek_dize)

ornek_dize

ornek_dize.lower()

ornek_dize # orjinal degeri degismemistir !!!

# ornek_dize.lower() => (dizelerin lower fonksiyonu) bir string dondurur
# ve orjinal dizeyi degistirmiyor
# => string dondurdugunden direk olarak (fonksiyonun cagrilmasina devamen) indeksleme yapilabilir
ornek_dize.lower()[0]

ornek_dize.lower().startswith('b')

# yukaridaki kod ile ayni islem yapmis olunuyor - tek fark kucuk harf olan versiyonuna bir degisken ile ulasilabilmekte.
ornek_dize_kucuk_harf = ornek_dize.lower()
ornek_dize_kucuk_harf.startswith('b')

# girdinin sayi mi kontrolunun yapilmasi
# girdi olarak 50 yerine 5o girildiginde;
# HATA: ValueError: could not convert string to float: '5o'

# amac: kullanici tarafindan girilen string, bir sayi iceriyor mu?
# hatali girdiler: 12,5   12o  20.5.5   1-2  -12- -12.44-
# hatasiz girdiler: 20  15.5  254.285  -12  -12.44 
# kullanilabilecek string fonksiyonlari: isnumeric, isdigit, isdecimal

# isnumeric fonk.
sayi_ornegi = '20'
sayi_ornegi.isnumeric()

sayi_ornegi = '2o'
sayi_ornegi.isnumeric()
# pozitif tamsayi kontrolunu yapabiliyor (fakat ondalik sayilar?, negatif sayilar?)

sayi_ornegi.isnumeric?
# Signature: sayi_ornegi.isnumeric()
# Docstring: Return True if the string is a numeric string, False otherwise.
# A string is numeric if all characters in the string are numeric and there is at least one character in the string.

sayi_ornegi = '50.5'
sayi_ornegi.isnumeric()

float(sayi_ornegi)

sayi_ornegi.isdigit()

sayi_ornegi.isdecimal()

sayi_ornegi * 3 # carpma islemi stringlerde concatenation olarak calismaktadir.

# ondalik sayiyi belirleyen nokta ya da virgulu, kaldirarak, sayi mi kontrolunu yapabiliriz
sayi_ornegi.replace('.', '')

sayi_ornegi.replace('.', '').isnumeric() # ondalikli sayilari gercekten sayi olarak degerlendiriyor?

sayi_ornegi

float(sayi_ornegi)

sayi_ornegi = '50.5.5'
sayi_ornegi.replace('.', '').isnumeric() # ondalikli sayilari gercekten sayi olarak degerlendiriyor??
# girdinin icinde tek bir ondalik belirteci varsa, girdi bir sayidir, fakat birden fazla ondalik belirteci varsa bu sayi degildir!!
# iki veya daha fazla . varsa, replace hepsini kaldirdigindan isnumeric yanlis olarak True donduruyor

sayi_ornegi.replace('.', '')

# tek bir belirteci kaldiralim (ilk gorulen . isareti kaldiriliyor)
# string icinde varsa noktalardan sadece ilki kaldirilsin
sayi_ornegi.replace('.', '', 1)

# ondalik sayi kontrolu
sayi_ornegi.replace('.', '', 1).isnumeric()

# Negatif sayi kontrolu
sayi_ornegi = '-50.5'
sayi_ornegi.replace('.', '', 1).isnumeric()

# - karakteri numerik olmadigindan sayi olarak gormuyor.
# hatali olarak -50.5 icin False donduruyor.
sayi_ornegi = '-50.5'
sayi_ornegi.replace('.', '', 1)

float(sayi_ornegi) # eksi sayiyi dogru bir sekilde floata cevirebiliyor

float(-19)

sayi_ornegi = '-50'
sayi_ornegi.isnumeric()

sayi_ornegi.replace('-', '')

sayi_ornegi.replace('-', '').isnumeric()

sayi_ornegi = '-5-0'
sayi_ornegi.replace('-', '').isnumeric()

sayi_ornegi = '-5-0'
sayi_ornegi.replace('-', '',1).isnumeric()

sayi_ornegi = '5-0'
sayi_ornegi.replace('-', '',1).isnumeric()
# hatali olarak True donduruyor

# ilk karakter eger - ise o karakteri kaldirip sayi kontrolunun yapilmasi gerekmekte
# ilk karakter eger - degil ise, negatif sayi kontrolu ile ilgili bir islem yapilmasina gerek bulunmamakta
sayi_ornegi[0] == '-'

sayi_ornegi = '-50.5'
print(sayi_ornegi)
if sayi_ornegi[0] == '-':
    # ilk karakter - karakteri oldugu icin replace fonk. 0. indeksteki - karakterini kaldirir
    # 1. indeksten sonrasini dilimleme ile ayni islem yapilmis olur
    print(sayi_ornegi.replace('-', '',1).isnumeric())
    print(sayi_ornegi[1:].isnumeric())
else:
    print(sayi_ornegi.isnumeric())
# NOT: yukaridaki kodda ondalik sayilar kontrolu yapilmamaktadir !!

# kontrol yapilirken orjinal dizenin degistirilmemesi gerekmektedir.
#  ==>> cunku girdi sayi ise, o girdinin floata donusturulmesi gerceklestirilecektir.
#  ==>> orjinal sayi kaybedilirse bunu gerceklestirmek mumkun olmayacaktir.
orjinal_sayi_girdisi = input("sayi giriniz: ")
if orjinal_sayi_girdisi[0] == '-':
    print(orjinal_sayi_girdisi[1:].replace('.', '', 1).isnumeric())
else:
    print(orjinal_sayi_girdisi.replace('.', '', 1).isnumeric())

orjinal_sayi_girdisi = input("sayi giriniz: ")
if orjinal_sayi_girdisi[0] == '-':
    if orjinal_sayi_girdisi[1:].replace('.', '', 1).isnumeric():
        sayi = float(orjinal_sayi_girdisi)
        print(sayi)
    else:
        print("HATALI SAYI GIRDISI")
else:
    if orjinal_sayi_girdisi.replace('.', '', 1).isnumeric():
        sayi = float(orjinal_sayi_girdisi)
        print(sayi)
    else:
        print("HATALI SAYI GIRDISI")

orjinal_sayi_girdisi = input("sayi giriniz: ")
sayi_girdisi_kontrol = orjinal_sayi_girdisi
# negatif sayi kontrolu icin gerekli islem
if sayi_girdisi_kontrol[0] == '-':
    sayi_girdisi_kontrol = sayi_girdisi_kontrol[1:]
# ondalik sayi kontrolu icin gerekli islem
sayi_girdisi_kontrol = sayi_girdisi_kontrol.replace('.', '', 1)
print(f"orjinal: {orjinal_sayi_girdisi}, kontrol islemleri sonrasi: {sayi_girdisi_kontrol}")
# sayi mi?
if sayi_girdisi_kontrol.isnumeric():
    # orjinal girdiyi float'a donusturuyoruz
    sayi = float(orjinal_sayi_girdisi)
    print(sayi)
else:
    print("HATALI SAYI GIRDISI")



print("Ücret Hesaplama Modülüne Hoşgeldiniz")
while True:
    # 1. Kullanıcıdan bilgi alma mödülü
    calisan_ismi = input("Çalışanın adını giriniz: ")
    # girdinin kontrolu yapilacak (a,A? ) # input check
    # girdinin kontrolu kucuk/buyuk harf a ile mi basliyor?
    if calisan_ismi[0] == 'a' or calisan_ismi[0] == 'A':
    # Alternatifler
    #if calisan_ismi.lower()[0] == 'a':
    #if calisan_ismi.upper()[0] == 'A':
    #if calisan_ismi.lower().startswith('a'):
    #if calisan_ismi.upper().startswith('A'):
        print(f"Çalışanın adının ilk harfi a ya da A olduğundan {calisan_ismi} için hesaplama yapılmıyor")
        continue
    
    sure = input("Saat olarak çalışılan süreyi giriniz: ")
    saatucreti = input("Saatlik ücret miktarını giriniz: ")
    # input check? - girdi kontrolu? - sure bir sayi mi kontrol edilmelidir
    # SURE KONTROLU
    sure_kontrol = sure
    saatucret_kontrol = saatucreti
    # negatif sayi kontrolu icin gerekli islem
    if sure_kontrol[0] == '-':
        sure_kontrol = sure_kontrol[1:]
    # ondalik sayi kontrolu icin gerekli islem
    sure_kontrol = sure_kontrol.replace('.', '', 1)
    print(f"orjinal: {sure}, kontrol islemleri sonrasi: {sure_kontrol}")
    # SAAT UCRETI KONTROLU
    if saatucret_kontrol[0] == '-':
        saatucret_kontrol = saatucret_kontrol[1:]
    # ondalik sayi kontrolu icin gerekli islem
    saatucret_kontrol = saatucret_kontrol.replace('.', '', 1)
    print(f"orjinal: {saatucreti}, kontrol islemleri sonrasi: {saatucret_kontrol}")

    # her surenin hem de saat ucretinin sayi olmasi gerekmekte?
    if sure_kontrol.isnumeric() and saatucret_kontrol.isnumeric():
        # orjinal girdiyi float'a donusturuyoruz
        sure = float(sure)
        saatucreti = float(saatucreti)
        # NOT: Sure ve Saat ucreti bilgilerinin NEGATIF olmamasi gerekliliginin de kontrol edilmesi gerekmektedir !!!!
        if sure < 0 or saatucreti < 0:
            print(f"Saat ücreti ve Süre bilgileri pozitif sayı içermelidir. Girilen değerler: {sure} ve {saatucreti}")
            continue # bastan veri girisi yapilsin - Aslinda sadece sure ve saat ucretinin tekrardan girilmesinin saglanmasi gerekir !!
    else:
        print(f"Saat ücreti ve Süre bilgileri sayı içermelidir. Girilen değerler: {sure} ve {saatucreti}")
        continue # bastan veri girisi yapilsin - Aslinda sadece sure ve saat ucretinin tekrardan girilmesinin saglanmasi gerekir !!


    # 2. Maas hesaplama modulu
    mesai_ici_sure = 40
    fazla_mesai_ucret_katsayisi = 1.5

    if sure > mesai_ici_sure:
        fazla_mesai_suresi = sure - mesai_ici_sure
        mesai_ucreti = saatucreti * fazla_mesai_ucret_katsayisi
        odeme_miktari = mesai_ici_sure * saatucreti +  fazla_mesai_suresi * mesai_ucreti
    else: # surenin mesai_ici_sure'den kisa olma durumu
        odeme_miktari = sure * saatucreti

    print(f"Alacağınız ödeme tutarı: {odeme_miktari} TL'dir")

    # 3. hesaplamalara devam edilecek mi kismi
    #    sonsuz dongu icinde kullanicidan dongunun bitip bitmedigi bilgisinin alınması
    # bitti bilgisi alindi ise donguden cikan kodu yazalim
    bitti_mi_bilgisi = input("Hesaplamaya devam etmek istiyor musunuz? Programı sonlandırmak için h/H ya da (h/H)ayır giriniz: ")
    # 'H' ya da 'Hayır' girdiği zaman programınız hesaplamaları durduracaktır.
    if bitti_mi_bilgisi.lower()[0] == 'h' or bitti_mi_bilgisi.lower() == 'hayır':
    # Hasan, Huseyin girildiginde de donguyu sonlandirir !! => if bitti_mi_bilgisi.lower().startswith('h') or bitti_mi_bilgisi.lower().startswith('hayır'):
        print("Hesaplama işlemleri sonlandırılmıştır.")
        break

"""### Dictionaries - Sözlükler

##### Temel Sözlük Veri Yapısı
"""

sayilar = {}
# bos sozluk olusturma

sayilar = dict()

# bos liste
[]
list()
# bos sozluk
{}
dict()

print(sayilar)

type(sayilar)

print( dir(sayilar) ) # print( dir(dict) )

# sozluklerde elemanlar anahtar:deger ikilileridir.
# sozluklerde anahtarlar birbirinde farkli degerler alirlar
# ==>> sozluk icinde ayni anahtara sahip 2 farkli deger bulunamaz !!!!
# sozlukten anahtar ve deger herhangi bir piton nesnesi icerebilir
sayilar = {'a':1, 'b':3, 'c':4, 'a':111}
# 'a' anahtarina karsilik olarak 2 farkli deger girildiginde, bunlardan sadece sonuncusu goz onune aliniyor
# 'a':1 eklendikten sonra => 'a' degerini 111 olarak guncelliyor

print(sayilar)

# sayilar sozlugunu bos bir sozluk olarak olusturduktan sonra, elemanlari tek tek nasil sozluge ekleyebiliriz.
# sozluge eleman ekleme
# sozlukadi[anahtar] = deger -->> anahtar:deger elemanini sozluk icine ekler
sayilar = {}
# 'a':1 elemaninin sozluge eklenmesi
sayilar['a'] = 1
print(sayilar)
# 'b':3 elemaninin sozluge eklenmesi
sayilar['b'] = 3
print(sayilar)
# 'c':4 elemaninin sozluge eklenmesi
sayilar['c'] = 4
print(sayilar)
# 'a':111 elemaninin sozluge eklenmesi??? 'a' anahtari sozlukte oldugundan, 'a' anahtarina karsilik gelen degerin guncellenmesi
sayilar['a'] = 111
print(sayilar)

# sozlukte anahtar ve deger herhangi bir piton nesnesini alabilir

# ogrenci idsi (int) ve ogrencinin genel not ortalamasi (float) ikililerini tutalim
ogrenci_ve_notlari = {5:3.55, 11:2.44, 7:1.44}

print(ogrenci_ve_notlari)

# idsi 11 olan ogrencinin genel not ortalamasi nedir?
ogrenci_ve_notlari[11]

# ogrenci adi (str) ve semester bilgisi (int) tuple () olarak ve ogrencinin genel not ortalamasi (float) ikililerini tutalim
ogrenciler_ve_semester_notlari = {('harun', 1):3.55, ('emel',2):2.44, ('burak',5):2.94}

# tuple:float ikilileri
ogrenciler_ve_semester_notlari[('harun', 1)]

"""###### elemanlara ulasma - (listelerde sifir-bazli indeksleme/dizinleme)

"""

personelgelirleri = {'onur': 100, 'ahmet':50, 'ece':200, 'arzu':50}

personelgelirleri[0]
# HATA: KeyError: 0
# sozluklerde 0-bazli indeksleme yoktur - sira kavrami sozluklerde bulunmamakta
# 0 anahtarina sahip bir eleman araniyor fakat sozlukte 0 anahtarina sahip eleman olmadigindan KeyError: 0 hatasi atiyor

# ahmet'in personel geliri nedir?
personelgelirleri['ahmet'] # 'ahmet' anahtarina sahip elemanin degeri nedir?

# degeri (geliri) 50 olan personelin (personellerin) anahtari (anahtarlari) nedir? Nasil ulasilabilir?
personelgelirleri[50] # 50yi anahtarlar icinde ariyor.

# anahtarlar tekildir (farkli deger almak durumundadir) fakat degerler tekil olmak zorunda degildir

# sözlüğe eleman ekleme (listelerde append)
# sozlukadi[anahtar] = deger # anahtar:deger ikililerini saklayan veri yapisi
# sozlukadi[key] = value # key:value pairs
# personelgelirleri sozlugune 'gokhan':400 elemaninin eklenmesi 
# ya da bu personel sozlukte var ise, yani 'gokhan' anahtarina sahip bir eleman var ise, bu elemanin deger bilgisinin guncellenmesi
personelgelirleri['gokhan'] = 400

print(personelgelirleri)

"""###### sözlük veri yapısının metotları"""

# sözlük veri yapısının metotları
print( dir(personelgelirleri) )

personelgelirleri.keys()

anahtarlar = personelgelirleri.keys()
type(anahtarlar)
# dict_keys listelere benzer bir iterable

list(anahtarlar)

for anahtar in anahtarlar:
    print(anahtar)

# degerleri getirmek
personelgelirleri.values()

degerler_personel = personelgelirleri.values()
type(degerler_personel)

list(degerler_personel)

for deger in degerler_personel:
    print(deger)

for deger in personelgelirleri.values():
    print(deger)

personelgelirleri.items() # dict_items tipinde, liste halinde 2 elemanli demetleri/tuple donduruyor

print(personelgelirleri)

personel   gelir
   onur     100
   ahmet     50
   ..
# tuple => satir => kayit

for eleman in personelgelirleri.items():
    print(eleman)
    print(type(eleman))

for eleman in personelgelirleri.items():
    # eleman tuple'inin icinde 2ser deger bulunmakta (anahtar ve deger ikilisi)
    print(eleman, type(eleman))
    # tuple veri yapisinda 0 bazli indeksleme yapabiliyoruz
    print(eleman[0], eleman[1])

# sozluk elemanlari hep 2 deger icerdiginden, for dongusunde bu degerleri 2 degiskende tutabiliriz
for anahtar, deger in personelgelirleri.items():
    print(anahtar, deger)
    print(f"anahtar degiskeninin tipi: {type(anahtar)}, deger degiskeninin tipi: {type(deger)}")

# listelerde eleman kontrolu
L = [11, 22, 33]

3 in L # in karsilastirma (uyelik kontrol) operatoru
       # sonuc olarak True/False donuyor

22 in L

# sozluklerde eleman kontrolu
'onur': 100 in personelgelirleri # 'onur':100 diye bir piton nesnesi olmadigindan hata veriyor

('onur', 100) in personelgelirleri
# hata vermiyor !!
# cunku ('onur', 100) bir piton nesnesi => tuple 

# sozluk ismini (personelgelirleri) vererek uyelik kontrolu yaptiginizda, anahtarlar icinde var mi diye bakiyor
# False => cunku anahtar(?!!) olarak ('onur',100) tuple nesnesi sozlukte bulunmamakta

'ece' in personelgelirleri
# sadece sozluk ismini vererek uyelik kontrolu yaptiginizda, anahtarlar icinde var mi diye bakiyor

'ece' in personelgelirleri.keys() # 'ece' in personelgelirleri
# 'ece' in dict_keys(['onur', 'ahmet', 'ece', 'gokhan'])

# ('onur', 100) elemani personelgelirleri sozlugumuzde var mi kontrolu yapmak istersek
('onur', 100) in personelgelirleri.items()
# ('onur', 100) in dict_items([('onur', 100), ('ahmet', 50), ('ece', 200), ('arzu', 50), ('gokhan', 400)])

personelgelirleri.items()

# direk personel gelirleri uzerinden for dongusu yaparsak
for eleman in personelgelirleri:
    print(eleman)

# personelgelirleri dongude personelgelirleri.keys() gibi davraniyor
print("keys() fonksiyonu ile okunan elemanlar")
for eleman in personelgelirleri.keys():
    print(eleman)

100 in personelgelirleri.values()
# 100 in dict_values([100, 50, 200, 400])

# anahtar bazli indeksleme - elemanlarin degerlerine anahtarlarla ulasma
for anahtar in personelgelirleri: # personelgelirleri.keys()
    print(anahtar)
    print(personelgelirleri[anahtar])
    # ['onur', 'ahmet', 'ece', 'arzu', 'gokhan']
    # döngünün 1. adımı
    # anahtar = 'onur'
    # personelgelirleri[anahtar] => personelgelirleri['onur'] => 100
    # döngünün 2. adımı
    # anahtar = 'ahmet'
    # personelgelirleri[anahtar] => personelgelirleri['ahmet'] => 50
    # ...
    # döngünün 5. ve son adımı
    # anahtar = 'gokhan'
    # personelgelirleri[anahtar] => personelgelirleri['gokhan'] => 400

"""###### birden fazla degiskene, tuple degerlerinin atanmasi"""

# tek satirda 2 ya da daha fazla degiskene deger atamak icin
birinci, ikinci, ucuncu = 1, 20, 300
#birinci = 1
#ikinci = 20
#ucuncu = 300

print(ikinci, ucuncu)

markettype, stockprice, risk = 'crypto', 130, 0.80
#markettype = 'crypto'
#stockprice = 130
#risk = 0.80

print(risk, stockprice)

market_stock_risk_ornek_tuple = ('crypto', 130, 0.80)
print(market_stock_risk_ornek_tuple)

degisken1, degisken2, degisken3 = market_stock_risk_ornek_tuple
#degisken1, degisken2, degisken3 = ('crypto', 130, 0.80)
#degisken1, degisken2, degisken3 = 'crypto', 130, 0.80
#degisken1 = 'crypto'
#degisken2 = 130
#degisken3 = 0.80

print(degisken2)

# tuple icindeki degerlerin 2.sini bir degiskende tutmak gerekmiyorsa
degisken1, degisken3 = market_stock_risk_ornek_tuple
#degisken1, degisken3 = 'crypto', 130, 0.80 # unpack edilmis hali

# ikinci degeri okuman istemezseniz, _ degiskeninde tutabilirsiniz
degisken1, _, degisken3 = market_stock_risk_ornek_tuple

_ # _ aslinda bir degisken adi fakat kullanimda, ulasmak istenilmeyen degerlerin tutuldugu degisken olarak kullanilir'

print(degisken3)

#anahtar, deger = ('onur', 100)
#anahtar, deger = 'onur', 100
#anahtar = 'onur'
#deger = 100
for anahtar, deger in personelgelirleri.items():
    print(f"Anahtar {anahtar} karsiligindaki deger {deger}")

turkcesozluk = ["aslında","yükümlülük"]
ingilizcesozluk = ["indeed","obligation"]
sozluk={}
sozluk[turkcesozluk[0]]=ingilizcesozluk[0]
print(sozluk)

"""#### Kelime Sayma"""

# kelime sayma => kelime:kac defa gectigi
# 1. bos bir sozluk olusturalim
kelimesayilari = {} # dict()
# sonucta ulasilmak istenen ==>> kelimesayilari => {'veri':5, 'de':44, 've':23, ...}
# sozlukte kelime anahtar olarak, kelimenin kac defa gectigi deger olarak saklanacak

print(kelimesayilari)

len(kelimesayilari) # len(kelimesayilari)

# yeni kelimemiz 'veri'
# bu kelime daha once sozluge eklenmis midir? ==>> sozlukte bu kelime ve gecme sayisi var midir?
# 'veri' kelimesi anahtar olarak sozlukte bulunuyor mu?
'veri' in kelimesayilari # 'veri' in kelimesayilari.keys()

# Kelime sozlugumuzde bulunmuyorsa sozluge kelime:1 ('veri':1) ikilisi ekleniyor.
# -> cunku bu kelimeyle ilk defa karsilasiliyor
# sozluge eleman anahtar:deger ekleme ==>> sozlukadi[anahtar] = deger
kelimesayilari['veri'] = 1

print(kelimesayilari)

# yeni kelimemiz 'analitik'
# bu kelime daha once sozluge eklenmis midir? ==>> sozlukte bu kelime ve gecme sayisi var midir?
'analitik' in kelimesayilari

# Kelime sozlugumuzde bulunmuyorsa sozluge kelime:1 ('analitik':1) ikilisi ekleniyor.
# -> cunku bu kelimeyle ilk defa karsilasiliyor
kelimesayilari['analitik'] = 1

print(kelimesayilari)

# yeni kelimemiz 'madenicilik'
# bu kelime daha once sozluge eklenmis midir? ==>> sozlukte bu kelime ve gecme sayisi var midir?
'madenicilik' in kelimesayilari
# 'madenicilik' in kelimesayilari.keys()

kelimesayilari['madencilik'] = 1
print(kelimesayilari)

# yeni kelimeyi yenikelime degiskeninde tutalim
yenikelime = 'veri'

yenikelime in kelimesayilari
# True donduruyor yani kelime daha once karsilasilan bir kelime

# kelime daha once belgede gecmis bir kelime
# oncelikle bu kelimenin daha once kac defa gectigi bilgisine ulasilmali
kelimesayilari[yenikelime] # daha onceki gecme sayisi

# kelimenin gecme sayisini 1 arttirmamiz gerekiyor
# artik kelimenin gecme sayisi su olmali:
kelimesayilari[yenikelime] + 1

# kelimenin gecme sayisi degerinin guncellenmesi gerekir
kelimesayilari[yenikelime] = kelimesayilari[yenikelime] + 1

print(kelimesayilari)

# TEK BIR KOD BLOGUNDA KONTROLU VE GUNCELLEMEYI yapalim
yenikelime = 'metin'
# 1. kelime sozlukte var mi?
if yenikelime in kelimesayilari:
    # kelime daha once belgede gecmis bir kelime
    kelimesayilari[yenikelime] = kelimesayilari[yenikelime] + 1
else:
    # kelime daha once belgede gecmemis
    # kelimesayilari[yenikelime] = kelimesayilari[yenikelime] + 1
    # kelimesayilari[yenikelime] = 0 + 1
    kelimesayilari[yenikelime] = 1

print(kelimesayilari)

yenikelime = 'veri'
# 1. kelime sozlukte var mi?
if yenikelime in kelimesayilari:
    # kelime daha once belgede gecmis bir kelime
    kelimesayilari[yenikelime] = kelimesayilari[yenikelime] + 1
else:
    # kelime daha once belgede gecmemis
    # kelimesayilari[yenikelime] = kelimesayilari[yenikelime] + 1
    # kelimesayilari[yenikelime] = 0 + 1
    kelimesayilari[yenikelime] = 1

print(kelimesayilari)

yenikelime = 'performans'

# daha once 5 defa karsilasildiysa
# => kelimesayilari[yenikelime] = 5 + 1
# daha once hic karsilasilmadiysa
# => kelimesayilari[yenikelime] = 0 + 1

kelimesayilari[yenikelime] = kelimesayilari[yenikelime] + 1

# kac defa karsilasildi
kelimesayilari[yenikelime]

# kelime sayma yaklasimi
'''
if yenikelime in kelimesayilari:
    # kelime daha once belgede gecmis bir kelime
    kelimesayilari[yenikelime] = kelimesayilari[yenikelime] + 1
else:
    # kelime daha once belgede gecmemis
    # kelimesayilari[yenikelime] = kelimesayilari[yenikelime] + 1
    # kelimesayilari[yenikelime] = 0 + 1
    kelimesayilari[yenikelime] = 1
'''
# tek bir satirda nasil yapabiliriz !

print(kelimesayilari)

# kelime ile daha once karsilasildi mi kontrolunun yapilip, 
# kelime daha once gectiyse, oncesinde kac defa karsilasildigi degeri bulunup getirilsin, 
# gecmediyse de gecme sayisi olarak 0 degerinin getirilmesi
kelimesayilari.get?
# Signature: kelimesayilari.get(key, default=None, /)
# Docstring: Return the value for key if key is in the dictionary, else default.

kelimesayilari.get('veri')

kelimesayilari.get('performans')
# ipython defteri sonuc bastirmadi
# cunku get fonksiyonu ==>> None donduruyor cunku varsayilan/default deger None

print( kelimesayilari.get('performans') )

# kelime sozlugumuzde yoksa None yerine 0 degerini dondursun
kelimesayilari.get('performans', 0)

kelimesayilari.get('veri', 0)

kelimesayilari.get(yenikelime, 0)

print(yenikelime)

# tek bir satirda gerceklestirilirse
kelimesayilari[yenikelime] = kelimesayilari.get(yenikelime, 0) + 1

print(kelimesayilari)

yenikelime = 'dogruluk'
kelimesayilari[yenikelime] = kelimesayilari.get(yenikelime, 0) + 1
print(kelimesayilari)

yenikelime = 'analitik'
kelimesayilari[yenikelime] = kelimesayilari.get(yenikelime, 0) + 1
print(kelimesayilari)

"""#### Alıştırma
Word Counting / Kelime Sayma - Most Frequent 3 words 
- belgede en çok geçen 3 kelime hangileridir ve kaçar defa geçmişlerdir?
"""

belge = "Veri madenciliği, eldeki verilerden üstü kapalı, çok net olmayan, önceden bilinmeyen ancak potansiyel olarak kullanışlı bilginin çıkarılmasıdır. Bu da; kümeleme, veri özetleme, değişikliklerin analizi, sapmaların tespiti gibi belirli sayıda teknik yaklaşımları içerir. Başka bir deyişle, veri madenciliği, verilerin içerisindeki desenlerin, ilişkilerin, değişimlerin, düzensizliklerin, kuralların ve istatistiksel olarak önemli olan yapıların yarı otomatik olarak keşfedilmesidir. Temel olarak veri madenciliği, veri setleri arasındaki desenlerin ya da düzenin, verinin analizi ve yazılım tekniklerinin kullanılmasıyla ilgilidir. Veriler arasındaki ilişkiyi, kuralları ve özellikleri belirlemekten bilgisayar sorumludur. Amaç, daha önceden fark edilmemiş veri desenlerini tespit edebilmektir. Veri madenciliğini istatistiksel bir yöntemler serisi olarak görmek mümkün olabilir. Ancak veri madenciliği, geleneksel istatistikten birkaç yönde farklılık gösterir. Veri madenciliğinde amaç, kolaylıkla mantıksal kurallara ya da görsel sunumlara çevrilebilecek nitel modellerin çıkarılmasıdır. Bu bağlamda, veri madenciliği insan merkezlidir ve bazen insan – bilgisayar arayüzü birleştirilir. Veri madenciliği sahası, istatistik, makine bilgisi, veritabanları ve yüksek performanslı işlem gibi temelleri de içerir."

belge

# 1. kelimelerin kaçar defa geçtiklerini sözlükte toplayacağız
# 2. geçme sayılarına göre sıralama yapacağız

type(belge)

print( dir(belge) )

################################################
##### Metin Ön işleme / Text Preprocessing #####
################################################
# 1.1. ; ve , isaretlerini belgeden yok edelim
# 1.2. . isaretlerini ise bosluk . olarak degistirelim => . sayisi kac cumle olduguna dair yaklasik bir sayi vermis olur.

# 1.1. ; ve , isaretlerini belgeden yok edelim
belge.replace(";", '')
# replace fonksiyonu, ;'leri yok ettikten sonra olusan stringi donduruyor !
# fakat orjinal string degismiyor.

belge.replace(",", '')

# stringler immutable/yerinde degistirilemez veri yapilaridir
# stringlerin replace fonksiyonu orjinal belge uzerinde degisik yapmaz (!!! belge (string) immutable oldugundan)
belge

# 1.1. belge orjinal halinde kalsin. Degisiklik yapilmis halini belge_2 degiskeninde tutalim
belge_2 = belge.replace(';', '')
# !!! orjinali degistirmek isteseydik => belge = belge.replace(";", '')

print(belge_2)

# ikinci bir degisiklik yapiliyorsa, onceki degisikligin yansitildigi string uzerinde degisiklik yapilmasi gerekmektedir
belge_2 = belge_2.replace(',', '')

belge_2

# 1.2. . isaretlerini ise bosluk . olarak degistirelim
belge_2 = belge_2.replace('.', ' .')

belge_2

# NOT: bu degisiklikleri stringler immutable olduklarindan tek bir satirda da yazabilirdik!
belge_2 = belge.replace(';', '').replace(',', '').replace('.', ' .')

# Noktalama isaretlerinin tumu
import string
print(string.punctuation)
print(type(string.punctuation))

# NOT: stringler karakter dizisi oldugundan, noktalama isaretleri stringi uzerinde dongu calistirip isaretleri alabiliriz 
for noktalama_isareti in string.punctuation:
    if noktalama_isareti != '.':
        print(noktalama_isareti)
    else:
        print(f"{noktalama_isareti} noktalama isareti icin degisiklik yapilmayacaktir")

# 1.2.2. belgedeki tum karakterlerin kucuk harf olmasi istenseydi
#belge_2 = belge_2.lower()

# 1.3. on islemden gecirilmis belgeden kelime listesinin cikarilmasi
# kelimelerin bosluk karakterleriyle ayrildigini varsayarak
kelime_listesi = belge_2.split() # bosluk karakterlerine gore belgeyi ayristiriyor
# ==> .split(' '), .split('\t'), ... 
# tek bosluk => ' '
# tab ile olusan bosluk => '    '
# .split fonksiyonu liste halinde kelime dizeleri dondurur
print(kelime_listesi)

type(kelime_listesi)

print(len(kelime_listesi))

# 1. kelimelerin kaçar defa geçtiklerini sözlükte toplayacağız
# kelime listesi üzerinden geçerek (kelimeler üzerinden for dongusu isleterek) kelime sözlüğünü oluşturalım.
# kelime:gecmesayisi => ilk defa karsilasildiysa => sozluk[kelime] = 1 => kelime:1
# ilk olarak => bos bir sozluk olustur
kelime_gecme_sayisi_sozlugu = dict() # {}
# ikinci olarak => kelime listesi uzerinden donguyu gerceklestirerek sayma islemini yapalim
for kelime in kelime_listesi:
    kelime_gecme_sayisi_sozlugu[kelime] = kelime_gecme_sayisi_sozlugu.get(kelime, 0) + 1
    # kelime sozlukte yoksa
       # kelime_gecmesayisi_sozlugu[kelime] = 0 + 1
    # kelime sozlukte varsa
       # kelime_gecmesayisi_sozlugu[kelime] = o ana kadarki gecme sayisi + 1

print(kelime_gecme_sayisi_sozlugu)

# sozlukte anahtar degerler birbirinden farklidir
# => belgedeki gecen birbirinden farkli kelimelerin sayisi, sozlukteki anahtar sayisina esittir
print(len(kelime_gecme_sayisi_sozlugu))

sozlukteki_kelimeler = kelime_gecme_sayisi_sozlugu.keys()
print(len(sozlukteki_kelimeler))

print(sozlukteki_kelimeler)

# tekil gecen kelimeler hangileridir
tekil_kelimeler = set(kelime_listesi) # kelime listesinde farkli kelimeleri dondurur
# sozluklerde anahtarlar coklayamayacagindan set'in icindeki kelimeler ile ayni kelimeleri icerir
# tekil_kelimeler < == > sozlukteki_kelimeler
print(type(tekil_kelimeler))
print(len(tekil_kelimeler))

# belgedeki en çok geçen 3 kelime hangileridir ve kaçar defa geçmişlerdir?
# ==>> Bu soruya cevap vermek icin siralama yapabiliriz.

kelime_gecme_sayisi_sozlugu.sort()
# => sozluklerde sort fonksiyonu bulunmamakta !!!

# anahtar:deger ikilileri
# kelime : gecme sayisi ikilileri
# siralamayi degerlere (yani gecme sayilarina) gore yapmak istiyoruz
# listelerin sort metodu var !
# => sozluklerin items() fonksiyonu list of tuples donduruyor => (dict_items tipinde) liste halinde demetler donduruyor
kelime_sayi_ikilileri_elemanlari = kelime_gecme_sayisi_sozlugu.items()
print(type(kelime_sayi_ikilileri_elemanlari))
print(kelime_sayi_ikilileri_elemanlari)

# dict_items tipindeki verinin liste verisine donusturulmesi
kel_gec_listesi = list(kelime_sayi_ikilileri_elemanlari)
print(kel_gec_listesi)
# => liste ([ ... ]) halinde tuple ( (...) ) elemanlar

kel_gec_listesi.sort()
# listelerin sort fonk. yerinde siralama yapip None donduruyor

print(kel_gec_listesi)
# varsayilan degerde, yani sort fonk. hicbir arguman gondermeden cagirirsak => listede kucukten buyuge dogru siralama yapar
# sort fonk. siralama yaparken, tuple'lari karsilastiriyor.
# siralamayi oncelikle tuple'larin ilk elemanlarina gore yani anahtarlara gore yapiyor.
#   =>(Eger ayni 2 anahtar olabilseydi, bu tuplelarin degerlerine bakarak (2. elemanlarini karsilastirarak) siralayacakti)
# !!! # sort fonk. elemanlari direk kelimelere bakarak siraladi. Fakat amacimiz degerlere gore buyukten kucuge siralamaydi

# buyukten kucuge dogru siralama
kel_gec_listesi.sort(reverse=True)

print(kel_gec_listesi)

# istedigimiz sadece degerlere gore siralama da degil
degerler_listesi = list(kelime_gecme_sayisi_sozlugu.values()) # kelimeleri kaybetmis oluyoruz !!
degerler_listesi.sort(reverse=True)
print(degerler_listesi)

"""##### 1. Sıralama Yaklaşımı - 1
- (anahtar:deger) ikililerini (listesini), (deger:anahtar) ikililerine (listesine) cevirerek ve listelerin sort() fonksiyonunu kullanarak
- orjinal sozlukteki kelime ve kelimenin gecme sayisi ikilileri yerine, gecme sayisi ve kelime ikilileri haline donusturebilirsek, sort fonks. istedigimiz gibi calisir
"""

# anahtar:deger ikililerini (listesini) => deger:anahtar ikililerine (listesi) cevirelim
deger_anahtar_ikilileri = []
for anahtar, deger in kelime_gecme_sayisi_sozlugu.items():
    # anahtar, deger = ('Veri', 4)
    # anahtar = 'Veri'
    # deger = 4
    # ==>> (4, 'Veri')
    deger_anahtar_demeti = (deger, anahtar)
    #deger_anahtar_demeti = (4, 'Veri')
    deger_anahtar_ikilileri.append(deger_anahtar_demeti)

print(deger_anahtar_ikilileri)
print(kelime_gecme_sayisi_sozlugu.items())

# deger_anahtar_ikilileri 'nin elemanlari gecme sayisi ile kelime ikilileri
# artik direk sort yapabiliriz
deger_anahtar_ikilileri.sort(reverse=True) # buyukten kucuge siralama

print(deger_anahtar_ikilileri)

# belgede en cok gecen ilk 3 kelime ve gecme sayisi
deger_anahtar_ikilileri[:3]

# siralanmis olan liste icinden en cok gecen kelimeleri ve gecme sayilari kullaniciya gosterilsin
encokgecen_kac_kelime = 7
print(f"Belgede en çok geçen {encokgecen_kac_kelime} kelime")
print('-----------------------------')
for gecmesayisi, kelime in deger_anahtar_ikilileri[:encokgecen_kac_kelime]:
    print(f"{kelime} kelimesi {gecmesayisi} defa geçmektedir.")

"""##### 2. Sıralama Yaklaşımı - 2 
- sorted yerleşik (built-in) fonksiyonu
"""

#### SORTED fonksiyonu
sorted?

a = [1, 5, 25, 10, 15, 3, 2]
print(a)

sorted(a) # iterable'in elemanlarinin kucukten buyuge olacak sekilde siralanmis listesini donduruyor

a
# sorted fonksiyonu, yerinde degisiklik yapmiyor. 
# ==>> Yeni siralanmis halde bir liste olusturup donduruyor.
# orjinal a listesinde bir degisiklik yapilmamistir

# buyukten kucuge siralamak icin reverse parametresinin kullanimi
sorted(a, reverse=True) # anahtar kelime argumani: fonksiyona reverse parametren True'ya esit olsun denilmis oluyor.

# sozlugu sort etmek istersek
sorted(kelime_gecme_sayisi_sozlugu) # sorted(kelime_gecme_sayisi_sozlugu.keys())
# anahtarlarin sirali halini liste olarak donduruyor
# fakat amacimiz elemanlarin siralanmasi.

print(  sorted(kelime_gecme_sayisi_sozlugu)  )
print(  sorted(kelime_gecme_sayisi_sozlugu.keys())  )
print(  sorted(kelime_gecme_sayisi_sozlugu, reverse=True)  )
print(  sorted(kelime_gecme_sayisi_sozlugu.values(), reverse=True)  )

# amacimiz elemanlarin siralanmasi.
print(kelime_gecme_sayisi_sozlugu.items())

# amacimiz elemanlarin siralanmasi. Elemanlarin sorted fonk. gonderilmesi
print(  sorted(kelime_gecme_sayisi_sozlugu.items(), reverse=True)  )
# => sozluk elemanlarini anahtarlara göre sıraladı
# istediğimiz? => değerlere göre sıralamak

# sozlugun elemanlarinin hepsi 2 öğe iceren birer tuple/demet
# sorted siralamayi oncelikle tuple'larin 1. elemanlarina yani anahtarlara/kelimelere bakip yapiyor.

# sorted fonksiyonunu 2 elemanlara (yani gecme sayilarina) bakarak siralama yapmaya yonlendirmemiz gerekiyor.
# key= ????? sorted fonk. bildirilerek
# A custom key function can be supplied to customize the sort order

# verilen demetin/tuple ikinci elemanini donduren bir fonksiyon
# iki eleman iceren ( ('üstü', 1) ) bir demetin (sözlük öğesi) ikinci öğesini döndürür (anahtar, değer) => değer 
def ikinci_eleman(demet):
    return demet[1]

ornek_demet_1 = ('üstü', 1)
ikinci_eleman(ornek_demet_1)

ornek_demet_2 = ('çıkarılmasıdır', 2)
ikinci_eleman(ornek_demet_2)

# direk demetler karsilastirildiginda  ('üstü', 1) elemani ('çıkarılmasıdır', 2) elemanindan buyuk oluyor
# cunku 'üstü' > 'çıkarılmasıdır'
ornek_demet_1 < ornek_demet_2

# ornek_demet_1 ile ornek_demet_2'yi 2. elemanlarina gore karsilastirisak
ikinci_eleman(ornek_demet_1) < ikinci_eleman(ornek_demet_2)
# ==>> Bu karsilastirmayi sorted fonksiyonun kendisi icinde yapiyor

# sorted fonksiyonunun key parametresine, hangi elemana bakarak siralama yapilacagini belirten fonksiyonu yaziyoruz
# NOT: key parametresine fonksiyonun adini veriyoruz !
# sorted fonk. calisirken < ve ya > karsilastirmasini kendisi yapiyor..
print(  sorted(kelime_gecme_sayisi_sozlugu.items(), key=ikinci_eleman, reverse=True)  )

# en çok geçen 3 kelimeyi ve geçme sayılarını gösterelim

sirali_kelime_gecme = sorted(kelime_gecme_sayisi_sozlugu.items(), key=ikinci_eleman, reverse=True)
print(sirali_kelime_gecme)

# siralanmis olan liste icinden en cok gecen kelimeleri ve gecme sayilari kullaniciya gosterilsin
encokgecen_kac_kelime = 7
print(f"Belgede en çok geçen {encokgecen_kac_kelime} kelime")
print('-----------------------------')
for kelime, gecmesayisi in sirali_kelime_gecme[:encokgecen_kac_kelime]:
    print(f"{kelime} kelimesi {gecmesayisi} defa geçmektedir.")

# derste "ordering dictionary elements by values python" aratarak bulduğumuz site
# https://stackoverflow.com/questions/613183/how-do-i-sort-a-dictionary-by-value
# sitedeki cozumlerden sorted iceren kismi alinirsa
# sorted(x.items(), key=lambda item: item[1])
sirali_kelime_gecme_lambda = sorted(kelime_gecme_sayisi_sozlugu.items(), key=lambda item: item[1], reverse=True)
#                            sorted(kelime_gecme_sayisi_sozlugu.items(), key=ikinci_eleman       , reverse=True)
print(sirali_kelime_gecme_lambda)
# key=lambda item: item[1] ===>> key=lambda demet: demet[1]
# ikinci_eleman ==>> return demet[1]

"""##### 3. Sıralama Yaklaşımı - 3 
- kütüphane kullanımı 
- [collections kütüphanesinin](https://docs.python.org/3/library/collections.html#collections.Counter) Counter nesnesinin kullanımı
"""

# Sadece Counter nesnesini import edelim
from collections import Counter # collections kutuphanesinden sadece Counter nesnesini getirelim
# tum kutuphaneyi getirmek isteseydik => import collections

# nesnenin olusturulmasi
# sayilmasi istenen listeyi gondererek nesneyi olusturuyoruz
cnt = Counter(kelime_listesi)
# 1. kelime sayma ve 2. siralama islemlerini beraber gerceklestiriyor

type(cnt)

print( dir(cnt) )
# sozluklerle ortak islevselligi olan bir veri yapisi

print(cnt)

cnt.most_common?
# Signature: cnt.most_common(n=None)
# Docstring: List the n most common elements and their counts from the most common to the least.  
# If n is None, then list all element counts.

# en cok gecen 3 kelime ve gecme sayisi
cnt.most_common(n=3)

cnt.most_common(n=encokgecen_kac_kelime)

# siralanmis olan liste icinden en cok gecen kelimeleri ve gecme sayilari kullaniciya gosterilsin
encokgecen_kac_kelime = 7
print(f"Belgede en çok geçen {encokgecen_kac_kelime} kelime")
print('-----------------------------')
for kelime, gecmesayisi in cnt.most_common(n=encokgecen_kac_kelime):
    print(f"{kelime} kelimesi {gecmesayisi} defa geçmektedir.")

"""### Tuples (Demetler) and Sets (Kümeler)

#### Tuples (Demetler)
"""

list => mutable sirali []
dict => anahtar:deger  {a:b}
tuple => immutable sirali ()

t = (1, 2, 4, 10, 20, 2, 4, 10, 4)
# NOT: ekleme ya da cikarma yapamiyoruz - immutable

len(t)

# 0-bazli indeksleme - elemanlara ulasim
t[4]

# dilimleme / slicing
t[1:6]

# listelerden farkli, stringlerle benzer olarak
# tuple immutable -> elemanlari degistirilemez.
t[2]

t[2] = 44

t.append(44) # tuple veri yapisinin append fonksiyonu bulunmamakta

# tuple veri yapisinin hangi fonksiyonlari bulunmakta
print( dir(t) )

# count fonk.
# Return number of occurrences of value.
t.count(10)

t.count(4)

t.count(44)

# index(value, start=0, stop=9223372036854775807)
# Return first index of value.
t.index(10) # arguman olarak verilen ogenin ilk bulundugu indeksi dondurur

t.index(10, 4) # 10un 2. defa bulundugu indeksi dondurur

t.sort() # sort fonk. bulunmamakta

# 1. TUPLE veri yapisi, fonk. dondurdugu (1den fazla nesne icin) degerlerde kullaniliyor
x = 0.125

type(x)

x.as_integer_ratio()
# fonksiyon 1den fazla nesne/deger dondurdugunde bunu bir tuple olarak donduruyor!

paypayda = x.as_integer_ratio()

print(type(paypayda))
print(paypayda)

paypayda[1]

# fonk. 2 degeri bir tuple icinde donduruyor
pay, payda = x.as_integer_ratio()
#pay, payda = (1, 8)
#pay, payda = 1, 8  # unpack
#pay = 1
#payda = 8

print(payda)

### 4 tane deger donduren bir fonksiyon tanimlayalim
def alistirma_fonk():
    return 1,2,5,10.5

alistirma_fonk()

dondurulen_degerler = alistirma_fonk()
# dondurulen_degerler = (1, 2, 5, 10.5)
print(type(dondurulen_degerler))
print(dondurulen_degerler)

len(dondurulen_degerler)

dondurulen_degerler[2]

d1, d2, d3, d4 = alistirma_fonk()
#d1, d2, d3, d4 = (1, 2, 5, 10.5)
#d1, d2, d3, d4 = 1, 2, 5, 10.5
print(d1, d4)
print(type(d1), type(d4))

# 4 deger donduren bir fonkiyonun degerleri 3 degiskende tutulmak istenirse
d1, d2, d3 = alistirma_fonk()

# 2. sozluk elemanlarinin liste halinde tuple biciminde ikililer olarak dondurulmesi 
s1 = {'a':1, 'as':5}
s1.items()

"""#### Sets (Kümeler)"""

# unordered
ornek_kume_1 = {1, 5, 8}
print(type(ornek_kume_1))
print(ornek_kume_1)

# bos kume 
yanlis_bos_kume = {} # => bos bir kume degil, bos bir sozluk olusturur
print(type(yanlis_bos_kume))

bos_kume = set()
print(type(bos_kume))
print(len(bos_kume))

liste_ornek = [1,2,5,1,1,1,2,6]
print(liste_ornek)
print(len(liste_ornek))

# ornek liste, kumeye donusturulurse
kume_liste_ornek = set(liste_ornek) # elemanlarin hepsi unique (birbirinden farkli) - tekil değerleri
print(kume_liste_ornek)

# kumeler / set unordered / sirali degiller
kume_ornek = set([1,1,4,4,2,2])
print(kume_ornek)

# kumelerde indeksleme yok (not subscriptable)
kume_ornek[0]

kume_ornek[1] = 5

print( dir(kume_ornek) )

# belgede geçen (tekil) kelimeler nelerdir
print(kelime_listesi)
print(len(kelime_listesi))

# vocab => sozluk kelimeleri
vocabulary = set(kelime_listesi)
print(vocabulary)
print(len(vocabulary))

# sira kavrami olmadigi icin ekleme yaparken basa/sona/ortaya ekleme secenegi bulunmuyor
# Yeni eleman ekleme metodu - .add()
vocabulary.add("halkbank")

print(vocabulary)
print(len(vocabulary))

vocabulary.add("sahası")
print(vocabulary)
print(len(vocabulary))

print?

for kelime in vocabulary:
    print(kelime, end=', ') # print her calistiginda default olarak end parametresi '\n' yeni satir karakterini alir.
    # bu sebeple her calistiginda bilgiyi ekrana bastiktan sonra bir alt satira gecer

# Kume fonksiyonlari
k = {1, 3, 5, 101, 105, 7, 9}
s = {100, 101, 102, 105, 110}

# birleşim kümesi
k.union(s) # sonucta olusan birlesim kumesi donduruluyor

k_s_birlesim = k.union(s)
print(k_s_birlesim)
print(k, s)

# Kesişim kümesi
k.intersection(s) # sonucta olusan Kesişim kumesi donduruluyor

# s kumesi, k kumesinin bir alt kumesi midir?
s.issubset(k)

m = {101, 9}

# Alt küme midir? 
# m kumesi, k kumesinin alt kumesi midir? 
# m nin elemanlari k nin elemanlari arasinda var midir?
m.issubset(k)

k.issubset(m)

k.issuperset(m)

# Kume ve Sozluk farki
kume_ornegi_ = {1,2,4,5}
sozluk_ornegi_ = {1:'bir', 2:'iki'}
print(kume_ornegi_)
print(sozluk_ornegi_)

"""#### Alıştırma (Pekiştirme) - Sözlükler
Kullanıcıdan öğrencilerin isimlerini ve dönem sonu not ortalamalarını alarak bunları anahtar/değer çiftleri olarak bir sözlükte tutan bir program yazınız. Programınız, 10 öğrencinin kayıtlarını saklamalı ve en yüksek not ortalamasına sahip 5 öğrencinin isimlerini ve notlarını, not ortalamalarının azalan sırasına göre kullanıcıya göstermelidir
"""

# 10 öğrencinin kayıtlarını saklamalı
ogr_not_ortalamalari = {}
for i in range(5):
    ogr_adi = input("Öğrencinin ismini giriniz: ")
    ogr_notu = input("Öğrencinin notunu giriniz: ")
    ogr_notu = float(ogr_notu)
    ogr_not_ortalamalari[ogr_adi] = ogr_notu # ogr_adi:ogr_notu ikilisini sozluge ekliyoruz

# en yüksek not ortalamasına sahip 5 öğrencinin isimlerini ve notlarını, not ortalamalarının azalan sırasına göre
sirali_notlar = sorted(ogr_not_ortalamalari.items(), key=lambda item: item[1], reverse=True)
for ogr_adi, notu in sirali_notlar[:3]:
    print(f"{ogr_adi} isimli öğrencinin notu {notu}'dir")

# from ERDiNC SAGLAMLI
sinif = {}
islem = ("ÖĞRENCİ BİLGİ/NOT GİRİŞ/TAKİP  \n" 
                "=====================================\n"
                "1. Öğrenci Bilgi Girisi Yap\n"
                "2. En İyi 5 Öğrenci ve Not Ortalamalarını Yazdir\n"
                "3. Çıkış\n"
                "=====================================\n")
while True: 
  islem_kodu = input(islem).lower().strip()
  if islem_kodu == '1':
    ogrenci_sayisi = int(input("Bilgi girişi yapacağınız öğrenci sayısını giriniz : "))
    for i in range(ogrenci_sayisi):
      k = input("Öğrenci İsmi: ")
      v = input("Dönem Not Ortalaması: ")
      sinif.update({k:v})
    print("Girişler tamamlanmıştır. Ana Menüye Dönülüyor..")
    print("-----------------------------------------------")
  elif islem_kodu == '2':
    sirali_notlar = sorted(sinif.items(), key=lambda item: item[1], reverse=True)
    for k,v  in sirali_notlar[:5]:
      print(f"{k} isimli öğrencinin notu {v}'dir")
    print("Listeleme tamamlandı, Ana Menüye Dönülüyor...")
    print("----------------------")
      
  elif islem_kodu == '3':
        print("ÇIKIŞ YAPILMIŞTIR.")
        print("----------------------")
        break

"""### Functions / Fonksiyonlar"""

# Girdi alip (opsiyonel olarak) Cikti ureten kod bloklari
# 1. yerlesik fonksiyonlar
#    - input, print, len, ...
# 2. kullanici tarafindan tanimlanmis fonk
#    2.1. def ile tanimlananlar
#    2.2. anonim - lambda fonksiyonlari

"""##### Fonksiyon Tanımlama"""

# Fonksiyonlar
def fonksiyon_adi(<parametreler>): # parametreler opsiyonel, yani parametresi olmayan bir fonk. tanımlayabiliriz
    '''
       Docstring: fonksiyonun açıklaması -- opsiyonel
    '''
    <fonksiyon kodu/mantığı/algoritma>
    return <degerler> # opsiyonel - fonk. return etmek zorunlulugu bulunmamaktadir 
                                    # => None donuyormus gibi calisir eger dondurdugu bir deger yoksa

###   Fonksiyon tanımlanması / definition   ###
###############################################
# x ve y degerini alip 2x^2+4y polinom degerini hesaplayan ve sonucu donduren bir fonksiyon
###############################################
def polinom_fonksiyonu(x, y):
    '''
        x ve y değişken/parametre değerlerine göre (2x^2+4y) polinom sonucunu hesaplar
        Sonuc hesapladıktan sonra, kullanıcıya girdi (parametre degerlerini) ve çıktıyı (polinom sonucunu) gösterir. 
        Son olarak hesaplanan bu sonucu cagiran yere/koda geri döner (return eder)
    '''
    polinom_sonucu = 2 * x**2 + 4*y
    print(f"x:{x} ve y:{y} girdileri ile hesaplanan (2x^2+4y) polinomunun sonucu: {polinom_sonucu}")
    return polinom_sonucu

polinom_fonksiyonu?

sum?

###   Fonksiyonun çağırılması - call   ###
##########################################
# fonksiyon_adi(argumanlar)
polinom_fonksiyonu(3, 6)

girdi_x = input("Birinci sayiyi giriniz: ")
girdi_x = float(girdi_x)
girdi_y = input("Ikinci sayiyi giriniz: ")
girdi_y = float(girdi_y)
polinom_fonksiyonu(girdi_x, girdi_y)

a1 = 4
a2 = 3
_sonuc = polinom_fonksiyonu(a1, a2)
#_sonuc = 44
print(_sonuc)

"""##### Return Degerleri"""

def ortalama_hesaplama(sayilistesi):
    '''
        sayilistesi parametresi liste veri yapisinda olmalidir
    '''
    ortalama = sum(sayilistesi) / len(sayilistesi)
    return ortalama

gnolar = [1.2, 2.2, 3.3, 2.5, 3.3]
# Fonksiyon çağırılıyor
ortalama_gno = ortalama_hesaplama(gnolar)
#ortalama_gno = 2.5
print(f"GNOların ortalaması: {ortalama_gno}")

# Fonksiyon çağırıldığında (call)
# >> ortalama_gno = ortalama_hesaplama(gnolar)  ???
# arguman => gnolar
# parametre => sayilistesi
# ortalama_gno => fonksiyon tarafindan dondurulen degerin tutulacagi degisken adi
# ortalama_hesaplama => fonksiyonun adi
0. ortalama_hesaplama degiskeni bir fonksiyon gosteriyor mu? Gosteriyorsa Fonksiyonun içine girilir
1. Parametrelerin atanması => sayilistesi = gnolar # ==>> sayilistesi = [1.2, 2.2, 3.3, 2.5, 3.3]
2. Fonksiyon algoritması/mantığı/kodları çalıştırılır => 
      - ortalama hesaplaması yapılır
      - ortalama = 2.5 bulunması
3. return değeri var ise, yani fonksiyon bir değer döndüyorsa (donen deger yoksa return işlemi, None döndürüyor)
      - bu değer fonksiyon tarafından, fonksiyonun çağırıldığı yere döndürülür
        - örneğimizde fonksiyon ortalama değişkeninin gösterdiği yerdeki 2.5 sayısını döndürür
4. Fonksiyonun çağırıldığı yerde, fonksiyonun çağrılma kısmındaki fonksiyon ifadesi ( ortalama_hesaplama(gnolar) ) dönen değer ile ( 2.5 ) değiştirilir
      - ortalama_gno = ortalama_hesaplama(gnolar) kısımda ortalama_hesaplama(gnolar), dönen 2.5 ile değiştirilir
5. Atama işlemi tamamlanır
      - ortalama_gno = 2.5

# 1 tane değerden fazla deger donduren fonk. (tuple/demet olarak)
# 1den fazla deger dondurulurken degerler birbirinden virgul ile ayrilir
def minmax_degerleri_bul(sayilistesi):
    minsayi = min(sayilistesi)
    maxsayi = max(sayilistesi)
    return minsayi, maxsayi  # ===>>> (minsayi, maxsayi) => tuple/demet

gnolar = [1.2, 2.2, 3.3, 2.5, 3.3]
minmax_gnolar = minmax_degerleri_bul(gnolar)
# minmax_gnolar = (1.2, 3.3)
print(minmax_gnolar)
print(type(minmax_gnolar))

minmax_gnolar[0]

minmax_gnolar[1]

minmax_gnolar[2]

# tuple veri yapisi immutable / degistirilemez
minmax_gnolar[0] = 1.3

"""#### Fonksiyon Argüman ve Parametreleri

###### 1. Required Positional Argument (positional arguments / konumsal argüman) => gerekli konumsal arguman
"""

# isim ve yas parametreleri "gerekli konumsal arguman" sekliyle tanimlanmislardir
def bilgilendirme(isim, yas):
    print(f"{isim} isimli kişinin yaşı {yas}'tir")
# return ifadesi ile döndürdüğü bir değer olmadığı için None döndürür (bir değer döndürmez - void fonk.)

bilgilendirme('cem', 25)
# isim = 'cem'
# yas = 25
# ...

# gerekli arguman?
bilgilendirme('cem')
 # yas parametresi gerekli bir arguman oldugundan, bir deger gonderilmesi zorunluluktur

bilgilendirme('cem', 25, 10000)
# gerekli olan arguman sayisindan fazla arguman gonderilemez

# konumsal?
bilgilendirme(25, 'cem') # gereklilik yerine getirildi
# !!!! Kod çalışıyor -> syntax hatası vermiyor
# fakat parametrelere gönderilen argümanların sırası yanlış => konumlari yanlis
# semantic error / mantiksal hata  ===>>>> program hata atmiyor fakat istenilen sekilde calismiyor

# bilgilendirme fonksiyonu isim olarak => str tipinde veri beklemekte
#                           yas olarak => float tipinde veri beklemekte

# kullanıcının istenilmeyen tipte argüman göndermesine engel olunamamaktadır !
# fakat bu konuda kullanıcıyı bilgilendirebilirsiniz;
#   1. docstring içinde bu bilgiyi vererek
#   2. def bilgilendirme(isim: str, yas: float):

"""###### 2. Default Argument => varsayilan arguman"""

# 2. Default Argument => varsayilan arguman
# yas varsayilan arguman
def bilgilendirme_varsayilan_deger_alan(isim, yas=18):
    print(f"{isim} isimli kişinin yaşı {yas}'tir")

bilgilendirme('cem', 25)

bilgilendirme('cem')

bilgilendirme_varsayilan_deger_alan('cem')
# isim = 'cem'
# yas? => yas = 18

bilgilendirme_varsayilan_deger_alan('cem', 27)
# isim = 'cem'
# yas = 27

# tum parametreler => varsayilan olarak tanimlanabilir
def bilgilendirme_hepsi_varsayilan(isim='Belirtilmemiş', yas=18):
    print(f"{isim} isimli kişinin yaşı {yas}'tir")

bilgilendirme_hepsi_varsayilan()
# isim? ==> isim='Belirtilmemiş'
# yas? ==>  yas=18

bilgilendirme_hepsi_varsayilan('onur')
# isim='onur'
# yas? ==> yas=18

# mantik hata => ilk parametre isim/string bekliyor fakat tip kontrolu olmadigindan syntax hatasi atmiyor 
bilgilendirme_hepsi_varsayilan(20)
# NOT: 20nin isme degil de yas parametresine gonderilmesini nasil saglayabiliriz??
#      yani isim parametresi default degerinde kalsin fakat yas parametresi 20 degerini alsin???

# gelir bilgisi de alinmak istenirse
def bilgilendirme_varsayilan_gelir(isim='Belirtilmemiş', yas=18, gelir):
    print(f"{isim} isimli kişi {yas} yaşındadır ve {gelir} miktar geliri vardır")
# non-default argument ==>> gelir
# default argument ==>> isim ve yas

# HATA 2
def bilgilendirme_varsayilan_diger(isim='Belirtilmemiş', gelir, yas=18):
    print(f"{isim} isimli kişi {yas} yaşındadır ve {gelir} miktar geliri vardır")

# DOGRU BIR SEKILDE FONK. TANIMLAMASI YAPMAK ICIN
# 1. gelir parametresinin default parametre olarak tanımlanması (gelir=5000) gerekir
def bilgilendirme_varsayilan_diger(isim='Belirtilmemiş', yas=18, gelir=5000):
    print(f"{isim} isimli kişi {yas} yaşındadır ve {gelir} miktar geliri vardır")

# 2. gelir parametresinin default parametre olarak tanımlanan tüm parametrelerden önce tanımlanması gerekir
# yani required positional parametre olacaksa, o parametrelerin default olanlardan once tanimlanmasi gerekmektedir
def bilgilendirme_varsayilan_diger_def_nondef(gelir, isim='Belirtilmemiş', yas=18):
    print(f"{isim} isimli kişi {yas} yaşındadır ve {gelir} miktar geliri vardır")

"""###### 3. Keyword Argument (Anahtar Argüman)"""

bilgilendirme('cem', 25)

# 2. Keyword Argument => anahtar kelime argumanlari
# fonk. cagrilirken kullaniyoruz
bilgilendirme(isim='cem', yas=25)

# anahtar kelime argümanı kullanarak, argümanları gönderirken sırasını dilediğiniz şekilde belirleyebilirsiniz
bilgilendirme(yas=25, isim='cem')

# bilgilendirme_hepsi_varsayilan(20)
# NOT: 20nin isme degil de yas parametresine gonderilmesini nasil saglayabiliriz??
#      yani isim parametresi default degerinde kalsin fakat yas parametresi 20 degerini alsin???
bilgilendirme_hepsi_varsayilan(yas=20)

# değişkenleri argüman olarak kullanabilirsiniz
# musteri bilgileri demeti/tupleı müşterilerin İsim, Yas ve Gelir bilgilerini iceriyor
# yani Tuple'in 0. indeksinde isim, 1. indeksinde yas ve 2. indeksinde Gelir bilgisi bulunmaktadir
musteri_bilgileri = ('selin', 22, 12000)

bilgilendirme(yas=musteri_bilgileri[1], isim=musteri_bilgileri[0])

bilgilendirme_varsayilan_diger_def_nondef(musteri_bilgileri[2], yas=musteri_bilgileri[1], isim=musteri_bilgileri[0])

# NOT: keyword argument sonrasi positional argument kullanilamamaktadir
bilgilendirme_varsayilan_diger_def_nondef(yas=musteri_bilgileri[1], musteri_bilgileri[2])
# positional argument ==>> gelir yani musteri_bilgileri[2]
# keyword argument ==>> yas=musteri_bilgileri[1]

bilgilendirme('cem', yas=25)
# positional/konumsal arguman kullanildiktan sonra keyword/anahtar arguman kullanabilmekte.

# NOT: anahtar arguman kullanildiktan sonraki tum argumanlar keyword/anahtar arguman olmak durumundadir.

"""#### Fonksiyon parametrelerinin immutable/mutable olması"""

def ekleme_yap_orjinal( veri ):
    veri = veri + (400, 500, 600)
    return veri

def ekleme_yap( veri ):
    # degisiklik/ekleme yapilmadan onceki parametre degiskenindeki (veri) deger bilgisi
    print(veri)
    print(type(veri))
    print( id(veri) )
    veri += (400, 500, 600)  # veri = veri + (400, 500, 600)
    # degisiklik/ekleme yapildiktan sonrasi parametre (veri) degiskenindeki bilgiler
    print("Fonksiyon içinde ekleme yapıldıktan sonrasındaki veri bilgisi")
    print(veri)
    print(type(veri))
    print( id(veri) )
    # ve ekleme yapilan veri parametresinin degerinin dondurulmesi
    return veri

demet_tuple_mut_imm = (1,2,3) # tuple => immutable / degistirilemez
liste_mut_imm = [40, 50, 60]  # list  => mutable / degistirilebilir

print(demet_tuple_mut_imm)
print( id(demet_tuple_mut_imm) )
#########
print(liste_mut_imm)
print( id(liste_mut_imm) )

# 1. Tuple/Demet => immutable / degistirilemez
print("Fonksiyonun çağrıldı")
fonk_demet_dond_deger = ekleme_yap(demet_tuple_mut_imm)
# veri = demet_tuple_mut_imm ===>>> veri = (1,2,3) !!! demet_tuple_mut_imm degiskeninin gosterdigi
print("Fonksiyonun çalışması tamamlandı")
print("Fonksiyonun döndürdüğü nesnenin bilgisi:")
print(fonk_demet_dond_deger)
print(type(fonk_demet_dond_deger))
print( id(fonk_demet_dond_deger) )

print(demet_tuple_mut_imm)
print( id(demet_tuple_mut_imm) )
# arguman olarak gonderdigimiz orjinal tuple (demet_tuple_mut_imm) DEĞİŞMEDİ !!! Fonksiyon içinde orjinal tuple değiştirilmedi

# 2. List => mutable / degistirilebilir
print("Fonksiyonun çağrıldı")
fonk_liste_dond_deger = ekleme_yap(liste_mut_imm)
# veri = liste_mut_imm ===>>> veri = [40, 50, 60] !!! liste_mut_imm degiskeninin gosterdigi
print("Fonksiyonun çalışması tamamlandı")
print("Fonksiyonun döndürdüğü nesnenin bilgisi:")
print(fonk_liste_dond_deger)
print(type(fonk_liste_dond_deger))
print( id(fonk_liste_dond_deger) )

print(liste_mut_imm)
print(id(liste_mut_imm))
# arguman olarak gonderdigimiz orjinal liste (liste_mut_imm) DEĞİŞTİ

"""##### FONKSIYON - ALISTIRMA
Çalışılan süreyi **sure** ve saat ücretini **saat_ucreti** parametre isimleriyle 2 parametre olarak alan ve ödeme miktarini hesaplayıp kullanıcıya döndüren **odeme_miktari_hesaplama** isminde bir fonksiyon yaziniz. (40 saat üzeri çalışma mesai olarak değerlendirilecek olup mesai saat ücreti normal ücretin 1,5 katı olacaktır.)
"""

def odeme_miktari_hesaplama(sure, saat_ucreti):
    if sure > 40:
        odeme_miktari = 40 * saat_ucreti + (sure - 40) * saat_ucreti * 1.5
    else:
        odeme_miktari = sure * saat_ucreti
    return odeme_miktari

odeme_miktari_hesaplama(60, 10)

odeme_miktari_hesaplama(55, 12.5)

def odeme_miktari_hesaplama_v2(sure, saat_ucreti):
    mesai_suresi = 40
    fazla_mesai_ucret_katsayisi = 1.5
    if sure > mesai_suresi:
        odeme_miktari = mesai_suresi * saat_ucreti + (sure - mesai_suresi) * saat_ucreti * fazla_mesai_ucret_katsayisi
    else:
        odeme_miktari = sure * saat_ucreti
    return odeme_miktari

odeme_miktari_hesaplama_v2(60, 10)

def odeme_miktari_hesaplama_vSON(sure, saat_ucreti, mesai_suresi=40, fazla_mesai_ucret_katsayisi=1.5):
    if sure > mesai_suresi:
        odeme_miktari = mesai_suresi * saat_ucreti + (sure - mesai_suresi) * saat_ucreti * fazla_mesai_ucret_katsayisi
    else:
        odeme_miktari = sure * saat_ucreti
    return odeme_miktari

odeme_miktari_hesaplama_vSON(60, 10)

odeme_miktari_hesaplama_vSON(60, 10, 45)

odeme_miktari_hesaplama_vSON(60, 10, 45, 1.68)

"""# Veri Analitiği
- [Veri Bilimi giriş kitabı](https://jakevdp.github.io/PythonDataScienceHandbook/)
- Numpy kütüphanesi
- [Mathematics for Machine Learning Kitabı](https://mml-book.github.io/book/mml-book.pdf) 
- Doğrusal Cebir
  - [Doğrusal Cebir Videoları](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)
- Regresyon
- İstatistik
- Görselleştirme
- Pandas kütüphanesi
    - Veri Analizi

"""



"""## Pandas Kütüphanesi
- DataFrame (2 boyutlu - matris)
- Series (1 boyutlu - vektor)
"""

import numpy as np
import pandas as pd

np.pi # numpy modulunun attribute/ozelligi

# pi sayisinin karekokunun bulunmasi (square root - sqrt)
np.sqrt(np.pi) # numpy modulunun metodu
# np.mean(...)
# np.std(...)

veri_baglantisi = "https://raw.githubusercontent.com/rashida048/Datasets/master/fifa.csv"
# absolute/full path => dosyanin yolu => nerede bulundugunun uzantisi
# df => DataFrame nesnesi
df_fifa = pd.read_csv(veri_baglantisi)

type(df_fifa)

# boyutlari ?
df_fifa.shape # (satir sayisi, sutun sayisi)

type(df_fifa.shape) # boyutlar ozelligi satir ve sutun sayilarini iceren bir tuple nesnesi

df_fifa.shape[0] # kac tane satir var => tuple nesnesinin indekslenmesi

# DataFrame'in metodlari
df_fifa.head() # ilk 5 satir veriyi getirir
# satir ve sutun isimleri/etiketleri(labels)
# satir ve sutun indeksleri (0-bazli)

df_fifa.tail(3)

df_fifa.columns # sutunlarin isim/etiket indeksleri
# column labels

type(df_fifa.columns)

df_fifa.index

# indeks isimleri/etiketleri(label) direk indeks sutunundan okunursa (0. indeksteki sutun)
df_fifa = pd.read_csv(veri_baglantisi, index_col=0)
#index_col: int, str, sequence of int / str, or False, optional, default None
# Column(s) to use as the row labels of the DataFrame, either given as string name or column index
# int olarak arguman verilirse (0) 0-bazli indeksi vermis oluyoruz, str olarak arguman verilirse ('endeks') o sutun ismindeki sutundaki degerleri indeksler olarak kulllaniyoruz
# indeks sutununun ismi olmadigindan, 0-bazli indeksini kullaniyoruz

df_fifa.shape
# artik 80 tane sutun var (81 yerine) ==>> ilk sutunu indeks olarak kullandi

df_fifa.columns

df_fifa.index

"""#### Indeksleme/Dizinleme ve Dilimleme
Veri yapısındaki değerlere ulaşma
"""

# pandas indekslemede iki yaklasim kullanabiliriz
# 1. satir/sutun isimleriyle/etiketleriyle (label) (.loc)
# 2. 0-bazli indekslemeyle (.iloc)

# NOT: yukaridaki ornekte satırlar için, indeks etiketleri ile 0-bazli indeksler ayni
# pandas, etiket indeksleme mi, yoksa 0-bazli indeksleme mi oldugunu .loc ve .iloc ile ayirt ediyor

# 1. satir/sutun isimleriyle/etiketleriyle (label) (.loc)
print(df_fifa.index) # satirlarin isimleri/etiketleri
print(df_fifa.columns) # sutunlarin isimleri/etiketleri

# 100 etiketli/isimli/label satirda bulunan oyuncunun tum bilgilerini (sutunlarini) getirelim
# iki boyutlu indekleme ile
df_fifa.loc[100, :]
# tek bir satirin tum bilgilerini/sutunlarini getirir
# 2 boyutlu olan DataFrame'den (tek bir futbolcu satiri sectigimiz icin) tek boyutlu olan bir Series dondurdu

oyuncu_100_verisi = df_fifa.loc[100, :]
type(oyuncu_100_verisi)
# DataFrame'den (2 boyutlu-matris), tek bir satir ya da tek bir sutun bilgisi alinirsa, Series (1 boyutlu-vektör) veri yapisinda bir deger dondurulur

# 100 ve 103 etiketli/isimli/label satirlar arasinda bulunan (ve 103 etiketli satir da dahil olmak uzere) oyuncularin tum bilgilerini getirelim
df_fifa.loc[100:103, :]
 # !!! 0 bazli indekslemeden farkli olarak sagdaki etiket dahil okunuyor/getiriliyor !!!

# tum oyuncularin (sadece) long_name bilgilerini getirelim
# tek bir sutun bilgisinin tum satirlar icin okunmasi
# NOT: satir isimleri INTEGER, sutun isimleri ise STRING
df_fifa.loc[:, 'long_name']
# sutunda (tek bir sutun icin) indeksleme yapildigindan Series veri yapisinda bir vektor donduruyor

type(df_fifa.loc[:, 'long_name'])

oyuncularin_isimleri = df_fifa.loc[:, 'long_name']
print(type(oyuncularin_isimleri))

oyuncularin_yaslari = df_fifa.loc[:, 'age']
print(type(oyuncularin_yaslari))

# Hucredeki bir degerin okunmasi - bir satirin, bir sutundaki degeri
# satir ve sutunda ayni anda indeksleme
df_fifa.loc[100, 'long_name']

# deger donduruyor - dondurulen deger ise bir string
type(df_fifa.loc[100, 'long_name'])

# deger donduruyor - dondurulen deger ise bir integer
type(df_fifa.loc[100, 'age'])

# iki boyutta dilimleme/slicing
# tum oyuncularin long_name ile weight_kg (dahil) sutunlarinin arasindaki tum bilgilerini/sutunlari getirelim
df_fifa.loc[:, 'long_name':'weight_kg']

type(df_fifa.loc[:, 'long_name':'weight_kg'])

# satir etiketleri/isimleri 100-103 (103 dahil) arasindaki oyuncular icin long_name ile weight_kg (dahil) sutunlarinin arasindaki tum bilgilerini getirelim
df_fifa.loc[100:103, 'long_name':'weight_kg']
# select long_name,	age, dob, height_cm, weight_kg
# from df_fifa
# where indeks IN (100,101,102,103)

# 100 etiketli/isimli satirdaki oyuncunun boyunu getirmek icin
df_fifa.loc[100,'height_cm']

# 100 etiketli/isimli satirdaki oyuncunun sadece yaş ve kilo bilgisini getirmek icin
df_fifa.loc[100, 'age':'weight_kg']
# yas ile kilo sutunlari arasindaki tum sutun bilgilerini getiriyor..

# 100 etiketli/isimli satirdaki oyuncunun sadece yaş ve kilo bilgisini getirmek icin
df_fifa.loc[100, ['age', 'weight_kg']]
# birden fazla ve ardisik olmayan sutunlardaki/satirlardaki veriyi getirmek icin istenilen sutun etiketlerini bir liste halinde yaziyoruz.

# 100, 103 ve 125 etiketli/isimli satirlardaki oyuncularin isim (long_name), yaş (age), boy (height_cm) ve kilo (weight_kg) bilgisini getirmek icin
df_fifa.loc[ [100,103,125], ['long_name', 'age', 'height_cm', 'weight_kg'] ]

# 2 boyutta da dilimleme yapildiginda DataFrame elde ediyoruz
type(df_fifa.loc[ [100,103,125], ['long_name', 'age', 'height_cm', 'weight_kg'] ])

"""2. 0-bazli indekslemeyle (iloc)"""

# 2. 0 bazli indekslemeyle => iloc
# 100 etiketli/isimli satirda bulunan oyuncunun tum bilgilerini getirelim
# NOT: 100 etiketine sahip olan oyuncunun 0-bazli indeksi de 100. indekstir
df_fifa.iloc[100, :]

# dilimleme yapilirsa
# !!!! .loc ve .iloc farkliligi !!!!
# 100 ve 103 etiketli/isimli satirlar arasinda bulunan (ve 103 etiketli satir da dahil olmak uzere) oyuncularin tum bilgilerini getirelim
df_fifa.iloc[100:103, :]
# !!! 0 bazli indekslemeden farkli olarak etiket kullaniminda sagdaki etiket dahil okunuyor/getiriliyor !!!
# Fakat 0-bazli indekslemede sagdaki indeks disarida birakiliyor !!!

# 100 ve 103 etiketli/isimli satirlar arasinda bulunan (ve 103 etiketli satir da dahil olmak uzere) oyuncularin tum bilgilerini getirelim
# 103 indeksindeki elemanin da dahil olmasi icin sagdaki indeksin bir arttirilmasi gerekmektedir
df_fifa.iloc[100:104, :]
# 0 bazli indekslemede sagdaki indeks haric olarak okunuyor

# tum oyuncularin (sadece) long_name bilgilerini getirelim ==> long_name 3. indeks sutununda bulunuyor
df_fifa.iloc[:, 3]

# 100 etiketli/isimli (100. indeksteki) satirdaki oyuncunun yaş (4. indekste) ve kilo (7. indekste) bilgisini getirmek icin
# birden fazla ve ardisik olmayan sutunlardaki/satirlardaki veriyi getirmek icin istenilen sutun indekslerini bir liste halinde yaziyoruz.
df_fifa.iloc[100, [4,7]]

# 100, 103 ve 125 etiketli/isimli satirlardaki oyuncularin isim, yaş, boy ve kilo bilgisini getirmek icin
df_fifa.iloc[[100,103,125],[3,4,6,7]]

# satir etiketleri/isimleri 100-103 arasindaki oyuncular icin (indeksler 100-104), long_name ile weight_kg (dahil degil) (3. ve 7. indekslerdeki) sutunlarinin arasindaki tum bilgilerini getirelim
# weight_kg hariç
df_fifa.iloc[100:104, 3:7]

# weight bilgisi de getirilerek, secilen verinin bir degiskende tutulmasi
df_fifa_dilim = df_fifa.iloc[100:104, 3:8]
print(df_fifa_dilim)

df_fifa_dilim.shape

# DataFrame icinde tutulan veriyi numpy ndarray formatina donusturebiliriz
df_fifa_dilim.to_numpy()

fifa_dilim_npndarray = df_fifa_dilim.to_numpy()
print(fifa_dilim_npndarray)

type(fifa_dilim_npndarray) # ndarray: n-dimensional array => n-boyutlu dizi

# dataframe'in values ozelligi, veriyi numpy biciminde gosteren bir ozelliktir
df_fifa_dilim.values
# Return a Numpy representation of the DataFrame.
# Only the values in the DataFrame will be returned, the axes labels will be removed.

"""pandas veri yapilarinin fonksiyonlari ve ozellikleri
- DataFrame ve Series
"""

# calismak istedigimiz sutunlari secelim ve tum oyuncularin bu sutunlardaki bilgilerini alalim
# bundan sonrasinda da bu yeni DataFrame uzerinde calisalim
calisilacak_sutunlar = ['short_name', 'long_name', 'age', 'height_cm', 'weight_kg', 'nationality',
       'club_name', 'league_name', 'value_eur', 'wage_eur', 'player_positions', 'preferred_foot']

df_fifa_alt = df_fifa.loc[:, calisilacak_sutunlar]

df_fifa_alt.shape, df_fifa.shape

df_fifa_alt.head(3)

type(df_fifa_alt)

df_fifa_alt.loc[:, 'age']

# fifada oynayan (paylasilan verideki) oyuncularin yas ortalamasi kactir?
# numpy kutuphanesinin fonk. kullanarak
np.mean(df_fifa_alt.loc[:, 'age'])

oyuncularin_yaslari = df_fifa_alt.loc[:, 'age']
print(type(oyuncularin_yaslari))
print(np.mean(oyuncularin_yaslari))

# FC Barcelona'da oynayan (paylasilan verideki) oyuncularin yas ortalamasi kactir?
# ???
## Secilim yapilmasi gerekmektedir

# shape DataFrame ve Series veri yapilarinin birer ozelligidir
df_fifa_alt.shape

oyuncularin_yaslari.shape

# DataFrame hakkinda genel bilgi
df_fifa_alt.info()

# DataFrame hakkinda istatistiksel bilgi
df_fifa_alt.describe()
# value_eur ve ya wage_eur, 0 olmasi ne demek? Hata mi?
# age < 18 olanlarin degerleri tam belirlenmemis olabilir mi?

"""Sayisal verilerin incelenmesinde kullanilan fonksiyonlarin bir kismi"""

# yas sutunu incelenmek istenirse
# ==>> tum satirlar icin bir sutunu (ya da sutunlari) getirilmek istenirse.
# ==>> tek sutun secildiginde sonuc bir Series olacaktir
oyuncularin_yaslari = df_fifa_alt['age']
#oyuncularin_yaslari = df_fifa_alt.loc[:, 'age']

type(oyuncularin_yaslari)

# Yas bilgisi sayisal bir bilgi
oyuncularin_yaslari.describe()

# Series tek boyutlu veri icerdigi icin .shape sadece satir sayisini gosteriyor
oyuncularin_yaslari.shape
# property
# Return a tuple of the shape of the underlying data.

# Series veri yapisinin fonksiyonlarini direk elemanlari uzerinde calistirabiliriz
oyuncularin_yaslari.mean()

oyuncularin_yaslari.std()

oyuncularin_yaslari.var()

# numpy fonk.
print(np.mean(oyuncularin_yaslari), np.std(oyuncularin_yaslari), np.var(oyuncularin_yaslari))

"""Kategorik verilerin incelenmesinde kullanilan fonksiyonlarin bir kismi"""

# kategorik sutunlarin farkli olarak hangi veriyi icerdiklerine bakilmak istenirse
oyuncu_uyruklari = df_fifa_alt['nationality']
oyuncu_uyruklari.shape

print( dir(oyuncu_uyruklari) ) # series

print( dir(df_fifa_alt) ) # dataframe 
# !!! sutun isimleri ('wage_eur', 'weight_kg'), DF nesnesinin birer ozelligi/attribute

# !!! sutun isimleri ('wage_eur', 'weight_kg'), DF nesnesinin birer ozelligi/attribute
# sutun elemanlarina . operatoru ile ulasilabilir
df_fifa_alt.nationality
# bu yaklasim yerine bir ustteki yaklasimi kullanacagiz

df_fifa_alt.size # veri yapisindaki eleman sayisini dondurur

df_fifa_alt.shape

df_fifa_alt.shape[0]*df_fifa_alt.shape[1]

# Series veri yapisinin fonksiyonlari
oyuncu_uyruklari.unique()

oyuncu_uyruklari.nunique()

# elimizdeki veride, her bir ulke vatandasi kac ornek oyuncu var?
oyuncu_uyruklari.value_counts()
# elimizde bulunan verideki oyuncularin milletlerine gore dagilimi

# NOT: .value_counts(): veri analitigi kisminda genellikle verinin dagilimina bakmak icin kullaniliyor
# ayrica veri orneklerinin imbalanced/(dengesiz dagilima sahip) olup olmadigini anlamak icin kullanabiliyoruz
# verinin bir degiskene (bagimli/hedef degisken) gore nasil dagildiginin anlasilmasi icin kullaniyoruz

oyuncu_uyruklari.value_counts?
# Signature: oyuncu_uyruklari.value_counts(normalize: 'bool' = False, sort: 'bool' = True, ascending: 'bool' = False, bins=None, dropna: 'bool' = True)
# Docstring: Return a Series containing counts of unique values.
#            The resulting object will be in descending order so that the first element is 
#            the most frequently-occurring element. Excludes NA values by default.

oyuncu_uyruklari.value_counts(normalize=True) 
# sirali bir sekilde normalize edilmis sayilari donduruyor

oyuncu_uyruklari.value_counts(normalize=True, sort=False)

"""pandas veri yapilarinda boolean indeksleme"""

# Boolean indeksleme
ulke__ = 'Turkey' # degiskene 'Turkey' degerini atiyoruz
# tek = atama operatoru

# ulke__ degiskeninde 'Italy' var mi sorgusu -> dondurdugu deger bool ==> True/False
ulke__ == 'Italy'
# iki = karsilastirma operatoru

ulke__ == 'Turkey'

['Ireland', 'Italy', 'Turkey', 'Turkey', 'Argentina']

pd.Series(['Ireland', 'Italy', 'Turkey', 'Turkey', 'Argentina']) == 'Turkey'
# boolean degerler olarak karsilastirma sonuclarini donduruyor

'Ireland' == 'Turkey'

'Italy' == 'Turkey'

'Turkey' == 'Turkey'

'Turkey' == 'Turkey'

'Argentina' == 'Turkey'

['Ireland', 'Italy', 'Turkey', 'Turkey', 'Argentina'] == 'Turkey'
# listelerde, pandas veri yapisi olan Series'deki karsilastirmadan farkli calisiyor ve tek bir bool deger donduruyor

# Series veri yapisi ile tek bir degerin karsilastirmasi yapildiginda, 
# tek olan degerin, Series icindeki eleman sayisi kadar coklandigini dusunebilirsiniz
# ve sonuc olarak bir seri halinde ve serideki eleman sayisi kadar boolean degerler donduruluyor.

df_fifa_alt['nationality']

# Orneklem kumemdeki Turk oyunculari bulmak istersek
df_fifa_alt['nationality'] == 'Turkey'
# turk olanlar True, turk olmayanlar False olacak sekilde bir Boolean indeks Serisi donduruyor 
# bu seriyi indeks olarak kullanabilirsiniz

# df[BOOLEAN INDEKSI TRUE OLANLARI SECER]
df_fifa_alt[ df_fifa_alt['nationality'] == 'Turkey' ]

turk_oyuncu_bool_indeksleri = df_fifa_alt['nationality'] == 'Turkey'
turk_oyuncu_bilgileri = df_fifa_alt[turk_oyuncu_bool_indeksleri]

turk_oyuncu_bilgileri.shape

turk_oyuncu_bilgileri.iloc[:5, 0:8]

# turk futbolcularin ortalama yaslari
turk_oyuncu_bilgileri['age']

# Series veri yapisinin ortalama alma fonksiyonunu kullanarak
turk_oyuncu_bilgileri['age'].mean()

# Turk futbolcularin yaslarinin ortalamasini bulunuz?
# 1. Veritabanlarinda sorgu yazilirsa (tablo adi: df_fifa_alt)
#       SELECT AVG(age)
#       FROM df_fifa_alt
#       WHERE nationality = 'Turkey'

# Turk futbolcularin yaslarinin ortalamasini bulunuz?
# 2. DataFrame ile
# 2.1. boolean indeksleri bulunur (==>> WHERE nationality = 'Turkey' )
turk_futbolcu_mu = df_fifa_alt['nationality'] == 'Turkey'
# 2.2. boolean indeksleri kullanarak turk futbolcu bilgilerini aliniz (yani turk futbolcusu olmayanlari eleyiniz)
turk_futbolcularin_bilgileri = df_fifa_alt[turk_futbolcu_mu] # satirlari seciyor
# 2.3. secilen (turk olan) futbolcularin yas ortalamasini bulunuz (==>> SELECT AVG(age) )
# 2.3.1. turk futbolcularin yas sutununu aliniz (Series veri yapisinda)
turk_futbolcu_yaslari = turk_futbolcularin_bilgileri['age']
# 2.3.2. yaslarin ortalamasini bulunuz
# 2.3.2.1. Series veri yapisinin mean fonk. ile
print(turk_futbolcu_yaslari.mean())
# 2.3.2.2. numpy kutuphanesinin mean fonk. ile
print(np.mean(turk_futbolcu_yaslari))
# 2.3.2.3. yerlesik fonk. ile
print(sum(turk_futbolcu_yaslari) / len(turk_futbolcu_yaslari))

# Kategorik verilerde birden fazla sonuc icin karsilastirma yapilmak istenirse

# Turk ve ya Kanada uyruklu olan futbolcu bilgileri
# 1. Veritabanlarinda sorgu yazilirsa (tablo adi: df_fifa_alt, *: tum sutunlari getir)
#       SELECT *
#       FROM df_fifa_alt
#       WHERE nationality = 'Turkey' or nationality = 'Canada'

#       SELECT *
#       FROM df_fifa_alt
#       WHERE nationality in ('Turkey', 'Canada')

# Turk ya da Kanadali futbolcularin yaslarinin ortalamasini bulunuz?
# 2. DataFrame ile
# 2.1. boolean indeksleri bulmak istersek!
df_fifa_alt['nationality'] in ['Turkey', 'Canada']

# 2.1. boolean indeksleri bulmak istersek!
# Serilerin isin fonksiyonu => tek tek seri elemanlarinin isin icine gonderilen yiginda olup olmadigini kontrol eder
df_fifa_alt['nationality'].isin(['Turkey', 'Canada'])

# Turk ya da Kanadali olan futbolcularin yaslarinin ortalamasini bulunuz?
# 2. DataFrame ile
# 2.1. boolean indeksleri bulunur (==>> WHERE nationality in ('Turkey', 'Canada') )
turk_yada_kanadali_futbolcu_mu = df_fifa_alt['nationality'].isin(['Turkey', 'Canada'])
# 2.2. boolean indeksleri kullanarak turk ya da kanadali olan futbolcularin bilgilerini aliniz 
# (yani turk ya da kanadali olmayan futbolculari eleyiniz)
turk_yada_kanadali_futbolcularin_bilgileri = df_fifa_alt[turk_yada_kanadali_futbolcu_mu] # satirlari seciyor
# 2.3. secilen (turk olan) futbolcularin yas ortalamasini bulunuz (==>> SELECT AVG(age) )
# 2.3.1. turk futbolcularin yas sutununu aliniz (Series veri yapisinda)
turk_yada_kanadali_futbolcu_yaslari = turk_yada_kanadali_futbolcularin_bilgileri['age']
# 2.3.2. yaslarin ortalamasini bulunuz
# 2.3.2.1. Series veri yapisinin mean fonk. ile
print(turk_yada_kanadali_futbolcu_yaslari.mean())
# 2.3.2.2. numpy kutuphanesinin mean fonk. ile
print(np.mean(turk_yada_kanadali_futbolcu_yaslari))
# 2.3.2.3. yerlesik fonk. ile
print(sum(turk_yada_kanadali_futbolcu_yaslari) / len(turk_yada_kanadali_futbolcu_yaslari))

turk_yada_kanadali_futbolcularin_bilgileri.shape

turk_yada_kanadali_futbolcularin_bilgileri.tail()

# yasi 40tan buyuk olan futbolcularin bilgilerini bulunuz?
#  SELECT *
#  FROM df_fifa_alt
#  WHERE age > 40

# df_fifa_alt[BOOLEAN INDEX]
#             BOOLEAN INDEX ==> df_fifa_alt['age'] > 40
futbolcu_40dan_buyuk_mu = df_fifa_alt['age'] > 40
df_fifa_alt[futbolcu_40dan_buyuk_mu]

# yasi 30dan buyuk olan Turk futbolcularin isim ve kulup adlarinin bilgilerini bulunuz?
# SELECT long_name, club_name
# FROM df_fifa_alt
# WHERE age > 30 AND nationality = 'Turkey'

# WHERE age > 30 AND nationality = 'Turkey'
# boolean indeksler
yas_indeksleri = df_fifa_alt['age'] > 30
milliyet_indeksleri = df_fifa_alt['nationality'] == 'Turkey'
# AND => &  ----- OR => |
# NOT: indekslerin birlestirilirken parantez icine alinmasi gerekir
# turk_30dan_buyuk_futbolcular = df_fifa_alt[BOOLEAN INDEKSLER]
turk_30dan_buyuk_futbolcular = df_fifa_alt[(yas_indeksleri) & (milliyet_indeksleri)]

turk_30dan_buyuk_futbolcular.shape

turk_30dan_buyuk_futbolcular.head()

# (yas_indeksleri) & (milliyet_indeksleri)
#       True       &        False       ==> False
#       True       &        True        ==> True
#       False      &        False       ==> False
#       False      &        True        ==> False

# SELECT long_name, club_name
gerekli_sutunlar = ['long_name', 'club_name']
turk_30_isim_kulup = turk_30dan_buyuk_futbolcular[gerekli_sutunlar]

turk_30_isim_kulup.shape

turk_30_isim_kulup

# BOOLEAN INDEKSLER ILE satirlari filtreliyoruz ==> WHERE/HAVING
#                  ==>> df[BOOLEAN INDEKSLER]

# LISTE HALINDE SUTUN ISIMLERI ILE sutunlari filtreliyoruz ==> SELECT
#                             ==>> df[SUTUN ISIM LISTESI]

# TEK SATIRDA YAZILMAK ISTENIRSE
df_fifa_alt[(df_fifa_alt['age'] > 30) & (df_fifa_alt['nationality'] == 'Turkey')][['long_name', 'club_name']]

"""ORNEKLER"""

# maaslari 100000 eurodan fazla olan ve ya Turk olan futbolcularin isim, yas, maas ve deger bilgilerini bulunuz?
# SELECT long_name, age, wage_eur, value_eur
# FROM df_fifa_alt
# WHERE wage_eur > 100000 OR nationality = 'Turkey'

# tek satirda yazilan sonuc
# df_fifa_alt[BOOLEAN INDEKSLER ile satirlari eleme][SUTUN ISIM LISTESI ile sutunlarin elenmesi]
df_fifa_alt[ (df_fifa_alt['wage_eur']>100000) | (df_fifa_alt['nationality']=='Turkey') ][['long_name', 'age', 'wage_eur', 'value_eur']]

# tek satirda yazilan sonuc
# df_fifa_alt[SUTUN ISIM LISTESI ile sutunlarin elenmesi][BOOLEAN INDEKSLER ile satirlari eleme]
df_fifa_alt[['long_name', 'age', 'wage_eur', 'value_eur']][ (df_fifa_alt['wage_eur']>100000) | (df_fifa_alt['nationality']=='Turkey') ]

maas_indeksleri = df_fifa_alt['wage_eur'] > 100000
uyruk_indeksleri = df_fifa_alt['nationality'] == 'Turkey'
secilen_futbolcu_bilgileri = df_fifa_alt[(maas_indeksleri) | (uyruk_indeksleri)]
gerekli_sutunlar = ['long_name', 'age', 'wage_eur', 'value_eur']
df_sonuc_100K_turk = secilen_futbolcu_bilgileri[gerekli_sutunlar]
print(df_sonuc_100K_turk.shape)
print(df_sonuc_100K_turk.iloc[:5, :])

"""PEKISTIRME ODEVI"""

# Spain Primera Division liginde oynayan ve degeri 1 milyon eurodan fazla olan futbolcularin aldiklari ortalama maas nedir?
#    SELECT AVG(wage_eur)
#    FROM df_fifa_alt
#    WHERE league_name = 'Spain Primera Division' AND value_eur > 1000000

df_fifa_alt.columns

"""# Veri Analitiği - 2. Kısım
**Kaynak Veri Kümeleri**
*   İlk derste bahsettiğimiz kitabın bağlantısı: https://www.amazon.com/Business-Intelligence-Analytics-Data-Science/dp/0134633288
*   [UCI Cam siniflandirma verisi](https://archive.ics.uci.edu/ml/machine-learning-databases/glass/glass.data) 
*   UCI ML housing dataset.
https://archive.ics.uci.edu/ml/machine-learning-databases/housing/
*   www.kaggle.com
*   scikit-learn datasets

**Kaynak Kitaplar**
* Introduction to Python: https://jakevdp.github.io/WhirlwindTourOfPython/
* Data Science w/ Python: https://jakevdp.github.io/PythonDataScienceHandbook/
* Artificial Intelligence: A Modern Approach, 4th Global ed.
"""

# Data Mining: The nontrivial process of identifying valid, novel, potentially useful, and 
# ultimately understandable patterns in data stored in structured databases.

# Veri Madenciliği: Yapılandırılmış veritabanlarında depolanan verilerdeki, geçerli (öğrenmeyi gerçekleştirdiğimiz veriden yaptığımız çıkarımlar, görmediğimiz veride de kullanılabilir mi, veriye uygulanabilir mi), 
#                   yeni, potansiyel olarak yararlı ve nihai olarak anlaşılabilir kalıpları (pattern) belirlemenin, basit olmayan süreci (process: deneme yanılma içeren adımlar bütünü).

# CRISP-DM: Cross Industry Standard Process for Data Mining
#           Veri Madenciliği için Endüstriler Arası Standart Süreç

"""### **Veri Madenciliği Süreci**

CRISP-DM

1. İş/Problemin Anlaşılması ve Tanımlanması (Business Understanding)
   - İş planının çıkarılması ve bütçenin planlanması
   - Camları tiplerine göre sınıflandırma - SINIFLANDIRMA (Classification)
      - Cam tipinin tahminlenmesi
   - Ev fiyatlarının tahminlenmesi - REGRESYON (Regression)

2. Verinin Anlaşılması (Problemin çözümünde kullanılacak olan verinin) (Data Understanding)
   - Özellik Belirlenmesi / Seçilimi (Feature Engineering - Özellik Mühendisliği)
   - Camın hangi özellikleri, cam tipini tahminlemede kullanılabilir?
        - Sodyum, Magnezyum, Demir vs. seviyelerine (özelliklerine) bakılarak tahminleme yapılabilir
        - Dış faktörlerden kullanabileceğimiz bir veri var mı?
            - Cam tipinin tahminlenmesinde belirlediğimiz bir dış veri bulunmamakta
   - Evlerin hangi özellikleri tahminlemede kullanılabilir?
        - Suç oranı, m2si, ilçe bilgisi, hava kirlilik durumu ..
        - Dış faktörlerden kullanabileceğimiz bir veri var mı?
            - enflasyon oranları, deprem riski ..

   - Veri kaynaklarının ve verinin ne formatta saklandıklarının belirlenmesi
        - belirlenen veriler elde edilebiliyor mu? / ölçümlenebiliyor mu? (kvkk izinleri alınmış mı?)
       - ölçümlerin nasıl yapılacağının belirlenmesi

  - Verinin sayısal mı yoksa kategorik bir veri mi olduğunun anlaşılması
     - Sayısal veri: müşterinin yaşı, gelir miktarı ...
     - Kategorik veri (sayıya dönüştürülmesi gereken veriler): 
        - müşterinin eğitim durumu (ordinal/sıralı) (Lise, Üniv., YL, PhD.)
        - cinsiyet (nominal/kategorik) (Kadın, Erkek - aralarında bir sıralama ya da üstünlük bulunmayan etiketler) (dönüştürürken OHE:one-hot encoding)

3. Verinin Hazırlanması (Data Preparation)
   - Modelin oluşturulmasında kullanılacak olan örneklerin ve ilgili diğer verinin bir araya getirilmesi

   - 214 adet cam örneğinin belirlenen özellikleri ölçümlendi ve örnek camların tipleri belirlendi (etiketlendi/labeling)
   - 506 adet evin belirlenen özellikleri belirlendi/ölçümlemdi ve fiyatları belirlendi (etiketlendi/labeling)

   - Verilerin birleştirilmesi
   - Verilerin temizlenmesi
      - eksik verilerin belirlenip, tamamlanması (ya da veriden kaldırılması) - Imputation (tamamlanması)
      - tutarlılık kontrolleri
   - Verinin dönüştürülmesi
      - normalize/standardize edilmesi
   - Verinin indirgenmesi (örneklerin azaltılması, özelliklerin azaltılması - PCA, tSNE, özellik seçilimi)

   - Üçüncü adım sonucundaki Çıktı 
            - X: özellik matrisi (her bir örnek için belirlenmiş özelliklerin değerlerinin tutulduğu 2 boyutlu veri) (pandasta DataFrame) (bağımsız değişkenleri içerir)
            - y: hedef değişken / etiket vektörü (pandasta Series) (bağımlı değişkeni içerir)

4. Modelin Oluşturulması (Model Building)
   - metotların belirlenmesi
    - Sınıflandırma problemine yönelik => Karar ağacı, Lojistik regresyon, Yapay sinir ağları, vs.
        - sınıf/kategori tahminleme: yarın havanın sıcak, soğuk olduğunu tahminleme

    - Regresyon problemine yönelik => Doğrusal regresyon, Yapay sinir ağları, ...
        - sayı tahminleme: yarın havanın derecesi 28.5 olduğunu tahminleme
   - ...

5. Modelin Değerlendirilmesi / Seçilimi (Model Evaluation and Selection)
   - oluşturulan tahminleme modelinin gerçekte nasıl performans sergilemesi bekleniyor?
   - X_train, X_test, y_train, y_test (X ve y verimizden eğitim ve test verileri elde ediyoruz)
       - train verisi: modeli eğitmek/oluşturmak için kullanılan veri
           - X_train, y_train => model
       - test verisi: eğitilen/oluşturulan modelin başarı performansının tahminlenmesi için kullanılan veri
           - X_test => modele => test_tahminleri
           - test_tahminleri ile y_test karşılaştırılarak modelin başarı performansı belirlenecek 

    - basit ayrıştırma (simple split) ya da k-katlamalı çapraz doğrulama (k-fold cross-validation / k-fold CV)

  - Performans Ölçütlerinin belirlenmesi
    - Sınıflandırma başarı performans ölçütleri: accuracy, precision, recall, f1, ...
      - Karışıklılık matrisinin analizi
    - Regresyon başarı performans ölçütleri: MSE (hataların kareler toplamının ortalaması), mean absolute error, ...

  - Farklı metotlar için performans tahminlemeleri göz önüne alınarak kullanıma sunulacak modelin seçilimi gerçekleştirilir

6. Modelin Kullanıma Sunulması (Model Deployment)
   - X, y (kullanıma sunulacak model oluşturulurken etiketlenmiş olan tüm veri kullanılır)
"""

1. Musterilerle ilgili tahminleme mi? (kredi riski KOTU/ORTA/IYI)   -----          Musterileri gruplamak mi? 
1.     supervised/gozetimli öğrenme mi?                              ---        unsupervised/gozetimsiz öğrenme mi? 
   => tahminleme (SINIFLANDIRMA/classification - REGRESYON)          ---   gruplama, benzer ürünler, ...   (KÜMELEME/clustering)
   => etiketleme/labeling yapilacak mi? etiketler/labels/(siniflar/sayilar) belli mi?
   => tahminleme (siniflandirma/regresyon) yapilacak ise => siniflar/etiketler/sayilar belli ve etiketleme yapilacaktir (supervision) - dogru sonuclarin supervisor tarafindan belirlenmesi gerekmektedir.
   => gruplama yapilacak ise => etikeleme yoktur

2. supervised/gozetimli ise 
   => classification/siniflandirma problemi mi (kategori tahminleme)?, yoksa regression/regresyon mu (sayı tahminleme)?
   => kategori tahminleme (sınıflandırma): yarin havanin sicakliginin YUKSEK mi DUSUK mu oldugunun tahminlenmesi (YUKSEK/DUSUK)
   => sayi tahminleme (regresyon): yarin havanin sicakliginin kac derece oldugunun tahminlenmesi (Sayi ~ 25.5 derece)

3. classification/siniflandirma ise 
   => binary/ikili siniflandirma mi? multi-?/çoklu-? siniflandirma mi?
   => binary classification / multi-class classification

4. multi-?/çoklu? siniflandirma ise 
   => problemi multi-class/çoklu-sinif olarak mi, multi-label/çoklu-etiket (bu yaklaşımı egitimimizde kullanmayacağız) olarak mi tasarlayacagiz?

5. çoklu-sinif siniflandirma / multi-class classification
   => hangi metotlar?

Binary classification / Ikili siniflandirma 
    => Tahminlenmek istenilen: Var/Yok - Spam/Degil - defaulta dusecek/dusmeyecek
    => Binary / 2 sinif olmasi

Multi-class classification/çoklu-sinif siniflandirma ve Multi-label/çoklu-etiketli siniflandirma classification
    => Multi => 2'den fazla sinif varsa

Şarkının taşıdığı duygunun, şarkı sözleri ile tahminlenmesi: Kızgınlık, Üzüntü, Sakinlik, Mutluluk (4 farklı sınıf)
Multi-class: Çoklu sınıf (Her bir örnek sadece tek bir sınıfa ait olabilir) (Her bir şarkı tek bir duygu taşıyorsa)
  Şarkı-1 => Kızgınlık
  Şarkı-2 => Üzüntü
  Şarkı-3 => Sakinlik

Multi-label: Çoklu etiket (her bir örnek birden fazla sınıfa ait olabilir) (Her bir şarkı birden fazla duygu taşıyabiliyorsa)
  Şarkı-1 => Kızgınlık
  Şarkı-2 => Üzüntü, Kızgınlık
  Şarkı-3 => Sakinlik, Üzüntü

Customer Risk Prediction / Müşteri Risk tahminlenmesi 
------------------------------------
Binary Classification Problem - İkili Sınıflandırma -->> gözetimli öğrenme (supervised learning ==>> etiketler elde edilecek)
----
Pozitif Sınıf -> yüksek
Negatif Sınıf -> düşük
----
Problemin çözümünde, yani tahminleme modelinin geliştirilmesi için 100 adet örnek veri (müşteri verisi) toplanmıştır.
------------------------------------
tüm 100 müşteri için tahminlemede kullanılacak özellik verisi (yaş, cinsiyet, gelir, ...) toplanmıştır -> X
---
Tüm veri (Etiketli veri) - 100 adet (etiketli) örnek (müşterilerimizin risklerinin yüksek/düşük olup olmadıkları bilgisi etiketlerde tutuluyor)
Etiketleme yapılırken uzman birisi örnek müşterilerimizin risklerinin yüksek mi düşük mü olduğunu belirlemiştir (supervision)
-> y
------------------------------------
==>> X ve y elimizde bulunmakta
------------------------------------
Cevaplamak istenilen soru: Üretilecek/Geliştirilecek olan tahminleme modelinin başarı performansının kullanımdaki beklenen değeri nedir?
-->> Model Değerlendirilmesi
Bunu yapabilmek için halihazırda sonucunu bilinen örneklerin kullanılması gerekmektedir. 
Sonucu bilinmeyen örnekler ile performans ölçümlenmesi yapılamaz.
------------------------------------
Oluşturulacak olan tahminleme modelinin başarı performansını ölçümleyebilmek için etiketlenmiş veri 2ye ayrılır (90/10 ayrışımı yapalım)
90 adet eğitim verisi (training data) - 10 adet test verisi (test data - holdout sample - modelin geliştirilirken/eğitilirken görmediği örnekler)
---
---
1. Adım
Eğitim verisi (90 adet örnek) ile -> Model Oluşturuldu (Eğitildi/Öğrenme Gerçekleşti/Patternler(kalıplar) bulundu) 
=> .fit => TAHMİNLEME MODELİ
2. Adım
Test Verisi (10 adet örnek) (ile modelin doğruluğunu/başarı performansını bulalım/ölçümleyelim) 

------ Modelin Test verisi üzerindeki Başarı Performansının Ölçümlenmesi ------
Modelin Test Verisi üzerindeki tahminleri alınır => MODEL.predict => y_pred_test 

müşteri -- True/ActualLabel/Observed/GoldLabel/Annotation/Etiket/Sınıf/y_true/y_test -- Model Predictions/prediction/y_pred/y_pred_test 
  m1                                    yüksek                                                       yüksek
  m2                                    düşük                                                        yüksek
  m3                                    yüksek                                                       yüksek
  m4                                    düşük                                                        yüksek
  m5                                    düşük                                                        düşük
  m6                                    düşük                                                        düşük
  m7                                    düşük                                                        düşük
  m8                                    yüksek                                                       düşük
  m9                                    düşük                                                        düşük
  m10                                   yüksek                                                       yüksek

Confusion Matrix - Karışıklılık Matrisi


                                    Gerçek Sınıf
                           Pozitif(yüksek)     Negatif(düşük)

               Pozitif     TP Sayısı: 3        FP Sayısı: 2
Tahminlenen
   Sınıf
               Negatif     FN Sayısı: 1        TN Sayısı: 4

# Başarı Oranı - Doğruluk - Accuracy
# accuracy = (TP + TN) / (TP + FP + TN + FN)
# genel bir ölçüt
accuracy = (3 + 4) / (3 + 2 + 4 + 1) # 7/10
print(f'Modelin doğruluk oranı: {accuracy}')

# modelin sınıflar (düşük/yüksek risk) bazındaki başarısı

# hassasiyet / kesinlik
# Precision => Model ne kadar güvenilir tahminleme yapiyor (güvenilirliği) 
#              => (ikili sınıflandırma problemlerinde pozitif sınıf (yani yüksek risk sınıfı) üzerinde hesaplanıyor) => TP / (TP + FP) 
# precision = modelin pozitif tahminlerinden kaç tanesinin doğru / model kaç örnek için pozitif tahmini yaptı
# precision = TP / (TP + FP)
precision = 3 / (3 + 2)
print(f"Modelin hassasiyet oranı: {precision}")

# duyarlılık
# Recall => Model, pozitif sınıfa ait olan örneklerin ne kadarını yakalayabiliyor (doğru olarak sınıflandırıyor)
# recall = modelin doğru tahminlediği pozitif sınıf örneklerinin sayısı / pozitif örneklerin toplam sayısı
# recall = TP / (TP + FN)
recall = 3 / (3 + 1)
print(f"Modelin duyarlılık oranı: {recall}")

# f1 skoru
# precision(p) ve recall(r) değerlerinin harmonik ortalaması
# f1 = 2 / (1/p + 1/r) = 2 / (r/p*r + p/p*r) = 2 / (p+r / p*r)
# f1 = 2*p*r / (p+r)
f1 = 2 * precision * recall / (precision + recall)
print(f"Modelin f1 skoru: {f1}")

"""[Harmonik ortalama](https://en.wikipedia.org/wiki/Harmonic_mean)"""



"""## Cam Sınıflandırma Probleminin çözümünde Veri Madenciliği Süreci
- https://archive.ics.uci.edu/ml/datasets/glass+identification
- [glass.data indirme bağlantısı](https://archive.ics.uci.edu/ml/machine-learning-databases/glass/glass.data)
"""

# paylasilan glass.data icindeki verilerin sutun isimleri - Sonrasinda ozellikleri belirlerken Id ve Type sutunlarini disarida birakacagiz
sutun_isimleri = ['Id', 'RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe', 'Type']

# cam tipini (Type) tahminlerken camin hangi ozelliklerine bakilacaktir => ozellik sutun isimleri bu ozelliklerin isimlerini belirtmektedir
ozellik_sutun_isimleri = ['RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe']

import numpy as np
import pandas as pd

"""#### Pandas kütüphanesi ile veri okuma

"""

# Pandas kütüphanesi ile veri okuma
veri_baglantisi = 'https://archive.ics.uci.edu/ml/machine-learning-databases/glass/glass.data'

# absolute/full path => dosyanin yolu => nerede bulundugunun uzantisi
# df => DataFrame nesnesi
camverisi = pd.read_csv(veri_baglantisi)

type(camverisi)

camverisi.head() # ilk satır veri baslik olarak okundu (infer edildi)

camverisi = pd.read_csv(veri_baglantisi, header=None)

camverisi.head()

# sutun isimlerini vererek verinin okunmasi
camverisi = pd.read_csv(veri_baglantisi, header=None, names=sutun_isimleri)
camverisi.head()

camverisi.shape
# 2 boyutlu veri - matris
# (satır sayısı, sütün sayısı) => (örnek sayısı, id ve özellik ve hedef değişken sayısı)

camverisi.columns

camverisi.index # 0dan 213e kadar range ile 0-bazli indeksler kullaniliyor

# Id sutunu index olarak kullanilmak istenirse
camverisi = pd.read_csv(veri_baglantisi, names=sutun_isimleri, index_col='Id')
# camverisi = pd.read_csv(veri_baglantisi, header=None, names=sutun_isimleri, index_col=0)
camverisi.head()

camverisi.shape

camverisi.iloc[:2, :]

camverisi.loc[0, 'Na':'Si']

camverisi.loc[1:3, 'Na':'Si']

"""##### Pandas ile okunmuş veri setinden özellik matrisi (X) ve etiket vektörünü (y) oluşturmak"""

# 1. Sütun isimleriyle seçilim
ozellik_sutun_isimleri = ['RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe']
X = camverisi[ozellik_sutun_isimleri] # indekslemeyi liste ile yapiyoruz (sutun isimleri)
print(X.shape)
print(X.head())

# 2. Hedef değişken (ve id) sutununun atılması





# Etiket Vektörü - Hedef Değişken Dizisi 
# 1. sütun ismi ile seçilim
y = camverisi['Type'] # Series -> vektor
print(type(y))
print(y.shape)

# 2. slicing - dilimleme





"""#### Modelin Eğitilmesi/Oluşturulması ve Değerlendirilmesi (4. ve 5. adımlar)
- Simple Split - Basit Ayrıştırma
- K-fold cross validation (K-katlamalı çapraz doğrulama)
"""

# Pandas kütüphanesi ile veri okuma
import pandas as pd
veri_baglantisi = 'https://archive.ics.uci.edu/ml/machine-learning-databases/glass/glass.data'
sutun_isimleri = ['Id', 'RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe', 'Type']
ozellik_sutun_isimleri = ['RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe']
camverisi = pd.read_csv(veri_baglantisi, names=sutun_isimleri, index_col='Id')
X = camverisi.iloc[:, :9] # tahminlemede kullanilacak ozellikler => X
# X = camverisi[ozellik_sutun_isimleri]
y = camverisi.iloc[:, 9] # tahminlenmek istenen hedef degisken verisi => y
# y = camverisi['Type']

camverisi.head(10)

X.head(10)

y.head(10)

# etiketlerin dagilimi
y.value_counts()

y.value_counts(normalize=True)

print(X.shape, y.shape, type(X), type(y))



"""#### Simple Split - Basit Ayrıştırma"""

# Tüm Veri
print(X.shape)
print(y.shape)
print(camverisi.shape) # X,y

# Model oluşturma (eğitim verisi) ve değerlendirme (test verisi - holdout - eğitimde dışarıda tutulan veri)
# Train - test split => eğitim ve test verisi olarak ayrıştırma
#X => özellik matrisi
#y => hedef değişken vektörü - etiketler
# scikit-learn kutuphane = sklearn
# X, y ==>> X_train, X_test, y_train, y_test
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42) # defaultta shuffle=True
# camverisini X ve y olarak ayirmadan once de train-test split/ayrisim yapilabilirdi
cv_train, cv_test = train_test_split(camverisi, test_size=0.33, random_state=42)
# shuffle => verinin rasgele ayrisimini kontrol eden parametre

print(type(X_train), type(X_test), type(y_train), type(y_test))
print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)

print(type(cv_train), type(cv_test))
print(cv_train.shape, cv_test.shape)

# train_test_split(*arrays, test_size=None, train_size=None, random_state=None, shuffle=True, stratify=None)
# shuffle: bool, default=True
#          => Whether or not to shuffle the data before splitting.
# stratify: array-like, default=None
#          => If not None, data is split in a stratified fashion, using this as the class labels.
# stratify ==>> orjinal verideki siniflarin dagiliminin, ayristirilmis verideki her altkumede de saglanmasi

y.value_counts(normalize=True)
# model olusturmak icin toplanilan tum verideki orneklerin siniflara gore dagilimi

y_train.value_counts(normalize=True)

y_test.value_counts(normalize=True)
# test verisindeki orneklerin siniflara gore dagilimi
# train_test_split fonk. shuffle parametresi True oldugu icin, rasgele secimin sonucu olarak sinif dagilimlari orjinaldekine yakin oluyor

# NOT: Train (y_train) ve Test (y_test) verisindeki sinif dagilimlari, orjinal verideki dagilimlara (y) benzer olsun isteniyorsa
# bunun stratified ornekleme yapmak gerekiyor.

# tum verideki sinif dagilimlarini  goz onune alarak ayristirma ==>> stratify = y
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify=y)
# shuffle'in varsayilan degeri True

# y: pandas kutuphanesinin Series veri yapisina ait
# hangi sinifa ait kac ornek oldugu => sayi, yuzde olarak
y.value_counts(normalize=True) # örneklerin sınıf dağılım yüzdeleri
# dengesiz bir sinif dagilimina sahip

y_test.value_counts(normalize=True) # test örneklerinin sınıf dağılım yüzdeleri

# egitim verisinde kac ornek olacak
# 0.33 test, 0.67 train
0.33 * 214, 0.67 * 214
# 70.62=>71, 143.38=>143

####  Stratified Ornek Secilimi  ####
# Train/Eğitim verisinde, tum verideki sinif dagiliminin elde edilmesi
# egitim verisinde toplamda 143 adet ornek secilecek
# tum verideki 1. sinifa ait olan ornek yuzdesi => 0.327103
# tum verideki 7. sinifa ait olan ornek yuzdesi => 0.135514
143*0.327103, 143*0.135514  # train/egitim verisinde 1. sinifa ve 7. sinifa ait olmasi beklenen ornek sayilari
# (46.775729, 19.378502)
# 1: 47, 7: 19

y_train.value_counts() # sayisal olarak sinif dagilimi

# Test verisinde tum verideki sinif dagilimini elde edelim
# test verisinde toplamda 71 adet ornek secilecek
# tum verideki 1. sinifa ait olan ornek yuzdesi => 0.327103
# tum verideki 7. sinifa ait olan ornek yuzdesi => 0.135514
71*0.327103, 71*0.135514  # test verisinde 1. sinifa ve 7. sinifa ait olmasi beklenen ornek sayilari
# 23.224313 => 23, 9.621494 => 10
# 23, 10

y_test.value_counts() # sayisal olarak sinif dagilimi





camsiniflari = {1: 'building_windows_float_processed',
                2: 'building_windows_non_float_processed',
                3: 'vehicle_windows_float_processed',
                4: 'vehicle_windows_non_float_processed',      ## !!!!! YOK !!!
                5: 'containers',
                6: 'tableware', 
                7: 'headlamps'}

"""#### Model Eğitilmesi/Oluşturulması (Training/Development)
 - 4. adım
"""

# Sınıflandırma problemine yönelik olarak eğitilecek modelin yaklaşımı/metodu => Karar ağacı

# Karar ağacı sınıflandırıcı modelinin oluşturulması
from sklearn.tree import DecisionTreeClassifier

# karar agaci siniflandirici nesnesinin olusturulmasi
karar_agaci = DecisionTreeClassifier() # default parametreler ile olusturuldu
# default olarak criterion='gini'

type(karar_agaci)

print( dir(karar_agaci) )

# Tahminleme Modeli olustururken (egitirken) ve tahminlemeleri yaparken 2 fonk kullaniyoruz
# 1. .fit(..train/egitim verisi - X_train, y_train..): modelin olusturulmasi (egitilmesi) => çıktı: sınıflandırıcı (model)
# 2. .predict(..test verisi - X_test..): modelin, tahmin gerektiren veri için tahminleme yapması => çıktı: modelin tahminleri (y_pred_test)

# Karar ağacı modelinin eğitilmesi => gözetimli öğrenmede Özellikler ve Etiketler kullanilir
karar_agaci.fit(X_train, y_train)
# Sonuc: Trained classifier - eğitilmiş sınıflandırıcı
# Karar agaci modeli => if-then-else

import matplotlib.pyplot as plt
from sklearn.tree import plot_tree

plt.figure(figsize=(25,10))
modeltree = plot_tree(karar_agaci,
                      feature_names = ozellik_sutun_isimleri,
                      filled=True, 
                      rounded=True, 
                      fontsize=14)

# Karar agaci modelinin derinligi nedir?
karar_agaci.get_depth()
# ==>> en fazla 10 tane ozellik-deger ikilisine bakarak model olusturulmus

# Daha basit bir Karar agaci modeli olusturalim
karar_agaci_basit = DecisionTreeClassifier(max_depth=3)
# stopping criteria => max_depth->3 # ==>> en fazla 3 tane ozellik-deger ikilisine bakarak model olustur.
# splitting criteria => gini # en iyi ayristiran ozelligi bulurken kullanilan kriter.
#                      ==>> criterion{“gini”, “entropy”, “log_loss”}, default=”gini”

# modelin egitilmesi
karar_agaci_basit.fit(X_train, y_train)

import matplotlib.pyplot as plt
from sklearn.tree import plot_tree

plt.figure(figsize=(25,10))
modeltree = plot_tree(karar_agaci_basit,
                      feature_names = ozellik_sutun_isimleri,
                      filled=True, 
                      rounded=True, 
                      fontsize=14)

ornek_sayilari = np.array([56, 61, 14, 10, 7, 24])
toplam_egitim_ornek_sayisi = np.sum(ornek_sayilari)
print(f"Model olusturulurken kullanilan toplam ornek sayisi (samples): {toplam_egitim_ornek_sayisi}")

olasiliklar = ornek_sayilari / toplam_egitim_ornek_sayisi # vektorun elemanlari bir sayiya bolunuyor - broadcast
print(f"Her bir sinifin olasiliklari: {olasiliklar}")

gini_train = 1 - np.sum(olasiliklar**2) # 1 - olasiliklarin karelerinin toplami
print(f"gini - kok hucrede: {gini_train}")
print(f"gini - kok hucrede: {gini_train:.3f}")

ornek_sayilari_ba_buyuk = np.array([1, 1, 0, 0, 21, 0])
toplam_egitim_ornek_sayisi_ba_buyuk = np.sum(ornek_sayilari_ba_buyuk)
olasiliklar = ornek_sayilari_ba_buyuk / toplam_egitim_ornek_sayisi_ba_buyuk # vektorun elemanlari bir sayiya bolunuyor - broadcast
print(f"Her bir sinifin olasiliklari: {olasiliklar}")
gini_train = 1 - np.sum(olasiliklar**2) # 1 - olasiliklarin karelerinin toplami
print(f"gini - kok hucrede: {gini_train}")
print(f"gini - kok hucrede: {gini_train:.3f}")

X_test.iloc[0]

karar_agaci_basit.predict(np.array(X_test.iloc[0]).reshape(1,-1))

"""#### Modelin  değerlendirilmesi
 - 5. adım
"""

# değerlendirme için test verisini kullanıyoruz
y_test.value_counts()

# Model Assessment - Modelin  değerlendirilmesi
# Test verisi ile değerlendirme
# test örneklerinin ait oldukları gerçek sınıflar (y_test) ve model tarafından tahmin edilen sınıflar (y_pred_test)

# 1. adim: modelin tahminlerinin alinmasi
y_pred_test = karar_agaci.predict(X_test)

type(y_pred_test)

# ilk test orneginin ozellikleri, gercek sinifi ve tahmin edilen sinifi nedir?
# ornegin ozellikleri
X_test.iloc[0, :]

# ornegin egitilmis olan model tarafindan tahmin edilen sinifi
y_pred_test[0]

# ornegin gercek sinifi
y_test.iloc[0] # y_test pandas Series veri yapisinda oldugundan iloc ile indeksleme yapiliyor

y_pred_test[0:5] # ilk 5 ornegin tahmin edilen siniflari

# ilk 5 ornegin gercek siniflari
y_test.iloc[:5]

# 2. adim: modelin tahminlerine gore performansinin olcumlenmesi

# Karışıklılık Matrisi (Confusion Matrix)
from sklearn.metrics import confusion_matrix
# y_true: array-like of shape (n_samples,)
#         => Ground truth (correct) target values.
# y_pred: array-like of shape (n_samples,)
#         => Estimated targets as returned by a classifier.
confm = confusion_matrix(y_test, y_pred_test)
confm
# Satırlar gerçek sınıfları, Sütunlar tahminleri veriyor
# Confusion matrix whose i-th row and j-th column entry indicates the number of samples with
#     true label being i-th class and predicted label being j-th class.
# i. satır ve j. sütun girişi, 
# gerçek etiketi i. sınıf ve tahmini etiketi j. sınıf olan örnek sayısını gösteren karışıklık matrisi.

type(confm)

confm.T
# Transpozunu alarak, yukarıdaki/sunumda tartıştığımız örnekteki görünüm
# Satırlar tahminleri, Sütunlar gerçek sınıfları veriyor

confm.T.shape # 6 adet sinif icin tahmin/gercek deger matrisi

# dogruluk hesabi
# herbir sinif icin dogru tahminlenen orneklerin toplami / toplam ornek sayisi
accuracy_ = (confm[0,0]+confm[1,1]+confm[2,2]+confm[3,3]+confm[4,4]+confm[5,5]) / np.sum(confm)
print(f"Modelin accuracy/basari skoru: {accuracy_}")

np.diag(confm)

accuracy_ = np.sum(np.diag(confm)) / np.sum(confm)
print(f"Modelin accuracy/basari skoru: {accuracy_}")

# 2 numaralı sınıf için performans hesaplamalari
# toplamda 23 adet örnek model tarafından 2. sınıfa ait olarak tahminlenmistir
# toplamda 25 adet 2. sınıfa ait test örneği mevcut
# 18 tane örnek 2 sinifina ait olarak doğru tahminlenmiştir
# 2 olarak tahminlenenlerden 3 tane örnek 1. sınıfa ait olarak, 1 tane örnek 5., 1 tane örnek 6. sınıfa ait olarak yanlış tahminlenmiştir

# Sonuc olarak 2. sinif icin basari olcutlerimiz
# duyarlilik/recall: 18/25
# hassasiyet/precision: 18/23

recall = 18 / 25
print("2. sinif icin basari skorlari - precision/recall/f1")
print(f"Recall: {recall}")
precision = 18 / 23
print(f"Precision: {precision}")
print(f"f1-score: {2 * precision * recall / (precision + recall)}")

from sklearn.metrics import classification_report
cls_rep = classification_report(y_test, y_pred_test)
print(cls_rep)

# support: test verisindeki her bir sinifa ait olan ornek sayilarini verir

# Soru: Modelim için ozet basari skoru (duyarlilik/hassasiyet/f1 için bir sayı) nedir?
# ==>> her sınıf için ayrı hesaplanan (f1) skorlarını nasıl tek bir skor halinde özetleyebiliriz?
# Cevap: makro veya ağırlıklı ortalamalar alabiliriz

# siniflara ait olan örnek sayıları
test_ornek_sayilari = np.array([23, 25, 6, 4, 3, 10])
# hesaplanan f1 skorlari
f1_skorlari_siniflar_icin = np.array([0.82, 0.75, 0.62, 0.75, 0.44, 0.90])
# classification reporttan okunan veriler

# macro avg: skorlarin ortalamasinin alinmasi (sinif dagilimlarini goz onunde bulundurMAdan)
macro_ortalama_f1_skoru = np.mean(f1_skorlari_siniflar_icin)
print(f"macro avg f1: {macro_ortalama_f1_skoru:.2f}")

# weighted avg: ornek sayilarinin agirliklarina gore hesaplanan agirlikli ortalama
test_orneklerinin_sinif_agirliklari = test_ornek_sayilari / np.sum(test_ornek_sayilari)
print(test_orneklerinin_sinif_agirliklari)
# agirlikli ortalama ==>> iki vektorun dot carpimi
agirlikli_f1 = f1_skorlari_siniflar_icin.dot(test_orneklerinin_sinif_agirliklari)
print(f"weighted avg f1: {agirlikli_f1:.2f}")

# NOT: siniflara ait olan ornek sayilari birbirlerine esit olduklari durumda (siniflarda dengeli dagilim var ise - BALANCED), 
# ==>> macro avg ve weighted/agirlikli ortalama da birbirine esit olur

"""#### K-fold cross validation (K-katlamalı çapraz doğrulama)

[Sklearn websitesindeki Cross Validation tutorial](https://scikit-learn.org/stable/modules/cross_validation.html)

##### K-katlamalı çapraz doğrulama ile Model Değerlendirme
- 4. ve 5. adım
"""

import numpy as np
import pandas as pd

# K-fold Cross Validation (with Stratified Sampling) - K-katlamalı çapraz doğrulama (tabakalı örneklem ile)
# 5-fold CV
# Stratified Sampling (Tabakalı (sınıf dağılımını göz önüne alan) örnekleme) 

# metod
from sklearn.tree import DecisionTreeClassifier
# train-test ayrışımı
from sklearn.model_selection import StratifiedKFold
# performans ölçütü
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
# => varsayim olarak tum siniflara esit onem verilsin => macro averaj/ortalama kullanilacak
# zaman performansı da ölçülsün
import time

5-fold CV adımları
Veriyi 5 splite ayir
5 farkli veri kümesi (split) için yap
    1. metod
    2. train-test spliti yap => X_train, X_test, y_train, y_test
        => 3., 4. ve 5. adimlar bir dongu icerisinde her bir splitin train ve test verisi ile yapilacaktir
        3. train => .fit                         ==>> ve modeli elde et
        4. test  => .predict => y_pred_test      ==>> modelin test verisi uzerindeki tahminlerini al
        5. performans => accuracy_score/f1_score ==>> performans değerlerini listede toplayalım
6. Son Adım
Performans değerlerinin (5 adet performans skorunun) özetlenmesi / aggregation

# 5 fold
skf.split(X, y) => 
[
 ([train_index_listesi1], [test_index_listesi1]),
 ([train_index_listesi2], [test_index_listesi2]),
 ([train_index_listesi3], [test_index_listesi3]),
 ([train_index_listesi4], [test_index_listesi4]),
 ([train_index_listesi5], [test_index_listesi5]),
]

from sklearn.model_selection import StratifiedKFold

skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=None)
splitnum = 1
print(list(skf.split(X,y)))
#for train_index, test_index in skf.split(X,y):
#    print(f"{splitnum}. split\nTrain-{splitnum}: {train_index}\nTest-{splitnum}: {test_index}")
#    splitnum += 1

type(X), type(y)

### Karar Agaci gini parametresi ile
# 1.
karar_agaci_g = DecisionTreeClassifier(criterion='gini')
# 2.1. 
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=32)
# 5.0.
performans_degerleri = []
# 2.2. splitlerin olusturulmasi
# 2.3. orneklerin split indeksleriyle secilimi
# 3. modelin egitilmesi
# 4. modelin test ornekleri uzerindeki tahminlerinin bulunmasi
# 5. performans olcumu
# -----------------------
# 2.2
for train_index, test_index in skf.split(X, y):
    # 2.3. => X_train, X_test, y_train, y_test
    X_train = X.iloc[train_index]  # eger X bir numpy ndarray nesnesi olsaydi => X[train_index]
    X_test = X.iloc[test_index]
    y_train = y.iloc[train_index]
    y_test = y.iloc[test_index]
    # 3.
    # model oluştur => train ==> .fit
    karar_agaci_g.fit(X_train, y_train)
    # 4. 
    # tahminleri al - Test verisinin
    y_pred_test = karar_agaci_g.predict(X_test) # ==>> performans degerlendirmesi icin kullanilacak
    # 5.
    # performans ölçümü ve saklanması (test)
    performans = f1_score(y_test, y_pred_test, average='macro')
    performans_degerleri.append(performans)

print(performans_degerleri)

# 6. Son Adım
# Performans değerlerini özetleyelim / aggregation
# ortalama, min, max f1_macro_avg skorlari
print( np.mean(performans_degerleri), np.min(performans_degerleri), np.max(performans_degerleri) )

### Karar Agaci entropy parametresi ile
# 1.
karar_agaci_e = DecisionTreeClassifier(criterion='entropy')
# 2.1. 
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=32)
# 5.0.
performans_degerleri = []
# 2.2. splitlerin olusturulmasi
# 2.3. orneklerin split indeksleriyle secilimi
# 3. modelin egitilmesi
# 4. modelin test ornekleri uzerindeki tahminlerinin bulunmasi
# 5. performans olcumu
# -----------------------
# 2.2
for train_index, test_index in skf.split(X, y):
    # 2.3. => X_train, X_test, y_train, y_test
    X_train = X.iloc[train_index]  # eger X bir numpy ndarray nesnesi olsaydi => X[train_index]
    X_test = X.iloc[test_index]
    y_train = y.iloc[train_index]
    y_test = y.iloc[test_index]
    # 3.
    # model oluştur => train ==> .fit
    karar_agaci_e.fit(X_train, y_train)
    # 4. 
    # tahminleri al - Test verisinin
    y_pred_test = karar_agaci_e.predict(X_test) # ==>> performans degerlendirmesi icin kullanilacak
    # 5.
    # performans ölçümü ve saklanması (test)
    performans = f1_score(y_test, y_pred_test, average='macro')
    performans_degerleri.append(performans)
# 6. Son Adım
# Performans değerlerini özetleyelim / aggregation
# ortalama, min, max f1_macro_avg skorlari
print(performans_degerleri)
print( np.mean(performans_degerleri), np.min(performans_degerleri), np.max(performans_degerleri) )

### K-En Yakın Komşu (KNN, K-nearest neighborhood)
# 1.
from sklearn.neighbors import KNeighborsClassifier
neigh = KNeighborsClassifier(n_neighbors=3)
# 2.1. 
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=32)
# 5.0.
performans_degerleri = []
# 2.2. splitlerin olusturulmasi
# 2.3. orneklerin split indeksleriyle secilimi
# 3. modelin egitilmesi
# 4. modelin test ornekleri uzerindeki tahminlerinin bulunmasi
# 5. performans olcumu
# -----------------------
# 2.2
for train_index, test_index in skf.split(X, y):
    # 2.3. => X_train, X_test, y_train, y_test
    X_train = X.iloc[train_index]  # eger X bir numpy ndarray nesnesi olsaydi => X[train_index]
    X_test = X.iloc[test_index]
    y_train = y.iloc[train_index]
    y_test = y.iloc[test_index]
    # 3.
    # model oluştur => train ==> .fit
    neigh.fit(X_train, y_train)
    # 4. 
    # tahminleri al - Test verisinin
    y_pred_test = neigh.predict(X_test) # ==>> performans degerlendirmesi icin kullanilacak
    # 5.
    # performans ölçümü ve saklanması (test)
    performans = f1_score(y_test, y_pred_test, average='macro')
    performans_degerleri.append(performans)
# 6. Son Adım
# Performans değerlerini özetleyelim / aggregation
# ortalama, min, max f1_macro_avg skorlari
print(performans_degerleri)
print( np.mean(performans_degerleri), np.min(performans_degerleri), np.max(performans_degerleri) )

### RandomForestClassifier
# 1.
from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier()
# 2.1. 
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=32)
# 5.0.
performans_degerleri = []
# 2.2. splitlerin olusturulmasi
# 2.3. orneklerin split indeksleriyle secilimi
# 3. modelin egitilmesi
# 4. modelin test ornekleri uzerindeki tahminlerinin bulunmasi
# 5. performans olcumu
# -----------------------
# 2.2
for train_index, test_index in skf.split(X, y):
    # 2.3. => X_train, X_test, y_train, y_test
    X_train = X.iloc[train_index]  # eger X bir numpy ndarray nesnesi olsaydi => X[train_index]
    X_test = X.iloc[test_index]
    y_train = y.iloc[train_index]
    y_test = y.iloc[test_index]
    # 3.
    # model oluştur => train ==> .fit
    rfc.fit(X_train, y_train)
    # 4. 
    # tahminleri al - Test verisinin
    y_pred_test = rfc.predict(X_test) # ==>> performans degerlendirmesi icin kullanilacak
    # 5.
    # performans ölçümü ve saklanması (test)
    performans = f1_score(y_test, y_pred_test, average='macro')
    performans_degerleri.append(performans)
# 6. Son Adım
# Performans değerlerini özetleyelim / aggregation
# ortalama, min, max f1_macro_avg skorlari
print(performans_degerleri)
print( np.mean(performans_degerleri), np.min(performans_degerleri), np.max(performans_degerleri) )

### RandomForestClassifier farkli parametrelerle
# 1.
from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier(n_estimators=90, criterion='gini', max_features='sqrt')
# 2.1. 
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=32)
# 5.0.
performans_degerleri = []
# 2.2. splitlerin olusturulmasi
# 2.3. orneklerin split indeksleriyle secilimi
# 3. modelin egitilmesi
# 4. modelin test ornekleri uzerindeki tahminlerinin bulunmasi
# 5. performans olcumu
# -----------------------
# 2.2
for train_index, test_index in skf.split(X, y):
    # 2.3. => X_train, X_test, y_train, y_test
    X_train = X.iloc[train_index]  # eger X bir numpy ndarray nesnesi olsaydi => X[train_index]
    X_test = X.iloc[test_index]
    y_train = y.iloc[train_index]
    y_test = y.iloc[test_index]
    # 3.
    # model oluştur => train ==> .fit
    rfc.fit(X_train, y_train)
    # 4. 
    # tahminleri al - Test verisinin
    y_pred_test = rfc.predict(X_test) # ==>> performans degerlendirmesi icin kullanilacak
    # 5.
    # performans ölçümü ve saklanması (test)
    performans = f1_score(y_test, y_pred_test, average='macro')
    performans_degerleri.append(performans)
# 6. Son Adım
# Performans değerlerini özetleyelim / aggregation
# ortalama, min, max f1_macro_avg skorlari
print(performans_degerleri)
print( np.mean(performans_degerleri), np.min(performans_degerleri), np.max(performans_degerleri) )

"""#### Deployment (Dağıtım)
- Kullanıma Sunulacak / deploy edilecek Modelin oluşturulması
- 6. adım
"""

# Pandas kütüphanesi ile veri okuma
import numpy as np
import pandas as pd
verilinki = 'https://archive.ics.uci.edu/ml/machine-learning-databases/glass/glass.data'
sutun_isimleri = ['id', 'RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe', 'Type']
ozellik_sutun_isimleri = ['RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe']
camverisi = pd.read_csv(verilinki, header=None, names=sutun_isimleri)
X = camverisi.iloc[:, 1:10]
y = camverisi.iloc[:, 10]

# en iyi performans gösteren metod ve parametreleri
# RandomForestClassifier - default parametrelerle 
from sklearn.ensemble import RandomForestClassifier
sunulacak_model = RandomForestClassifier()

# tum veri ile modeli egitiyoruz
sunulacak_model.fit(X, y)

"""##### Model Persistence (Model Kalıcılığı)
- oluşturulan modelin kaydedilmesi
"""

# import pickle
from joblib import dump
# tum veri ile egitilmis olan modeli kaydediyoruz/sakliyoruz (kodun bulundugu klasorun altina)
dump(sunulacak_model, 'camsiniflandiricimodeli.joblib')

"""##### Deploy edilmiş / kullanıma sunulmuş model ile Tahminleme yapma"""

# Kaydedilmiş/Saklanmış Modeli okumak
from joblib import load 
camsiniflandirici = load('camsiniflandiricimodeli.joblib') # path verilmesi gerekmektedir. 'C:\halkbankasi\modeller\camsiniflandiricimodeli.joblib' gibi

# use deployed model - Dağıtım için eğitilen modelin tahminlemede kullanımı
# yeni gelen verinin özellik sayısının ve sırasının, model eğitilirken ki kullanilan özellik sayısı ve sırası ile aynı olması gerekmektedir

# camin hangi ozellikleri kullaniliyor
X.columns

X.shape

yeniveri = np.array([ 1.55, 15.55, 0., 2.55, 70.1,  0. , 6.62, 1.21, 0.])
print(yeniveri)
print(yeniveri.shape) # icinde 9 deger olan bir vektor

# yeni veri icin model tahminlemesi
camsiniflandirici.predict(yeniveri)
# ALINAN HATA:
# ValueError: Expected 2D array, got 1D array instead:
# yani 2D => matris beklenirken, 1D => vektor gonderilmistir
# predict fonksiyonu Matris (ornek sayisi, ozellik sayisi) olarak verilen verinin tahminlenmesini yapiyor.
# 1 ornegin tahmini yapilacagindan, verinin bicimi (shape'i) (1, 9) olmalidir

# Reshape your data either using array.reshape(-1, 1) if your data has a single feature or 
# array.reshape(1, -1) if it contains a single sample.

# Verilerinizin tek bir özelliği varsa array.reshape(-1, 1) veya 
# tek bir örnek içeriyorsa array.reshape(1, -1) kullanarak verilerinizi yeniden şekillendirin.

# elimizdeki veri, sınıfını tahminlemek istediğimiz tek bir örnek
yeniveri.reshape(1, -1)

yeniveri.reshape(1, -1).shape

yeniveri.reshape(3, -1).shape # 3 tane ornek icin yeniden bicimlendir. => 3 ozellik varmis gibi ayiriyor

yeniveri.reshape(-1, 1)

# yvr: yeniden biçimlendirilmis veri
# y:yeni v:veri r:reshaped
yvr = yeniveri.reshape(1, -1)
print(yvr)
print(yvr.shape)
# icinde tek ornek olan bir matris !

# ya da en bastan veriyi 2 noyutlu hazirlamamiz gerekiyordu
# yeniveri = np.array([ 1.55, 15.55, 0., 2.55, 70.1,  0. , 6.62, 1.21, 0.])
yeniveri__ = np.array([[ 1.55, 15.55,  0.  ,  2.55, 70.1 ,  0.  ,  6.62,  1.21,  0.  ]])
print(yeniveri__.shape)

# yeni veri icin model tahminlemesi
camsiniflandirici.predict(yvr)

type(camsiniflandirici.predict(yvr))

# tek bir ornek icin tahminleme yapildigindan => tek deger dondurdugu icin aslinda sonuc 0 indeksteki deger
siniftahmini = camsiniflandirici.predict(yvr)
print(siniftahmini)
print(siniftahmini[0])

camsiniflari

camsiniflari[7]

camsiniflari[siniftahmini[0]]

print(f"Yeni gelen cam verisinin sınıfı {camsiniflari[siniftahmini[0]]}'tir")

X.head()

"""## Metin Madenciligi - Text Mining

* https://www.nltk.org/

- Corpus: Eldeki dokümanların tümü (model oluşturmak için toplanan doküman verisi)
- Tokenizing: simgeleştirme, jetonlaştırma
- Term: Terim - bir ya da daha fazla kelimeden oluşan
- Stemming: Köklerine ayırma
   - madeni, madenciliği => maden
- Stopwords: Tahminleme problemine yönelik olarak kullanıldığında farklılık oluşturmayan (özellik olarak kullanılmayan) kelimeler. Doküman(lar)dan çıkarılacak olan kelimeler
- N-gram: n tane ardışık kelime.
   - Cümlede geçen bir örnek parça: karar destek sistemi
   - Unigram (1-gram): tek kelimeden oluşan terim
    - karar, destek, sistemi
   - Bigram (2-gram): iki ardışık kelimeden oluşan terim
    - karar destek, destek sistemi
   - Trigram (3-gram): üç ardışık kelimeden oluşan terim
    - karar destek sistemi
- Term dictionary: Terim sözlüğü (Özelliklerin tümü)
    - Corpustaki tüm terimler / ya da kendi oluşturduğumuz terimlerin tümü

- Word frequency: Kelime geçme sıklığı
- Morphological-Lexical: Kelime bilimi
- Syntactic: Sözdizimi
- Semantic: Anlamsal

- Part-of-Speech (POS) Tagging: Konuşma Bölümü Etiketleme
   - bir terimin cümledeki görevi -> terim yüklem mi, isim mi ...
- Named Entity Recognition: Adlandırılmış Varlık Tanıma
   - Adlandırılmış Varlıklar: insan, firma, tarih..
   - Elon Musk Twitter'ı 45 Milyar dolara 2022'de satın aldı
     - [Elon Musk]_insan [Twitter]_firma'ı 45 Milyar dolara [2022]_tarih'de satın aldı

- Term by Document Matrix: Terim/Doküman Matrisi
    - Özellik Matrisi - X (representation learning)
    - curse of dimensionality (boyutluluk laneti)
      - çok sayıda özellik bulunması

"""

###  ÖZELLIKLER ( (BAGIMSIZ) DEGISKENLER)  ###
Cam sınıflandırma
Özellikler          =>  Na,  K,   Ca,  ...
ilk (1.) cam örneği => 1.5, 2.8, 13.6, ... (degerlerinin olcumlenmesi) => vektorize edilmis hali

Müşteriler Defaulta dusecek mi
Özellikler              =>  Yaş,   Gelir,  EgitimSeviyesi,  ...
ilk (1.) müşteri örneği =>  29,    10000,         3      ,  ... (degerlerinin toplanmasi) => vektorize edilmis hali

NOT: her bir ornek esit sayida ve ayni sirada ozellik icermeli ve sayisal degeri olmali
(Tum) Camlarda (ornegin) 3 adet ozellik var
(Tum) Musterilerde (ornegin) 3 adet ozellik var

############################
Haber dokümanlarının sınıflandırılması => spor/finans/politika (oncelikle ornek dokumanlarin etiketlenmesinin yapildigini varsayiyoruz.)
Özellikler ??? => Dokümanlarda geçen terimler (kelimeler)
Özellikler            => finans, veri, faiz, kredi, madencilik, veri madenciliği, ...
ilk (1.) haber örneği =>    5  ,  3  ,  15 ,   9  ,     1     ,     0           , ... => vektorize edilmis hali
                            1     1      1     1        1           0   -> İkili geçme-geçmeme (0 ya da 1 değeri alıyor her bir kelime)

## SORULAR
Metin Madenciligi
1. Terimler/Özellikler ne olsun ? (parametreler => lowercase?, stemming?, n-gram (unigram/bigram))
    => turetilmis terimlerin köklerini alalim
         - madencilik, maden 
             => kok kullanma: madencilik 1 defa ve maden 1 defa geciyor 
             => kok kullanirsak (ve madencilik koku maden ise): maden 2 defa geciyor 
    => kucuk harf haline getirelim, noktalama isaretlerini kaldiralim, iki kelimeden olusan terimleri
         - Finans/finans ayni kelime mi? => büyük/küçük harf farkını gözetecek miyiz?

2. Sayısal degerleri ne olsun?
    => Terim var ya da yok (0/1), terimlerin geçme sıklıkları (5, 3, 15 ..), Tfidf skorlari
      - Kelime dokümanda geçiyor ya da geçmiyor => ikili => 0 ya da 1 değerini alır
      - Kelimenin dokümandaki geçme sıklığı => finans kelimesi dokümanda 5 defa geçiyor
      - Kelimenin dokümandaki Tf-idf (Term frequency-inverse document frequency) skoru => finans kelimesinin dokümandaki tf-idf skoru 0.275tir

# unigram ve bigram kullanimi
ben veri madenciliği öğreniyorum
# yukaridaki satırdaki cumle icin terimler 
# unigram
ben, veri, madenciliği, öğreniyorum ==>> terimleridir

# bigram - iki kelimeden olusan terimler
ben veri, veri madenciliği, madenciliği öğreniyorum ==>> terimleridir

# hem unigram, hem de bigram kelimelerden oluşan terimler
ben, veri, madenciliği, öğreniyorum, ben veri, veri madenciliği, madenciliği öğreniyorum

# Vektörleştirme - Doküman vektörleştirme
# Vectorization
# ==>> X matrisi nasil olusturulur?
# vektorlestirme adimi sonucunda Terim-doküman matrisi elde edilmektedir.



"""### Term by Document Matrix 
- Feature Matrix / Özellik Matrisi

#### Özellik Matrisini Oluşturma / Feature Extraction (Özellik çıkarımı)
- 2./3. Adım (Veri madenciliği sürecindeki)
- Representation Learning
"""

from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer

# Gereksinimler
# 1. dokumanlar vektorize edildiklerinde esit sayida ozellige (terime) sahip olmalari gerekmektedir.
# -> ozellik olarak (corpustaki) tum dokumanlarda gecen terimlerin hepsini kullanabiliriz.

# Veri madenciliginde => X, y
# Metin madenciliginde => corpus, y

corpus = ['This is the first document.',
          'This is the second, second document.',
          'And this is the third one about text.',
          'Is this the first document about data?']

belgeler = ['Bu ilk belge.',
            'Bu ikinci yani ikinci belge.',
            'Ve bu metinle ilgili üçüncüsü.',
            'Bu, verilerle ilgili ilk belge mi?']

len(corpus) # corpusta kaç adet doküman var (ogrenme ve degerlendirmenin gerceklestirilirken kullanilacak orneklerimizin sayisi)

# tek kelimeden olusan terimler (unigram) - kucuk harfe donusturdugumuzu varsayalim
# ==>> this, is, the, first, document, second, and, third, one, about, text, data
# ==>> bu, ilk, belge, ikinci, yani, ve, metinle, ilgili, üçüncüsü, verilerle, mi

# sklearn.feature_extraction.text modulunu kullanacagiz
# metinden özellik çıkarımı !!!

# feature_extraction.text => CountVectorizer
# => Convert a collection of text documents to a matrix of token counts.
# => Metin belgelerini, bir belirteç (terim) sayısı (sıklığı) matrisine dönüştürür.

# feature_extraction.text => TfidfVectorizer
# Convert a collection of raw documents to a matrix of TF-IDF features.
# => Belge koleksiyonunu bir TF-IDF (skor) özellikleri matrisine dönüştürür.

"""- [CountVectorizer sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer)
- [TfidfVectorizer sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer)
"""

from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
# NOT: CountVectorizer ve TfidfVectorizer özellik çıkarımı açısından benzer şekilde çalışır. 
# ==>> Sadece her bir doküman-terim ikilisi için hesaplanan sayısal değerleri farklı hesaplarlar.
# 1. fit => özellikler nelerdir? => terimler nelerdir? 
#       ==>> terimler bulunduktan sonra, terimleri alfabetik sıralayarak ozellikleri/terimleri çıkarıyor (feature extraction)
# 2. transform => corpusu vektörize et (dokümanları hepsini tek tek vektörize et) 
#              => corpus => X
#              => doküman örneklerini vektörize eder

# ozellik cikarim nesnesinin olusturulmasi
vect_c = CountVectorizer()

# 1. adim => fit => dokumanlardan ozelliklerin çıkarımını gerçekleştir
vect_c.fit(corpus)

# ozelliklerim/terimlerim neler?
vect_c.get_feature_names_out()
# ==>> numpy ndarray biciminde terimleri/ozellikleri donduruyor <= array([
# ==>> terimler harf sirasina gore siralanmis olarak donduruluyor
# ==>> noktalama işaretleri kaldırılmış
# ==>> ve tum terimler kucuk harf olarak getiriliyor

ozellik_listesi = vect_c.get_feature_names_out()
type(ozellik_listesi)

print(ozellik_listesi.shape)
print(ozellik_listesi)

# 2. adim => transform => ozelliklerden, belirlenen sayilama yaklasimini (countv, tfidfv) kullanarak ozellik matrisini olusturur
X_corpus_cnt = vect_c.transform(corpus)

X_corpus_cnt
# Sparse/Seyrek -> matrisin içinde çok sayıda 0 değeri vardır
# 4x12 lik bir matris => 4 tane dokumanin icinde toplam 12 tane terim varmis.
# normal formattaki matriste toplam 4*12=48 sayi vardir fakat sparse matris formatin toplamda 25 tane sayi bulunmakta
# geriye kalan 13 tane sayi degeri 0 gelmektedir.

type(X_corpus_cnt) # csr => Compressed Sparse Row

# icinde 0'dan farkli deger olan elemanlarin indekslerini ve degerlerini tutan veri yapisi
print(X_corpus_cnt)
# (0, 3) ==>> indeks ---	1 ==>> deger
#  0. indeksteki dokumanda, 3. indeksteki terim icin gecme sıklığı (1 dir)

# X: term by doc matrix => feature matrix 
# satırlar: dokümanlar
# sütunlar: terimler => feature
X_corpus_cnt.toarray()

terim_dokuman_matrisi = X_corpus_cnt.toarray()
print(terim_dokuman_matrisi.shape)

# corpustaki 3. dokuman (2. indeksteki dokuman)
print(corpus[2])                  # => dokuman
print(terim_dokuman_matrisi[2])   # => dokumanin vektorize edilmis hali
# dokuman, dokumanin vektor karsiligi
# vektor sparse bir vektor (icinde cok sayida 0 barindiriyor) !!!

# ozellik/terim listesini donduruyor => vect_c.get_feature_names_out()
ozellik_listesi = vect_c.get_feature_names_out()
print(ozellik_listesi)
# corpustaki kelimelerin sozlugu => alfabetik siraya gore kucukten buyuge sirali halde
# fit fonk. ogrendigi seylerden ilki
# ozellik matrisimde kac tane ozellik var - yani 12 tane terim var
print( len(ozellik_listesi) )
print( len(vect_c.get_feature_names_out()) )

import pandas as pd
# terim dokuman matrisini pandas DataFrame'e donusturelim
X_corpus_cnt_pd = pd.DataFrame(terim_dokuman_matrisi, columns=ozellik_listesi)
# X_corpus_cnt_pd = pd.DataFrame(X_corpus_cnt.toarray(), columns=vect_c.get_feature_names_out())
X_corpus_cnt_pd

# Yukaridaki yapilan islemler biraraya getirilise
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
import pandas as pd
# ozellik cikarim nesnesinin olusturulmasi
vect_c = CountVectorizer()
vect_c.fit(corpus)
X_corpus_cnt = vect_c.transform(corpus)

ozellik_listesi = vect_c.get_feature_names_out()
terim_dokuman_matrisi = X_corpus_cnt.toarray()

# terim dokuman matrisini pandas DataFrame'e donusturelim
X_corpus_cnt_pd = pd.DataFrame(terim_dokuman_matrisi, columns=ozellik_listesi)
print(ozellik_listesi)
X_corpus_cnt_pd

# Yukaridaki yapilan islemler TfidfVectorizer kullanarak yapilirsa
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
import pandas as pd
# ozellik cikarim nesnesinin olusturulmasi
vect_t = TfidfVectorizer()
vect_t.fit(corpus)
X_corpus_tf = vect_t.transform(corpus)

ozellik_listesi_t = vect_t.get_feature_names_out()
terim_dokuman_matrisi_t = X_corpus_tf.toarray()
# terim dokuman matrisini pandas DataFrame'e donusturelim
X_corpus_tf_pd = pd.DataFrame(terim_dokuman_matrisi_t, columns=ozellik_listesi_t)
print(ozellik_listesi_t)
X_corpus_tf_pd

"""##### Ozellik Cikariminda 1. sorunun cevabi
- 1. Özellikler/Terimler ne olsun ?
"""

# 1. Özellikler/Terimler ne olsun ? (parametreler => lowercase?, stemming?, n-gram (unigram/bigram/...))
#                                                 --> (Veri *** veri, Onur *** onur -> aynı kelimeler olarak mı alınmalı)
#
#    => turetilmis terimlerin köklerini alalim
#         - madencilik, maden 
#             => kok alınMIyorsa: madencilik 1 defa ve maden 1 defa geciyor 
#             => kok alınıyorsa (ve madencilik kelimesinin koku maden ise): maden 2 defa geciyor 
#    => kucuk harf haline getirelim, noktalama isaretlerini kaldiralim, iki kelimeden olusan terimleri kullanalim mi?
#         - Finans/finans ayni kelime mi? => büyük/küçük harf farkını gözetecek miyiz?

# 1.1. n-gram
# yukarida unigram (1-gram) olarak ozellik cikarimi gerceklestirilmistir

# 1.1. n-gram
# ngram_range=(1, 1) # ==>> en az 1 kelimeden olusan ve en fazla 1 kelimeden olusan terimleri cikarimla ===>>> sadece unigram
# ngram_range: tuple (min_n, max_n), default=(1, 1)
# The lower and upper boundary of the range of n-values for different word n-grams or char n-grams to be extracted.
# Çıkarılacak farklı kelime n-gramları veya karakter n-gramları için n-değer aralığının alt ve üst sınırı.

# Bigram ozellikler - terimler
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import CountVectorizer # terimleri nasil sayiyoruz (2. sornun cevabini) burada belirledik

# sadece bigram terimleri kullan
vc2 = CountVectorizer(ngram_range=(2, 2))
vc2.fit(corpus)
ozellik_listesi_vc2 = vc2.get_feature_names_out()
print(len(ozellik_listesi_vc2))
print(ozellik_listesi_vc2)

'And this is the third one about text.'
=> # kucuk harfe donusturup, noktalama isaretlerini kaldir
'and this is the third one about text'
=> # bigram terimlerin bulunmasi
and this, this is, is the, the third, third one, one about, about text

'Ve bu metinle ilgili üçüncüsü.'
=> # kucuk harfe donusturup, noktalama isaretlerini kaldir
've bu metinle ilgili üçüncüsü'
=> # bigram terimlerin bulunmasi
ve bu, bu metinle, metinle ilgili, ilgili üçüncüsü

X_vc2 = vc2.transform(corpus)
terim_dokuman_matrisi_vc2 = X_vc2.toarray()
X_vc2_pd = pd.DataFrame(terim_dokuman_matrisi_vc2, columns=ozellik_listesi_vc2)
print(ozellik_listesi_vc2)
X_vc2_pd

# Unigram ve Bigram ozellikler beraber - terimler
from sklearn.feature_extraction.text import CountVectorizer # nasil sayiyoruz burada belirledik
# ngram_range: tuple (min_n, max_n), default=(1, 1)
vc_1_2 = CountVectorizer( ngram_range=(1,2) ) # en az 1-gram, en fazla 2-gram (hem 1-gram hem de 2-gram) terimleri kullan
vc_1_2.fit(corpus)
print(vc_1_2.get_feature_names_out())
print( len(vc_1_2.get_feature_names_out()) )
########
X_vc_1_2 = vc_1_2.transform(corpus)
print("## Özellik Matrisi (Term-by-document matrix) ##")
print(X_vc_1_2.toarray())
X_vc_1_2_pd = pd.DataFrame(X_vc_1_2.toarray(), columns=vc_1_2.get_feature_names_out())
X_vc_1_2_pd

'And this is the third one about text.'
=> # kucuk harfe donusturup, noktalama isaretlerini kaldir
'and this is the third one about text'
=> # bigram terimlerin bulunmasi
and this, this is, is the, the third, third one, one about, about text
=> # unigram+bigram terimlerin bulunmasi
and, this, is, the, third, one, about, text, and this, this is, is the, the third, third one, one about, about text

'Ve bu metinle ilgili üçüncüsü.'
=> # kucuk harfe donusturup, noktalama isaretlerini kaldir
've bu metinle ilgili üçüncüsü'
=> # bigram terimlerin bulunmasi
ve bu, bu metinle, metinle ilgili, ilgili üçüncüsü
=> # unigram+bigram terimlerin bulunmasi
ve, bu, metinle, ilgili, üçüncüsü, ve bu, bu metinle, metinle ilgili, ilgili üçüncüsü

# Unigram, Bigram ve Trigram ozellikler beraber - terimler
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer # nasil sayiyoruz burada belirledik
# ngram_range: tuple (min_n, max_n), default=(1, 1)
vc_1_2_3 = CountVectorizer( ngram_range=(1,3) ) # hem 1-gram, hem 2-gram, hem de 3-gram terimleri kullan
vc_1_2_3.fit(corpus)
print(vc_1_2_3.get_feature_names_out())
print( len(vc_1_2_3.get_feature_names_out()) )
########
X_vc_1_2_3 = vc_1_2_3.transform(corpus)
print("## Özellik Matrisi (Term-by-document matrix) ##")
print(X_vc_1_2_3.toarray())
X_vc_1_2_3_pd = pd.DataFrame(X_vc_1_2_3.toarray(), columns=vc_1_2_3.get_feature_names_out())
print(X_vc_1_2_3_pd)

# STOPWORDS !!???
# Unigram, Bigram ve Trigram ozellikler beraber - terimler
vc_1_2_3_sw = CountVectorizer( ngram_range=(1,3), stop_words='english' )
# hem 1-gram, hem 2-gram, hem de 3-gram terimleri kullan
# and, the, this .. gibi kelimeler gereksiz kelimeler olarak, ozelliklerden atilacak
vc_1_2_3_sw.fit(corpus)
print( len(vc_1_2_3_sw.get_feature_names_out()) )
print(vc_1_2_3_sw.get_feature_names_out())
#######
X_vc_1_2_3_sw = vc_1_2_3_sw.transform(corpus)
print("## Özellik Matrisi (Term-by-document matrix) ##")
print(X_vc_1_2_3_sw.toarray())
X_vc_1_2_3_sw_pd = pd.DataFrame(X_vc_1_2_3_sw.toarray(), columns=vc_1_2_3_sw.get_feature_names_out())
print(X_vc_1_2_3_sw_pd)

# stop_words='english'
# stopwords'ler atilmadan once unigram terimler olarak
'about', 'and', 'data', 'document', 'first', 'is', 'one', 'second', 'text', 'the', 'third', 'this'

# stopwords atildiktan sonraki unigram terimler olarak
'data', 'document', 'second', 'text'

# yani sklearn countvectorizer icindeki stopwords icinde asagidaki terimler bulunmaktaymis
'about', 'and', 'first', 'is', 'one', 'the', 'third', 'this' => stopwords terimleri olarak bulunmaktalar

# scikit learn icindeki stopwords kelime listesi
from sklearn.feature_extraction import text
print(text.ENGLISH_STOP_WORDS)
print("stopwords kelimeleri kümesindeki kelime sayısı:")
print(len(text.ENGLISH_STOP_WORDS))

# NOT:
# text modulunu import ettikten sonra direk text modulunun aldindaki Count ya da Tfidf Vectorizer modullerini cagirabiliyoruz
vect_text_modulunden = text.CountVectorizer()

# Kendi STOPWORDS !!???
# Unigram, Bigram ve Trigram ozellikler beraber - terimler
# Kendi olusturdugumuz stopwords kelime listesi
kendi_stdws = ['and', 'is', 'the']
vc_1_2_3_sw_kendi = CountVectorizer( ngram_range=(1,3), stop_words=kendi_stdws)
# is, and, the kelimeleri gereksiz kelimeler olarak ozelliklerden atiyoruz
vc_1_2_3_sw_kendi.fit(corpus)
print( len(vc_1_2_3_sw_kendi.get_feature_names_out()) )
print(vc_1_2_3_sw_kendi.get_feature_names_out())
#######
X_vc_1_2_3_sw_kendi = vc_1_2_3_sw_kendi.transform(corpus)
print("## Özellik Matrisi (Term-by-document matrix) ##")
print(X_vc_1_2_3_sw_kendi.toarray())
X_vc_1_2_3_sw_pd_kendi = pd.DataFrame(X_vc_1_2_3_sw_kendi.toarray(), columns=vc_1_2_3_sw_kendi.get_feature_names_out())
print(X_vc_1_2_3_sw_pd_kendi)

"This is the first document."
=> 
"this is the first document"
Stopwords kisminin uygulanmasi
kendi_sws = ['is', 'and', 'the']
=>
"this first document"
=>
unigram+bigram
'this', 'first', 'document', 'this first', 'first document'

"""##### Min_df ve max_df parametreleri"""

## MAX_DF ##
# max_df: float in range [0.0, 1.0] or int, default=1.0
# When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words). If float, the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None.
# Sözcük dağarcığını (özellikleri bulurken) oluştururken, verilen eşikten kesinlikle daha yüksek bir belge frekansına sahip terimler yok sayılır (özelliklerden çıkarılır) (bütünceye özgü durdurma sözcükleri). Float ise, parametre belgelerin bir oranını temsil eder, tamsayı mutlak sayıları.
# 1000 dokuman
# max_df -> 100 (int)   ==> 100den fazla dokümanda gecen terimler ozelliklerden çıkarılacaktır
# max_df -> 0.9 (float) ==> dokümanlarin yuzde 90indan (900 dokümandan) daha fazla dokumanda gecen terimler ozelliklerden çıkarılacaktır

## MIN_DF ##
# min_df: float in range [0.0, 1.0] or int, default=1
# When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold. This value is also called cut-off in the literature. If float, the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None.
# Kelime dağarcığı (özellikleri bulurken) oluştururken, verilen eşikten kesinlikle daha düşük bir belge frekansına sahip terimleri göz ardı edilecektir (ozelliklerden çıkarılacaktır). Bu değer literatürde cut-off olarak da adlandırılmaktadır. Float ise, parametre belgelerin bir oranını temsil eder, tamsayı mutlak sayıları. Sözlük Yok değilse bu parametre yok sayılır.
# 1000 dokuman
# min_df -> 0.1 (float) ==> dokümanlarin yuzde 10undan (100 dokümandan) daha az dokumanda gecen terimler ozelliklerden çıkarılacaktır
# min_df -> 10 (int)    ==> 10dan az dokumanda gecen kelimeler ozelliklerden atiliyor

# 3 kelimeden olusan terimleri de barindiran - ngram_range=(1,3)
print(len(vc_1_2_3.get_feature_names_out()))
print(vc_1_2_3.get_feature_names_out())

corpus

len(corpus)

# Min/Max df
from sklearn.feature_extraction.text import CountVectorizer
vc_mmdf = CountVectorizer( ngram_range=(1,3), max_df=0.5)
# max_df=0.5 --> 4*0.5=2 tane dokumandan daha fazla dokumanda geciyorsa terim, o terim ozelliklerden cikariliyor
# terim en fazla 2 dokumanda gecsin !! Daha fazla dokumanda geciyorsa o terim, ozelliklerden cikarilmalidir
vc_mmdf.fit(corpus)
print(vc_mmdf.get_feature_names_out())
print( len(vc_mmdf.get_feature_names_out()) )
########
X_vc_mmdf = vc_mmdf.transform(corpus) # corpustaki dokumanlari vektörize ediyoruz
print("## Özellik Matrisi (Term-by-document matrix) ##")
print(X_vc_mmdf.toarray())
X_vc_mmdf_pd = pd.DataFrame(X_vc_mmdf.toarray(), columns=vc_mmdf.get_feature_names_out())
X_vc_mmdf_pd

# NOT:
#       'document' terimi 3 dokumanda (0.75), 'this' terimi ise 4 dokumanda (1.0) gectigi icin ozellik listesinden cikarilmislardir.
# Fakat 'document about' terimi 1 dokumanda (0.25), 'about' terimi ise 2 dokumanda (0.5) gectigi icin ozellik (listesinde bulunuyorlardir) listesinden cikarilMAmislardir.

# Min/Max df
from sklearn.feature_extraction.text import CountVectorizer
vc_mmdf2 = CountVectorizer( ngram_range=(1,2), max_df=0.5, min_df=2 )
# max_df=0.5 --> 4*0.5=2 tane dokumandan daha fazla dokumanda geciyorsa terim, o terim ozelliklerden cikariliyor
# => max_df en fazla 2 dokumanda bulunsun, min_df=2 de, en az 2 dokumanda bulunsun => yani 2 dokumanda bulunanlar kalsin
# ==>> en az 2 ve en fazla 2 dokumanda bulunsun dendiginden 2 dokumanda bulunsun denmis oldu
vc_mmdf2.fit(corpus)
print( len(vc_mmdf2.get_feature_names_out()) )
print(vc_mmdf2.get_feature_names_out())

"""##### Ozellik Cikarimindaki 2. sorunun cevabi
- 2. Sayısal degerleri ne olsun?
- sayisal temsil cikarimi nasil yapilsin

"""

# 2. Sayısal degerleri ne olsun? 
#     => Terim dokümanda var ya da yok (0/1), terimin dokümandaki geçme sıklıkları (5, 3, 15 ...), Tfidf skorlari (1.55, 0.13, 2.88), ...
#       - Kelime dokümanda geçiyor ya da geçmiyor => ikili => 0 ya da 1 değerini alır
#       - Kelimenin dokümandaki geçme sıklığı => finans kelimesi dokümanda 5 defa geçiyor
#       - Kelimenin dokümandaki Tf-idf (Term frequency-inverse document frequency) skoru => finans kelimesinin dokümandaki tf-idf skoru 0.275tir

from sklearn.feature_extraction.text import CountVectorizer
vectorizer_ = CountVectorizer( ngram_range=(1,1), max_df=0.5 )
vectorizer_.fit(corpus)
print( len(vectorizer_.get_feature_names_out()) )
print(vectorizer_.get_feature_names_out())
#######
X_corpus = vectorizer_.transform(corpus) # vektörize ediyoruz
print(X_corpus.toarray())
X_corpus_pd = pd.DataFrame(X_corpus.toarray(), columns=vectorizer_.get_feature_names_out())
print(X_corpus_pd)

from sklearn.feature_extraction.text import TfidfVectorizer
vectorizer_ = TfidfVectorizer( ngram_range=(1,1), max_df=0.5 )
vectorizer_.fit(corpus)
print( len(vectorizer_.get_feature_names_out()) )
print(vectorizer_.get_feature_names_out())
#######
X_corpus = vectorizer_.transform(corpus) # vektörize ediyoruz
print(X_corpus.toarray())
X_corpus_pd = pd.DataFrame(X_corpus.toarray(), columns=vectorizer_.get_feature_names_out())
print(X_corpus_pd)

# Tf-Idf skoru hesaplanmasi
# bir terimin, bir belgedeki tf-idf skoru ne kadar yuksekse, o terim, o belge icin o kadar oneme sahiptir
'veri' kelimesinin corpusta bulunan bir belgedeki tf-idf skoru nedir?
                                    bu belgede veri kelimesi 5 defa geçiyorsa
                                    bu belgede en çok geçen kelime 10 defa geçiyor
       bu kelime (veri kelimesi) corpusta bulunan 1000 adet dokumandan 100 tanesinde geciyor.

tf-idf
tf => term frequency => terim sıklığı -> bir terimin bir dokümanda geçme sıklığının normalize edilmiş hali
   -> terimin geçme sıklığı / dokümanda en fazla geçen terimin geçme sıklığı
   -> 5/10 = 0.5

idf => inverse document frequency => ters doküman sıklığı
    -> log2(N/ni) => log2(corpustaki doküman sayısı / terimin içinde geçtiği doküman sayısı)
    -> log2(1000 / 100) = log2(100) = 3.32

tf-idf => tf*idf => 0.5 * 3.32 = 1.62
# NOT: CountVectorizer kullanimda deger 5 olacakti.

import numpy as np
print( np.log2(1000 / 100)  )  # 1000 dokumanin 100 tanesinde geciyor
print( np.log2(1000 / 10)  )  # 1000 dokumanin 10 tanesinde geciyor
print( np.log2(1000 / 1)  )  # 1000 dokumanin 1 tanesinde geciyor

"""### Spam e-posta Sınıflandırması 
- Kelime Torbası Yaklaşımı (Bag-of-Words) ile
    - kelimelerin hangi sırayla geçtiği, hangi içerikte bulunduğu göz önüne alınmıyor
"""

import pandas as pd
df_emails = pd.read_csv("spam_std.csv")
# UnicodeDecodeError: 'utf-8' codec can't decode bytes in position 755-756: invalid continuation byte
# problem encoding ile alakali

import pandas as pd
df_emails = pd.read_csv("spam_std.csv", encoding='latin-1')

type(df_emails)

df_emails.shape

df_emails.head(10)
# ham: normal eposta
# spam: spam eposta

# verinin .csv dosyasindaki orjinal halinin ilk 2 satiri
first,second,,,
ham,Do u noe wat time e place dat sells 4d closes?,,,
# NOT 1:
# ilk satir => etiketleri bulunduruyor => ham/spam
# ikinci satir => epostalari bulunduruyor => (NOT: bazi satirlar icin 3.,4. ve 5. sutunlar epostalarin devamini iceriyor)
# bu kodda 2. sutun disindaki eposta parcalarini gormezden geliyoruz !!
# NOT 2:
# ilk satirda adi bulunmayan sutunlarin isimlerini pandas kendisini Unnamed: 0-bazli indeks olarak veriyor => Unnamed: 2	Unnamed: 3	Unnamed: 4

# 1. 
atilacak_sutunlar = ['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4']
df_emails.drop(columns=atilacak_sutunlar) # stringler gibi yerinde degil kopyasi uzerinde degisiklik yapiliyor
# doc = doc.lower() ==>> eger doc'un gosterdigi dokuman degistirilmek istenirse
# df_emails = df_emails.drop(columns=atilacak_sutunlar)

df_emails.head(2)  # orjinal veri degismedi

# 2.
df_emails.drop(columns=atilacak_sutunlar, inplace=True) # listeler gibi yerinde/orjinalinde degisiklik yapiliyor
# inplace=True => degisikligi orjinal veri uzerinde yani yerinde yap

df_emails.head(2)  # orjinal veri degistirildi

# sutun isimlerini daha anlamlilariyla degistirelim
df_emails.rename(columns={'first':'etiketler', 'second':'belgeler'}, inplace=True)
#df_emails.rename(columns={'first':'labels', 'second':'documents'}, inplace=True)
# belgeler ==> documents ==> corpus

df_emails.head(2)  # orjinal veri degistirildi

# corpus ve hedef degisken vektorlerinin alinmasi
corpus = df_emails['belgeler']
# => ozellik matrisini olustururken kullanacagimiz epostalarin metinleri - su anda elimizde X yok
# => X (ozellik matrisini) elde etmek icin Vectorizer kullanacagiz
y = target = df_emails['etiketler']
# ==> hedef degisken vektoru - etiketler (epostalarin spam mi ham(normal) mi olduklarinin bilgisi) => tahminlemek istedigimiz

type(corpus), type(target)

corpus.shape, target.shape

corpus.head(3)

target.head(3)

# sinif dagilimlarini gorelim
target.value_counts()

target.value_counts(normalize=True)
# imbalance/dengesiz sinif dagilimi (1e 7 orani)
# imbalance (undersampling/oversampling)
# ==>> degerlendirme yapilirken veri train test olarak 2 ayrilirken, sampling icin strafied sampling kullanilir

"""##### Metin madenciliginde 4. ve 5. adımlar

"""

# 4. ve 5. adimlar => Model olusturma ve degerlendirme
# simple split
### ONCE DOKUMANLARI TRAIN ve TEST olarak 2ye ayirip
### SONRASINDA X_TRAIN ve X_TEST ozellik matrislerini olusturuyoruz
### !!! once X yani ozellik matrisini olusturup sonra matrisi X_train ve X_test olarak 2ye ayirMIyoruz !!!
from sklearn.model_selection import train_test_split
# !!!! corpusu ve targeti, train ve test olarak 2ye ayiralim
# !!! X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42) => YAPMIYORUZ !!!
corpus_train, corpus_test, y_train, y_test = train_test_split(corpus, y, test_size=0.2, random_state=42, stratify=y)

print(corpus_train.shape, corpus_test.shape, y_train.shape, y_test.shape)

type(corpus_train)

corpus_train.head(2)

y_train.head(2)

"""###### CountVectorizer Kullanimi"""

from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
vect_c_eposta = CountVectorizer( ngram_range=(1,1) )
vect_c_eposta.fit(corpus_train)  # !!!!! tum corpus ile degil !!!

print(vect_c_eposta.get_feature_names_out())
print(len(vect_c_eposta.get_feature_names_out()))
# 4372 tane ozellik kullanilacaktir => 4372 tane terim cikarimi yapilmistir

print(vect_c_eposta.get_feature_names_out()[:20])
# ORNEK: tarih iceren sayilar ozelliklerde tutulup, digerleri ozelliklerden cikarilabilir
#        ==> NER (adlandirilmis varlik tanima)
# -------
# terimler incelendiginde, anlamsiz terimler oldugu gorulmekte
# bu sebeple, epostalarin on islemden (text preprocessing !!) gecirilmeleri gerekmektedir !

# X_train ??
X_train_eposta = vect_c_eposta.transform(corpus_train) # dokumanlarin sayisal vektorlere donusturulmesi

# X_test ??
X_test_eposta = vect_c_eposta.transform(corpus_test) # dokumanlarin sayisal vektorlere donusturulmesi

X_train_eposta.shape, X_test_eposta.shape

X_train_eposta

# 21011 stored elements
1584*4372 # 6925248 tane elemanin sadece 21binini tutuyor
# 6milyon 925bin sayisinin, 9 milyon 904bin tanesinde 0 degeri bulunmakta

"""Eldeki ozellik matrisleri ve hedef degisken vektorleriyle model degerlendirme kismini gerceklestirebiliriz
- veri madenciligi ile benzer sekilde
"""

# Metod => Karar Agaci
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import f1_score, classification_report

# metod nesnesi olusturulur
karar_agaci_metin = DecisionTreeClassifier()
# model egitilir
karar_agaci_metin.fit(X_train_eposta, y_train)

# modelin egitim verisi ve test verisi uzerindeki performanslari olculur
# 1. modelin egitim/train verisi uzerindeki performansi
# tahminleme
y_pred_train = karar_agaci_metin.predict(X_train_eposta)
f1_train = f1_score(y_train, y_pred_train, average='macro')
print(f"Karar agaci modelinin EGITIM VERISI uzerindeki performansi: {f1_train:.3f}")

# modelin test verisi uzerindeki performansi
# tahminleme
y_pred_test = karar_agaci_metin.predict(X_test_eposta)
f1_train = f1_score(y_test, y_pred_test, average='macro')
print(f"Karar agaci modelinin TEST VERISI uzerindeki performansi: {f1_train:.3f}")
cls_rep_test = classification_report(y_test, y_pred_test)
print(cls_rep_test)

# Tahminleme modeli olusturulurken 2 fit yapilmistir
# 1. CountVectorizer ve ngram_range=(1,1)
# 2. Karar agaci - gini

# 2. Karar agaci - gini ==>> parametreleri degistirilsin
# metod nesnesi olusturulur
karar_agaci_metin_e = DecisionTreeClassifier(criterion='entropy')
# model egitilir
karar_agaci_metin_e.fit(X_train_eposta, y_train)
# modelin egitim verisi ve test verisi uzerindeki performanslari olculur
# 1. modelin egitim/train verisi uzerindeki performansi
# tahminleme
y_pred_train = karar_agaci_metin_e.predict(X_train_eposta)
f1_train = f1_score(y_train, y_pred_train, average='macro')
print(f"Karar agaci (entropy) modelinin EGITIM VERISI uzerindeki performansi: {f1_train:.3f}")
# modelin test verisi uzerindeki performansi
# tahminleme
y_pred_test = karar_agaci_metin_e.predict(X_test_eposta)
f1_train = f1_score(y_test, y_pred_test, average='macro')
print(f"Karar agaci (entropy) modelinin TEST VERISI uzerindeki performansi: {f1_train:.3f}")
cls_rep_test = classification_report(y_test, y_pred_test)
print(cls_rep_test)

# Tahminleme modeli olusturulurken 2 fit yapilmistir
# 1. CountVectorizer ve ngram_range=(1,1)
# 2. Karar agaci - entropy

"""###### TfidfVectorizer Kullanimi"""

# fit(corpus_train)
# transform(corpus_train)
# transform(corpus_test)
# tfidfvectorizer ile sayisal degerlerin ogrenilmesi gerceklestirilsin

from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
vect_tf_eposta = TfidfVectorizer(ngram_range=(1,1))
vect_tf_eposta.fit(corpus_train) # !!!!! tum corpus ile degil !!!
print(vect_tf_eposta.get_feature_names_out())
print(len(vect_tf_eposta.get_feature_names_out()))
# 4372 tane ozellik kullanilacaktir => 4372 tane terim cikarimi yapilmistir

# X_train ??
X_train_eposta = vect_tf_eposta.transform(corpus_train) # dokumanlarin sayisal vektorlere donusturulmesi
# X_test ??
X_test_eposta = vect_tf_eposta.transform(corpus_test) # dokumanlarin sayisal vektorlere donusturulmesi

# Metod => Karar Agaci
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import f1_score, classification_report
# metod nesnesi olusturulur
karar_agaci_metin_e = DecisionTreeClassifier(criterion='entropy')
# model egitilir
karar_agaci_metin_e.fit(X_train_eposta, y_train)
# modelin egitim verisi ve test verisi uzerindeki performanslari olculur
# 1. modelin egitim/train verisi uzerindeki performansi
# tahminleme
y_pred_train = karar_agaci_metin_e.predict(X_train_eposta)
f1_train = f1_score(y_train, y_pred_train, average='macro')
print(f"Karar agaci (entropy) modelinin EGITIM VERISI uzerindeki performansi: {f1_train:.3f}")
# modelin test verisi uzerindeki performansi
# tahminleme
y_pred_test = karar_agaci_metin_e.predict(X_test_eposta)
f1_test = f1_score(y_test, y_pred_test, average='macro')
print(f"Karar agaci (entropy) modelinin TEST VERISI uzerindeki performansi: {f1_test:.3f}")
cls_rep_test = classification_report(y_test, y_pred_test)
print(cls_rep_test)
# 1. TfidfVectorizer ve ngram_range=(1,1)
# 2. Karar agaci - entropy

# Bastan sona tumn islemler 
# 1. TfidfVectorizer ve ngram_range=(1,2)
# 2. Karar agaci - entropy
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
vect_tf_eposta = TfidfVectorizer(ngram_range=(1,2))
vect_tf_eposta.fit(corpus_train) # !!!!! tum corpus ile degil !!!
print(vect_tf_eposta.get_feature_names_out())
print(len(vect_tf_eposta.get_feature_names_out()))
# 19910 tane ozellik kullanilacaktir => 19910 tane terim cikarimi yapilmistir
# X_train ??
X_train_eposta = vect_tf_eposta.transform(corpus_train) # dokumanlarin sayisal vektorlere donusturulmesi
# X_test ??
X_test_eposta = vect_tf_eposta.transform(corpus_test) # dokumanlarin sayisal vektorlere donusturulmesi

# Metod => Karar Agaci
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import f1_score, classification_report
# metod nesnesi olusturulur
karar_agaci_metin_e = DecisionTreeClassifier(criterion='entropy')
# model egitilir
karar_agaci_metin_e.fit(X_train_eposta, y_train)
# modelin egitim verisi ve test verisi uzerindeki performanslari olculur
# 1. modelin egitim/train verisi uzerindeki performansi
# tahminleme
y_pred_train = karar_agaci_metin_e.predict(X_train_eposta)
f1_train = f1_score(y_train, y_pred_train, average='macro')
print(f"Karar agaci (entropy) modelinin EGITIM VERISI uzerindeki performansi: {f1_train:.3f}")
# modelin test verisi uzerindeki performansi
# tahminleme
y_pred_test = karar_agaci_metin_e.predict(X_test_eposta)
f1_test = f1_score(y_test, y_pred_test, average='macro')
print(f"Karar agaci (entropy) modelinin TEST VERISI uzerindeki performansi: {f1_test:.3f}")
cls_rep_test = classification_report(y_test, y_pred_test)
print(cls_rep_test)

"""##### Model Degerlendirme Fonksiyonu - Otomatizasyon - Metin Madenciligi
- degerlendirme fonksiyonu
"""

# model_degerlendirme fonksiyonu - metin madenciligi
# ==>> stratified k-fold sonuclarini donduren
# import'lar
# train-test ayrışımı
from sklearn.model_selection import StratifiedKFold
# performans ölçütü
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
# zaman performansı
import time
import numpy as np
import pandas as pd

# Herhangi bir metodun ornek veri uzerindeki performansi ile degerlendirilmesi
# k-katlamalı (stratified) çapraz doğrulama ile bir metodun performansının ölçülmesi
#def model_degerlendirme(X_all, y_all, metod, olcut='f1', numsplits=5):
def model_degerlendirme_metin(corpus, y, vect, metod, olcut='f1', numsplits=5):
    '''
        vect: metin halindeki dokumanlari sayisal Vektorlere donusturecek vectorize etme yaklasiminin nesnesi
              NOT: egitilmemis (.fit edilmemis) vektorizer nesnesi. Fonksiyon icinde egitilecek (.fit)
        corpus (pandas Series ya da numpy.ndarray veri yapisinda): corpus (örnek sayısı,) -> (number of instances, )
              => Olusturulacak olan (.fit edilmis olan) vect kullanilarak ! X_train ve X_test elde edilecektir
                 -> özellik matrisi (örnek sayısı, özellik sayısı) -> (number of instances, number of features)
        y: etiket/hedef değişken vektörü (örnek sayısı,) -> (number of instances,)
        metod: tahminleme yapacak modelin egitimi icin kullanilacak yaklasimin nesnesi
    '''
    # verinin katmanlı olarak 5(numsplits) alt kümeye (fold) ayrılması ve her alt kümenin (fold'un) döngü içinde test verisi olarak kullanımı
    skf = StratifiedKFold(n_splits=numsplits, shuffle=True, random_state=33)
    # performans verileri
    performans_degerleri = []
    # süre performanslari
    sure_egitim = [] # modelin train edilirken harcadigi zaman
    sure_tahmin = [] # modelin test icin tahminleme yaparken harcadigi zaman
    # numsplits 5 ise
    # [(train1,test1), (train2,test2), (train3,test3), (train4,test4), (train5,test5)]
    for train_index, test_index in skf.split(corpus, y):
        # train/test verisinin oluşturulması - indekslerin kullanılarak örneklerim seçilimi
        # => X_train, X_test, y_train, y_test
        corpus_train = corpus.iloc[train_index]
        corpus_test = corpus.iloc[test_index]
        y_train = y.iloc[train_index]
        y_test = y.iloc[test_index]

        # train ve test corpusunun vektorize edilmesi (X_train, X_test in yani Ozellik matrislerinin elde edilmesi)
        ### 1. egitim
        vect.fit(corpus_train)
        # 2. donustur
        X_train = vect.transform(corpus_train)
        X_test = vect.transform(corpus_test)

        # Sınıflandırma modelinin eğitilmesi ve test performansının ölçümlenmesi
        baslangic_zamani_egitim = time.time()
        # model oluştur => train
        #### Eğitim - Training
        metod.fit(X_train, y_train) ### Model eğitim - .fit
        bitis_zamani_egitim = time.time()

        #### Test verisinin Tahminlemesi - Prediction
        # tahminleri al - Hem eğitim verisinin Hem de Test verisinin
        # y_pred_train = metod.predict(X_train) # ? overfit var mi? sorusu icin kullanilacak
        ### Modelin tahminlemesi - .predict
        y_pred_test = metod.predict(X_test) # ==>> performans degerlendirmesi icin kullanilacak
        bitis_zamani_tahminleme = time.time()

        #### Süre Performans ölçümleme
        egitim_suresi = bitis_zamani_egitim - baslangic_zamani_egitim
        tahminleme_suresi = bitis_zamani_tahminleme - bitis_zamani_egitim
        sure_egitim.append(egitim_suresi)
        sure_tahmin.append(tahminleme_suresi)
        
        #### Tahminleme Başarısının Performansını ölçümleme
        # performans ölçümü (test)
        if olcut == 'acc':
            performans = accuracy_score(y_test, y_pred_test)
        elif olcut == 'prec':
            performans = precision_score(y_test, y_pred_test, average='macro')
        elif olcut == 'rec':
            performans = recall_score(y_test, y_pred_test, average='macro')
        elif olcut == 'f1':
            performans = f1_score(y_test, y_pred_test, average='macro')
        else:
            print("Default ölçüt olan accuracy kullanılmıştır")
            performans = accuracy_score(y_test, y_pred_test)
        # performansin saklanması (test)
        performans_degerleri.append(performans)
    return performans_degerleri, sure_egitim, sure_tahmin
    # return degeri birden fazla piton nesnesi ise => sonucu tuple olarak dondurur

# Model, Vektorize edici ve Parametre Seçilimi - Model/Parameter Selection
# METOTLAR
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier 
from sklearn.linear_model import LogisticRegression
from sklearn.neural_network import MLPClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import MultinomialNB
from sklearn.neighbors import KNeighborsClassifier
nn5u = KNeighborsClassifier(n_neighbors=5, weights='uniform')
nn5d = KNeighborsClassifier(n_neighbors=5, weights='distance')
lg = LogisticRegression(penalty='l2', C=1.0, solver='liblinear', max_iter=1000)
rf = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None)
dte = DecisionTreeClassifier(criterion='entropy', max_depth=None)
mlp = MLPClassifier(hidden_layer_sizes=(30,), max_iter=1000)
svc = SVC(C=1.0, kernel='linear')
mn_nb = MultinomialNB()

# farkli siniflandirma yontemlerini sozlukte tutalim
siniflandirici_sozlugu = {"NNeiU":nn5u, "NNeiD":nn5d, "LG":lg, "RF":rf, "DTE":dte, "MLP":mlp, "SVC":svc, "MN_NB":mn_nb}

# VECTORIZERLAR
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
vect_c = CountVectorizer(ngram_range=(1,1))
vect_c_ub = CountVectorizer(ngram_range=(1,2))
vect_t = TfidfVectorizer(ngram_range=(1,1))
vect_t_ub = TfidfVectorizer(ngram_range=(1,2))
vect_c_mm = CountVectorizer(ngram_range=(1,1), min_df=2, max_df=0.80)
vect_c_ub_mm = CountVectorizer(ngram_range=(1,2), min_df=2, max_df=0.80)
vect_t_mm = TfidfVectorizer(ngram_range=(1,1), min_df=2, max_df=0.80) # max_df etkisi idf hesabindan dolayi azdir
vect_t_ub_mm = TfidfVectorizer(ngram_range=(1,2), min_df=2, max_df=0.80)

# farkli vektorize etme yontemlerini sozlukte tutalim
# string olarak vektorize etme yaklasiminin adi anahtar olsun.
# vektorize etme yaklasiminin nesnesini de deger olarak verelim
vect_sozlugu = {"CountVec_Uni": vect_c, "CountVec_UniBi": vect_c_ub, "TfidfVec_Uni": vect_t, "TfidfVec_UniBi": vect_t_ub,
                "CountVec_Uni_mm": vect_c_mm, "CountVec_UniBi_mm": vect_c_ub_mm, "TfidfVec_Uni_mm": vect_t_mm, "TfidfVec_UniBi_mm": vect_t_ub_mm}

# kac farkli model/parametre var
print( len(siniflandirici_sozlugu) )
# kac farkli vektorlestirme yaklasimi var
print( len(vect_sozlugu) )
# kac farkli kombinasyon icin degerlendirme yapiliyor
kac_farkli_komb = len(siniflandirici_sozlugu) * len(vect_sozlugu)
print(f"Degerlendirme yapilirken {kac_farkli_komb} farkli model/parametre ve vektorlestirme yaklasimi kombinasyonu kullanilmaktadir")

perf, sure_e, sure_t = model_degerlendirme_metin(corpus, y, vect_t_ub_mm, mn_nb, olcut='f1', numsplits=5)
print("Vectorizer: TfidfVectorizer(ngram_range=(1,2), min_df=2, max_df=0.80)")
print("Metod: MultinomialNB()")
print("Olcut: f1 skor")
print(perf)
print(np.mean(perf))

perf, sure_e, sure_t = model_degerlendirme_metin(corpus, y, vect_t_ub, mn_nb, olcut='f1', numsplits=5)
print("Vectorizer: TfidfVectorizer(ngram_range=(1,2))")
print("Metod: MultinomialNB()")
print("Olcut: f1 skor")
print(perf)
print(np.mean(perf))

# farkli yaklasimlar icin (yukaridaki ornegimizde 64 farkli) en iyi degeri bulan bir program yaziniz

# metod ve vektorizer ikililerinin performanslarinin sozlugu
metod_vekt_perf_sozlugu = {}
for siniflandirici_adi, siniflandirici_nesnesi in siniflandirici_sozlugu.items():
    # siniflandirici_adi => string
    for vek_adi, vek_nesnesi in vect_sozlugu.items():
        # vek_adi => string
        perf, sure_e, sure_t = model_degerlendirme_metin(corpus, y, vek_nesnesi, siniflandirici_nesnesi, olcut='f1', numsplits=5)
        ortalama_perf_degeri = np.mean(perf)
        # hangi siniflandirma ve vektorize etme yaklasimlarinin performansi
        # anahtar sozcuk siniflandirici metodu ve vektorize etme metodu ikilisinin adlari. Aralarina bosluk karakteri koyalim
        metod_vek_ikilisi = siniflandirici_adi + " " + vek_adi
        # sozluge ekleme yapalim
        metod_vekt_perf_sozlugu[metod_vek_ikilisi] = ortalama_perf_degeri

print(metod_vekt_perf_sozlugu)

len(metod_vekt_perf_sozlugu)

# sozluk siralama (metod_vek_ikisinin_adlari:performans degeri)
metod_vekt_perf_sirali = sorted(metod_vekt_perf_sozlugu.items(), key=lambda x:x[1], reverse=True)
print(metod_vekt_perf_sirali[0])

enbasarili_metod_vek_ikilisi = metod_vekt_perf_sirali[0][0] # => (metod_vek_ikisinin_adlari, performans degeri)
enbasarili_vek = enbasarili_metod_vek_ikilisi.split()[1]
enbasarili_metod = enbasarili_metod_vek_ikilisi.split()[0]
enyuksekperformansdegeri = metod_vekt_perf_sirali[0][1]
print(f"{enbasarili_vek} ile Dönüştürülmüş veri ile elde edilen En başarılı metod olan {enbasarili_metod} yüzde {enyuksekperformansdegeri*100:.2f}'lik performans göstermiştir")

"""[Support Vector Machine](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)

#### Metin Madenciliği Modelinin Kullanima sunulumu (Deployment (Dağıtım))
- Kullanıma Sunulacak / deploy edilecek Modelin oluşturulması
- 6. adım

##### Model Persistence (Model Kalıcılığı)
- oluşturulan modelin kaydedilmesi
- oluşturulan vektorize etme nesnesinin de kaydedilmesi

## Regresyon
- Doğrusal Regresyon
"""

import numpy as np
import pandas as pd

# Boston ev fiyatları veriseti (dataset)
from sklearn.datasets import load_boston
boston_ev_fiyatlari = load_boston()
print(boston_ev_fiyatlari)
print(boston_ev_fiyatlari['DESCR'])

# Gözetimli Öğrenme (Supervised Learning)
# X: özellik matrisi (feature matrix)
# y: hedef değişken vektörü (target-hedef / label-etiket / annotation)
X = boston_ev_fiyatlari['data']
y = boston_ev_fiyatlari['target']

type(X), type(y)

X.shape, y.shape

X[0]

# pandas kütüphanesi kullanılarak DataFrame/Series olarak gösterim
X_pd = pd.DataFrame(X, columns=boston_ev_fiyatlari['feature_names'])
X_pd.head()

# Hedef değişkeni
y_pd = pd.Series(y, name='Hedef Değişken')
y_pd.head()

# 1. Metod: Doğrusal Regresyon (linear regression)
# y' = intercept + k1*x1 + k2*x2 + ... + k13*x13 => tahmini fiyat
# y' =    k0*1   + k1*x1 + k2*x2 + ... + k13*x13 => tahmini fiyat
# y -> gerçek fiyat

# katsayılar vektoru => k1, k2, ..., k13 (ogrenilmesi gerekenler)
# ozellikler vektoru => x1, x2, ..., x13

# sumproduct(katsayılar, özellikler) => katsayılar vektoru ile ozellikler vektoru (dot) + kesişim => tahmini fiyat

from sklearn.linear_model import LinearRegression
# metodun nesnesini olusturuyoruz
reg = LinearRegression() # LinearRegression(fit_intercept=True)

# 1.1. Modeli Nasıl Oluşturuyoruz (Eğitiyoruz) - Model Training - .fit
# öğrenme - fit => k1, k2, k3, ..., k13, intercept (coefficients/katsayılar and intercept/kesişim)
reg.fit(X, y)

print(reg.intercept_)

print(reg.coef_)

params = pd.Series(reg.coef_, index=boston_ev_fiyatlari['feature_names'])
params

"""Model ile tahminleme"""

# 1.2. Oluşturulan (Eğitilen) Model ile Tahminleme (Prediction) Yapma - .predict
y_pred = reg.predict(X)

# ilk ev örneğimizin fiyat tahmini
y_pred[0]

# 2. Modeli Nasıl Değerlendirmeliyiz? Modelin başarısını ne ile ve nasıl ölçmeliyiz?

# Modelin eğitimini tamamlamıştık
   # reg = LinearRegression()
   # reg.fit(X, y)

# 2.1. Başarı ölçümünde kullanılacak ölçüt (metric) ne olmalıdır?
# https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics
from sklearn.metrics import mean_squared_error
# 2.2. Modelin eğitim veri kümesi (X? X_train) üzerindeki başarısı?
# tahminler ile hedef değerlerin karşılaştırılması
y_pred = reg.predict(X) # eğitim kümesindeki örnek evlerin fiyat tahminleri

# Başarı ölçümlenmesi
# y_true (y?): Ground truth (correct) target values.
# y_pred: Estimated (Predicted) target values.
mse_X = mean_squared_error(y, y_pred)
print(f"Mean squared error - Hata Karelerinin Ortalaması: {mse_X:.3}")

rmse = np.sqrt(mse_X)
print(f"Root Mean squared error - Hata Karelerinin Ortalamasının Karekökü: {rmse:.3}")
print("Root Mean squared error - Hata Karelerinin Ortalamasının Karekökü: {0:.3}".format(np.sqrt(mse_X)))

# MODEL DEGERLENDIRME VE SECILIMI
# Elimizdeki etiketli? veriyi Eğitim ve Değerlendirme (test/validation) verisi olarak ikiye ayıralım.
# model selection
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)

from sklearn.linear_model import LinearRegression, Lasso, Ridge
reg = LinearRegression()
las = Lasso()
las2 = Lasso(alpha=0.5)
rid = Ridge()
rid2 = Ridge(alpha=0.5)
reg.fit(X_train, y_train)
las.fit(X_train, y_train)
rid.fit(X_train, y_train)
las2.fit(X_train, y_train)
rid2.fit(X_train, y_train)

from sklearn.metrics import mean_squared_error
y_pred_train = reg.predict(X_train) # eğitim kümesindeki örnek evlerin fiyat tahminleri
mse_train = mean_squared_error(y_train, y_pred_train)
print("(Eğitim) Mean Squared Error - Hata Karelerinin Ortalaması:", mse_train)
print("(Eğitim) Root Mean Squared Error: {0:.3}".format( np.sqrt(mse_train) ))
y_pred_test = reg.predict(X_test) # test veri kümesindeki örneklerin fiyat tahminleri
mse_test = mean_squared_error(y_test, y_pred_test)
print("(Test) Mean Squared Error - Hata Karelerinin Ortalaması:", mse_test)
print("(Test) Root Mean Squared Error: {0:.3}".format( np.sqrt(mse_test) ))

# Farkli Basari olcutu
from sklearn.metrics import mean_absolute_error
mae_test = mean_absolute_error(y_test, y_pred_test)
print("(Test) Mean Absolute Error - Hatalarin Farklarinin Ortalaması - LINEAR REG:", mae_test)

y_pred_train = las.predict(X_train) # eğitim kümesindeki örnek evlerin fiyat tahminleri
mse_train = mean_squared_error(y_train, y_pred_train)
print("(Eğitim) Mean Squared Error - Hata Karelerinin Ortalaması:", mse_train)
print("(Eğitim) Root Mean Squared Error: {0:.3}".format( np.sqrt(mse_train) ))
y_pred_test = las.predict(X_test) # test veri kümesindeki örneklerin fiyat tahminleri
mse_test = mean_squared_error(y_test, y_pred_test)
print("(Test) Mean Squared Error - Hata Karelerinin Ortalaması:", mse_test)
print("(Test) Root Mean Squared Error: {0:.3}".format( np.sqrt(mse_test) ))

# Farkli Basari olcutu
from sklearn.metrics import mean_absolute_error
mae_test = mean_absolute_error(y_test, y_pred_test)
print("(Test) Mean Absolute Error - Hatalarin Farklarinin Ortalaması - LASSO:", mae_test)

# 3. Farklı Metotlar kullanarak Tahminleme Modelleri oluşturma
from sklearn.tree import DecisionTreeRegressor
dtr_se = DecisionTreeRegressor(criterion="squared_error")
 # "absolute_error"

dtr_se.fit(X_train, y_train)

# 2. Modeli Nasıl Değerlendirmeliyiz? Modelin başarısını ne ile ve nasıl ölçmeliyiz?
# 2.1. Başarı ölçümünde kullanılacak ölçüt (metric) ne olmalıdır?
from sklearn.metrics import mean_squared_error
# 2.2.1. Modelin eğitim veri kümesi (X_train) üzerindeki başarısı?
# tahminler ile hedef değerlerin karşılaştırılması
y_pred_train = dtr_se.predict(X_train) # eğitim kümesindeki örnek evlerin fiyat tahminleri

# Başarı ölçümlenmesi
# y_true (y_train): Ground truth (correct) target values.
# y_pred (y_pred_train): Estimated (Predicted) target values.
mse_train = mean_squared_error(y_train, y_pred_train)
print("(Eğitim) Mean Squared Error - Hata Karelerinin Ortalaması:", mse_train)
print("(Eğitim) Root Mean Squared Error: {0:.3}".format( np.sqrt(mse_train) ))

# 2.2.2. Modelin (eğitilirken karşılaşmadığı örnekler) test veri kümesi (X_test) üzerindeki başarısı?
# tahminler ile hedef değerlerin karşılaştırılması
y_pred_test = dtr_se.predict(X_test) # test veri kümesindeki örneklerin fiyat tahminleri

# Başarı ölçümlenmesi
# y_true (y_test): Ground truth (correct) target values.
# y_pred (y_pred_test): Estimated (Predicted) target values.
mse_test = mean_squared_error(y_test, y_pred_test)
print("(Test) Mean Squared Error - Hata Karelerinin Ortalaması:", mse_test)
print("(Test) Root Mean Squared Error: {0:.3}".format( np.sqrt(mse_test) ))

# Farkli Basari olcutu
from sklearn.metrics import mean_absolute_error
mae_test = mean_absolute_error(y_test, y_pred_test)
print("(Test) Mean Absolute Error - Hatalarin Farklarinin Ortalaması - KARAR AGACI:", mae_test)

